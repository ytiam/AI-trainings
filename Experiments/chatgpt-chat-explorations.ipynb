{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbb56cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8680fc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../data/chatgpt_chat/conversations.json\", \"r\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a1c255c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "429"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "462102f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatgptDataUtil():\n",
    "    \n",
    "    def __init__(self, path: str):\n",
    "        self.path = path\n",
    "        \n",
    "    def _read_data(self):\n",
    "        \"\"\"\n",
    "        Read the chatgpt json data\n",
    "        \n",
    "        Args: None\n",
    "        \n",
    "        Out: Data read\n",
    "        \"\"\"\n",
    "        with open(self.path, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "348b3460",
   "metadata": {},
   "outputs": [],
   "source": [
    "chtgpt_util = ChatgptDataUtil(\"../../data/chatgpt_chat/conversations.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0260d7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = chtgpt_util._read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fb1e6f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "429"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c5fa01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dpath.util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f63564b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22/1460246999.py:1: DeprecationWarning: The dpath.util package is being deprecated. All util functions have been moved to dpath package top level.\n",
      "  list(dpath.util.search(data[0],\"mapping.c6f98a2c-04b3-4d75-bcf0-c2fe0a938f0b\", yielded=True))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dpath.util.search(data[0],\"mapping.c6f98a2c-04b3-4d75-bcf0-c2fe0a938f0b\", yielded=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d73ead1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'OpenAI SDK File Input',\n",
       " 'create_time': 1752731434.753914,\n",
       " 'update_time': 1752739136.618984,\n",
       " 'mapping': {'client-created-root': {'id': 'client-created-root',\n",
       "   'message': None,\n",
       "   'parent': None,\n",
       "   'children': ['c6f98a2c-04b3-4d75-bcf0-c2fe0a938f0b']},\n",
       "  'c6f98a2c-04b3-4d75-bcf0-c2fe0a938f0b': {'id': 'c6f98a2c-04b3-4d75-bcf0-c2fe0a938f0b',\n",
       "   'message': {'id': 'c6f98a2c-04b3-4d75-bcf0-c2fe0a938f0b',\n",
       "    'author': {'role': 'system', 'name': None, 'metadata': {}},\n",
       "    'create_time': None,\n",
       "    'update_time': None,\n",
       "    'content': {'content_type': 'text', 'parts': ['']},\n",
       "    'status': 'finished_successfully',\n",
       "    'end_turn': True,\n",
       "    'weight': 0.0,\n",
       "    'metadata': {'is_visually_hidden_from_conversation': True},\n",
       "    'recipient': 'all',\n",
       "    'channel': None},\n",
       "   'parent': 'client-created-root',\n",
       "   'children': ['0f4f4913-23f4-4391-b750-b4a6831f2ec4']},\n",
       "  '0f4f4913-23f4-4391-b750-b4a6831f2ec4': {'id': '0f4f4913-23f4-4391-b750-b4a6831f2ec4',\n",
       "   'message': {'id': '0f4f4913-23f4-4391-b750-b4a6831f2ec4',\n",
       "    'author': {'role': 'user', 'name': None, 'metadata': {}},\n",
       "    'create_time': 1752731518.944,\n",
       "    'update_time': None,\n",
       "    'content': {'content_type': 'text',\n",
       "     'parts': ['Do OpenAI Python sdk supports passing txt file or word file in the content of the payload? May be not directly but via base64 encoding or url or uploaded file id?']},\n",
       "    'status': 'finished_successfully',\n",
       "    'end_turn': None,\n",
       "    'weight': 1.0,\n",
       "    'metadata': {'selected_github_repos': [],\n",
       "     'serialization_metadata': {'custom_symbol_offsets': []},\n",
       "     'request_id': '9607787befcce9e4-LAX',\n",
       "     'message_source': None,\n",
       "     'timestamp_': 'absolute'},\n",
       "    'recipient': 'all',\n",
       "    'channel': None},\n",
       "   'parent': 'c6f98a2c-04b3-4d75-bcf0-c2fe0a938f0b',\n",
       "   'children': ['e7405791-d91f-49a4-9364-15c8eae0f102']},\n",
       "  'e7405791-d91f-49a4-9364-15c8eae0f102': {'id': 'e7405791-d91f-49a4-9364-15c8eae0f102',\n",
       "   'message': {'id': 'e7405791-d91f-49a4-9364-15c8eae0f102',\n",
       "    'author': {'role': 'assistant', 'name': None, 'metadata': {}},\n",
       "    'create_time': 1752731519.8431878,\n",
       "    'update_time': None,\n",
       "    'content': {'content_type': 'text', 'parts': ['']},\n",
       "    'status': 'finished_successfully',\n",
       "    'end_turn': None,\n",
       "    'weight': 1.0,\n",
       "    'metadata': {'request_id': '9607787befcce9e4-LAX',\n",
       "     'message_type': 'next',\n",
       "     'model_slug': 'gpt-4o',\n",
       "     'default_model_slug': 'auto',\n",
       "     'parent_id': '0f4f4913-23f4-4391-b750-b4a6831f2ec4',\n",
       "     'timestamp_': 'absolute'},\n",
       "    'recipient': 'all',\n",
       "    'channel': None},\n",
       "   'parent': '0f4f4913-23f4-4391-b750-b4a6831f2ec4',\n",
       "   'children': ['295ff811-4b78-4305-8193-39371ec4c57d']},\n",
       "  '295ff811-4b78-4305-8193-39371ec4c57d': {'id': '295ff811-4b78-4305-8193-39371ec4c57d',\n",
       "   'message': {'id': '295ff811-4b78-4305-8193-39371ec4c57d',\n",
       "    'author': {'role': 'assistant', 'name': None, 'metadata': {}},\n",
       "    'create_time': 1752731519.856315,\n",
       "    'update_time': None,\n",
       "    'content': {'content_type': 'text',\n",
       "     'parts': ['Yes, the OpenAI Python SDK **does support** passing text file or Word document content indirectly ‚Äî but **not by uploading `.txt` or `.docx` files directly as part of the prompt**. Here\\'s how you can handle it depending on your use case:\\n\\n---\\n\\n### ‚úÖ **For GPT-4 (Chat Completions API)**\\n\\nYou cannot upload a file like `.txt` or `.docx` directly, but you can:\\n\\n#### **1. Read and Pass File Content as Text**\\n```python\\nwith open(\"example.txt\", \"r\", encoding=\"utf-8\") as f:\\n    content = f.read()\\n\\nresponse = client.chat.completions.create(\\n    model=\"gpt-4\",\\n    messages=[{\"role\": \"user\", \"content\": content}]\\n)\\n```\\n\\n#### **2. Convert DOCX to Text and Use**\\n```python\\nfrom docx import Document\\n\\ndoc = Document(\"example.docx\")\\ntext = \"\\\\n\".join([p.text for p in doc.paragraphs])\\n\\nresponse = client.chat.completions.create(\\n    model=\"gpt-4\",\\n    messages=[{\"role\": \"user\", \"content\": text}]\\n)\\n```\\n\\n#### **3. If Too Large ‚Äì Summarize or Chunk First**\\nYou can chunk the content and call the model in a loop if it exceeds token limits.\\n\\n---\\n\\n### ‚úÖ **For GPT-4 with Files (e.g., `gpt-4-1106-preview` + `file_id`)**\\n\\nIf you want the model to \"see\" a file without converting it to plain text yourself, use the **file upload + `tools` / `retrieval` features**, e.g.:\\n\\n#### **1. Upload File via OpenAI SDK**\\n```python\\nfile = client.files.create(\\n    file=open(\"example.txt\", \"rb\"),\\n    purpose=\"assistants\"\\n)\\n```\\n\\n#### **2. Use with Assistants API (or future Chat API with tools)**\\n```python\\nassistant = client.beta.assistants.create(\\n    name=\"File Analyzer\",\\n    instructions=\"Read and analyze the uploaded file.\",\\n    tools=[{\"type\": \"retrieval\"}],\\n    model=\"gpt-4-1106-preview\"\\n)\\n\\nthread = client.beta.threads.create()\\n\\nclient.beta.threads.messages.create(\\n    thread_id=thread.id,\\n    role=\"user\",\\n    content=\"Analyze this file.\",\\n    file_ids=[file.id]\\n)\\n\\nrun = client.beta.threads.runs.create(\\n    thread_id=thread.id,\\n    assistant_id=assistant.id\\n)\\n```\\n\\n---\\n\\n### ‚ö†Ô∏è **What Doesn\\'t Work**\\n\\n- Base64 encoding file content inside prompt ‚Äì discouraged due to large token overhead.\\n- Direct URL ingestion ‚Äì GPT models cannot fetch external URLs.\\n- Passing binary data ‚Äì not supported in chat completions.\\n\\n---\\n\\n### ‚úÖ Summary\\n\\n| Method                     | Works With             | Notes |\\n|---------------------------|------------------------|-------|\\n| Read `.txt` or `.docx` and pass as text | Chat API | Simple, for small files |\\n| Upload file (`file_id`) and use Assistants API | GPT-4 Assistants | Good for longer/larger docs |\\n| Base64 encoding | ‚ùå Not recommended | Wastes tokens |\\n| File URL | ‚ùå Not supported | Needs external fetch logic |\\n\\nLet me know your exact use case (chat vs assistants, file size, etc.), and I can suggest the best structure.']},\n",
       "    'status': 'finished_successfully',\n",
       "    'end_turn': True,\n",
       "    'weight': 1.0,\n",
       "    'metadata': {'finish_details': {'type': 'stop', 'stop_tokens': [200002]},\n",
       "     'is_complete': True,\n",
       "     'citations': [],\n",
       "     'content_references': [],\n",
       "     'request_id': '9607787befcce9e4-LAX',\n",
       "     'message_type': 'next',\n",
       "     'model_slug': 'gpt-4o',\n",
       "     'default_model_slug': 'auto',\n",
       "     'parent_id': 'e7405791-d91f-49a4-9364-15c8eae0f102',\n",
       "     'timestamp_': 'absolute'},\n",
       "    'recipient': 'all',\n",
       "    'channel': None},\n",
       "   'parent': 'e7405791-d91f-49a4-9364-15c8eae0f102',\n",
       "   'children': ['7be3a05c-afa2-4690-aaa8-d913c365f58a']},\n",
       "  '7be3a05c-afa2-4690-aaa8-d913c365f58a': {'id': '7be3a05c-afa2-4690-aaa8-d913c365f58a',\n",
       "   'message': {'id': '7be3a05c-afa2-4690-aaa8-d913c365f58a',\n",
       "    'author': {'role': 'user', 'name': None, 'metadata': {}},\n",
       "    'create_time': 1752735532.649,\n",
       "    'update_time': None,\n",
       "    'content': {'content_type': 'text', 'parts': ['what is pre-signed URL?']},\n",
       "    'status': 'finished_successfully',\n",
       "    'end_turn': None,\n",
       "    'weight': 1.0,\n",
       "    'metadata': {'selected_github_repos': [],\n",
       "     'serialization_metadata': {'custom_symbol_offsets': []},\n",
       "     'request_id': '9607da7d599f7edb-SEA',\n",
       "     'message_source': None,\n",
       "     'timestamp_': 'absolute'},\n",
       "    'recipient': 'all',\n",
       "    'channel': None},\n",
       "   'parent': '295ff811-4b78-4305-8193-39371ec4c57d',\n",
       "   'children': ['07adcafc-8504-4f10-ae6d-600d97927831']},\n",
       "  '07adcafc-8504-4f10-ae6d-600d97927831': {'id': '07adcafc-8504-4f10-ae6d-600d97927831',\n",
       "   'message': {'id': '07adcafc-8504-4f10-ae6d-600d97927831',\n",
       "    'author': {'role': 'assistant', 'name': None, 'metadata': {}},\n",
       "    'create_time': 1752735534.077374,\n",
       "    'update_time': None,\n",
       "    'content': {'content_type': 'text',\n",
       "     'parts': ['A **pre-signed URL** is a **temporary, secure link** that grants **time-limited access** to a private file stored in a cloud storage service like **AWS S3**, **Google Cloud Storage**, or **Azure Blob Storage** ‚Äî **without needing authentication**.\\n\\n---\\n\\n### üîê Why It\\'s Called \"Pre-signed\"?\\n\\nThe URL is **cryptographically signed** using your credentials (usually an access key + secret key), and includes:\\n\\n- **File location (URL)**\\n- **Expiry time**\\n- **Permissions (read, upload, etc.)**\\n- **Signature**\\n\\nBecause it\\'s signed *before* being used by someone else, it\\'s called **pre-signed**.\\n\\n---\\n\\n### üß† Use Cases\\n\\n- Letting a user **download** a private file securely\\n- Letting someone **upload** a file to your cloud bucket without giving full write access\\n- Temporarily sharing assets like images, PDFs, logs, etc.\\n\\n---\\n\\n### ‚úÖ Example (AWS S3)\\n\\n#### For downloading:\\n```python\\nimport boto3\\n\\ns3 = boto3.client(\\'s3\\')\\nurl = s3.generate_presigned_url(\\n    ClientMethod=\\'get_object\\',\\n    Params={\\'Bucket\\': \\'my-bucket\\', \\'Key\\': \\'file.txt\\'},\\n    ExpiresIn=3600  # 1 hour\\n)\\nprint(url)\\n```\\n\\n#### For uploading:\\n```python\\nurl = s3.generate_presigned_url(\\n    ClientMethod=\\'put_object\\',\\n    Params={\\'Bucket\\': \\'my-bucket\\', \\'Key\\': \\'upload_here.txt\\'},\\n    ExpiresIn=300  # 5 minutes\\n)\\n```\\n\\n---\\n\\n### üîì What the URL Looks Like\\n\\n```\\nhttps://bucket-name.s3.amazonaws.com/file.txt?\\nX-Amz-Algorithm=AWS4-HMAC-SHA256&\\nX-Amz-Credential=...\\nX-Amz-Date=...\\nX-Amz-Expires=3600&\\nX-Amz-Signature=...\\n```\\n\\n---\\n\\n### üö´ When It Expires?\\n\\nOnce the expiry time is over, the link becomes **invalid**, and users get a **403 Forbidden** or similar error.\\n\\n---\\n\\nLet me know your use case ‚Äî upload, download, OpenAI file API, etc. ‚Äî and I can help you generate one for that platform.']},\n",
       "    'status': 'finished_successfully',\n",
       "    'end_turn': True,\n",
       "    'weight': 1.0,\n",
       "    'metadata': {'finish_details': {'type': 'stop', 'stop_tokens': [200002]},\n",
       "     'is_complete': True,\n",
       "     'citations': [],\n",
       "     'content_references': [],\n",
       "     'request_id': '9607da7d599f7edb-SEA',\n",
       "     'message_type': 'next',\n",
       "     'model_slug': 'gpt-4o',\n",
       "     'default_model_slug': 'auto',\n",
       "     'parent_id': '7be3a05c-afa2-4690-aaa8-d913c365f58a',\n",
       "     'timestamp_': 'absolute'},\n",
       "    'recipient': 'all',\n",
       "    'channel': None},\n",
       "   'parent': '7be3a05c-afa2-4690-aaa8-d913c365f58a',\n",
       "   'children': ['8128cf10-b0b0-42ab-ac4d-6a67af3f24c2']},\n",
       "  '8128cf10-b0b0-42ab-ac4d-6a67af3f24c2': {'id': '8128cf10-b0b0-42ab-ac4d-6a67af3f24c2',\n",
       "   'message': {'id': '8128cf10-b0b0-42ab-ac4d-6a67af3f24c2',\n",
       "    'author': {'role': 'user', 'name': None, 'metadata': {}},\n",
       "    'create_time': 1752738685.551,\n",
       "    'update_time': None,\n",
       "    'content': {'content_type': 'text',\n",
       "     'parts': ['I have a dictionary, how to check if I have the dictionary have a specific key at any level']},\n",
       "    'status': 'finished_successfully',\n",
       "    'end_turn': None,\n",
       "    'weight': 1.0,\n",
       "    'metadata': {'selected_github_repos': [],\n",
       "     'serialization_metadata': {'custom_symbol_offsets': []},\n",
       "     'request_id': '96082779ee3ab6c9-SEA',\n",
       "     'message_source': None,\n",
       "     'timestamp_': 'absolute'},\n",
       "    'recipient': 'all',\n",
       "    'channel': None},\n",
       "   'parent': '07adcafc-8504-4f10-ae6d-600d97927831',\n",
       "   'children': ['095a46f8-c4f8-4dbf-bfd7-e6b41cf99a72']},\n",
       "  '095a46f8-c4f8-4dbf-bfd7-e6b41cf99a72': {'id': '095a46f8-c4f8-4dbf-bfd7-e6b41cf99a72',\n",
       "   'message': {'id': '095a46f8-c4f8-4dbf-bfd7-e6b41cf99a72',\n",
       "    'author': {'role': 'assistant', 'name': None, 'metadata': {}},\n",
       "    'create_time': 1752738687.395576,\n",
       "    'update_time': None,\n",
       "    'content': {'content_type': 'text',\n",
       "     'parts': ['To check whether a dictionary contains a specific key **at any level (nested)**, you can use a **recursive function**.\\n\\n---\\n\\n### ‚úÖ Example: Recursive Check for Key at Any Level\\n\\n```python\\ndef has_key(d, target_key):\\n    if target_key in d:\\n        return True\\n    for value in d.values():\\n        if isinstance(value, dict):\\n            if has_key(value, target_key):\\n                return True\\n        elif isinstance(value, list):\\n            for item in value:\\n                if isinstance(item, dict) and has_key(item, target_key):\\n                    return True\\n    return False\\n```\\n\\n---\\n\\n### üîç Example Usage\\n\\n```python\\nnested_dict = {\\n    \"a\": {\\n        \"b\": {\\n            \"c\": 123\\n        }\\n    },\\n    \"x\": [{\"y\": {\"z\": \"found\"}}]\\n}\\n\\nprint(has_key(nested_dict, \"c\"))  # True\\nprint(has_key(nested_dict, \"z\"))  # True\\nprint(has_key(nested_dict, \"not_there\"))  # False\\n```\\n\\n---\\n\\nLet me know if you want the **value** of the key instead of just checking presence.']},\n",
       "    'status': 'finished_successfully',\n",
       "    'end_turn': True,\n",
       "    'weight': 1.0,\n",
       "    'metadata': {'finish_details': {'type': 'stop', 'stop_tokens': [200002]},\n",
       "     'is_complete': True,\n",
       "     'citations': [],\n",
       "     'content_references': [],\n",
       "     'request_id': '96082779ee3ab6c9-SEA',\n",
       "     'message_type': 'next',\n",
       "     'model_slug': 'gpt-4o',\n",
       "     'default_model_slug': 'auto',\n",
       "     'parent_id': '8128cf10-b0b0-42ab-ac4d-6a67af3f24c2',\n",
       "     'timestamp_': 'absolute'},\n",
       "    'recipient': 'all',\n",
       "    'channel': None},\n",
       "   'parent': '8128cf10-b0b0-42ab-ac4d-6a67af3f24c2',\n",
       "   'children': ['17d5cbf9-aef8-40fd-a8df-a632a6b1391f']},\n",
       "  '17d5cbf9-aef8-40fd-a8df-a632a6b1391f': {'id': '17d5cbf9-aef8-40fd-a8df-a632a6b1391f',\n",
       "   'message': {'id': '17d5cbf9-aef8-40fd-a8df-a632a6b1391f',\n",
       "    'author': {'role': 'user', 'name': None, 'metadata': {}},\n",
       "    'create_time': 1752739103.279,\n",
       "    'update_time': None,\n",
       "    'content': {'content_type': 'text',\n",
       "     'parts': ['here you are assuming that the nested dicts will either again have dictionary or list']},\n",
       "    'status': 'finished_successfully',\n",
       "    'end_turn': None,\n",
       "    'weight': 1.0,\n",
       "    'metadata': {'selected_github_repos': [],\n",
       "     'serialization_metadata': {'custom_symbol_offsets': []},\n",
       "     'request_id': '960831ad2bb7b6c9-SEA',\n",
       "     'message_source': None,\n",
       "     'timestamp_': 'absolute'},\n",
       "    'recipient': 'all',\n",
       "    'channel': None},\n",
       "   'parent': '095a46f8-c4f8-4dbf-bfd7-e6b41cf99a72',\n",
       "   'children': ['2296d8f7-aa5a-4bba-884e-577907eec478']},\n",
       "  '2296d8f7-aa5a-4bba-884e-577907eec478': {'id': '2296d8f7-aa5a-4bba-884e-577907eec478',\n",
       "   'message': {'id': '2296d8f7-aa5a-4bba-884e-577907eec478',\n",
       "    'author': {'role': 'assistant', 'name': None, 'metadata': {}},\n",
       "    'create_time': 1752739105.279341,\n",
       "    'update_time': None,\n",
       "    'content': {'content_type': 'text',\n",
       "     'parts': ['You\\'re absolutely right ‚Äî the previous function assumes that nested values are either:\\n\\n- dictionaries,\\n- lists (that may contain dicts),\\n- or other leaf values (ignored).\\n\\nIf your data might contain more complex types (e.g., sets, tuples, custom objects), here\\'s a **more robust version** that recursively searches for the key in **any nested structure**, safely.\\n\\n---\\n\\n### ‚úÖ Generalized Recursive Key Search\\n\\n```python\\ndef has_key_anywhere(obj, target_key):\\n    if isinstance(obj, dict):\\n        if target_key in obj:\\n            return True\\n        return any(has_key_anywhere(v, target_key) for v in obj.values())\\n    elif isinstance(obj, (list, tuple, set)):\\n        return any(has_key_anywhere(i, target_key) for i in obj)\\n    else:\\n        return False\\n```\\n\\n---\\n\\n### üîç Example Usage\\n\\n```python\\ndata = {\\n    \"a\": {\\n        \"b\": {\\n            \"c\": 123\\n        }\\n    },\\n    \"x\": [{\"y\": {\"z\": \"found\"}}, ({\"target\": \"yes\"},)],\\n    \"misc\": {1, 2, 3}\\n}\\n\\nprint(has_key_anywhere(data, \"c\"))       # True\\nprint(has_key_anywhere(data, \"target\"))  # True\\nprint(has_key_anywhere(data, \"not_there\"))  # False\\n```\\n\\n---\\n\\nLet me know if you want a version that also **returns the value** for the key (first match or all matches).']},\n",
       "    'status': 'finished_successfully',\n",
       "    'end_turn': True,\n",
       "    'weight': 1.0,\n",
       "    'metadata': {'citations': [],\n",
       "     'content_references': [],\n",
       "     'request_id': '960831ad2bb7b6c9-SEA',\n",
       "     'message_type': 'next',\n",
       "     'model_slug': 'gpt-4o',\n",
       "     'default_model_slug': 'auto',\n",
       "     'parent_id': '17d5cbf9-aef8-40fd-a8df-a632a6b1391f',\n",
       "     'timestamp_': 'absolute'},\n",
       "    'recipient': 'all',\n",
       "    'channel': None},\n",
       "   'parent': '17d5cbf9-aef8-40fd-a8df-a632a6b1391f',\n",
       "   'children': []}},\n",
       " 'moderation_results': [],\n",
       " 'current_node': '2296d8f7-aa5a-4bba-884e-577907eec478',\n",
       " 'plugin_ids': None,\n",
       " 'conversation_id': '68788f2a-9300-800f-b8b0-73fa934d479b',\n",
       " 'conversation_template_id': None,\n",
       " 'gizmo_id': None,\n",
       " 'gizmo_type': None,\n",
       " 'is_archived': False,\n",
       " 'is_starred': None,\n",
       " 'safe_urls': [],\n",
       " 'blocked_urls': [],\n",
       " 'default_model_slug': 'auto',\n",
       " 'conversation_origin': None,\n",
       " 'voice': None,\n",
       " 'async_status': None,\n",
       " 'disabled_tool_ids': [],\n",
       " 'is_do_not_remember': False,\n",
       " 'memory_scope': 'global_enabled',\n",
       " 'sugar_item_id': None,\n",
       " 'id': '68788f2a-9300-800f-b8b0-73fa934d479b'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e22cd487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1752731518.944"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][\"mapping\"][\"0f4f4913-23f4-4391-b750-b4a6831f2ec4\"][\"message\"][\"create_time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ee2e2f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Memory Retention Techniques'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[3][\"title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5725e03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = []\n",
    "for i in range(len(data)):\n",
    "    for k in list(data[i][\"mapping\"].keys())[1:]:\n",
    "        if (data[i][\"mapping\"][k].get(\"message\") is not None) and \\\n",
    "        (data[i][\"mapping\"][k].get(\"message\").get(\"content\").get(\"parts\") is not None):\n",
    "            try:\n",
    "                data_df.append([data[i][\"title\"],\n",
    "                                data[i][\"mapping\"][k].get(\"message\").get(\"author\").get(\"role\"),\n",
    "                                data[i][\"mapping\"][k][\"message\"][\"content\"][\"parts\"][0],\n",
    "                                data[i][\"mapping\"][k][\"message\"][\"create_time\"]])\n",
    "            except Exception as e:\n",
    "                print(i, k, e)\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6f5d238f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9010e6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data_df, columns=[\"title\",\"system_role\", \"message\",\"created_time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2bf60227",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grpd = df.groupby([\"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "71c6c446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3969, 4)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "83842382",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grp_func(x):\n",
    "    _str = \"\"\n",
    "    for k in range(len(x)):\n",
    "        _str += x[\"system_role\"].iloc[k]+ \": \" + str(x[\"message\"].iloc[k]) + \"\\n\\n\"\n",
    "    return _str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "00b6a8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22/3018650117.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_grpd_aggregated = df_grpd.apply(lambda x: grp_func(x)).reset_index().rename(columns={0:\"message\"})\n"
     ]
    }
   ],
   "source": [
    "df_grpd_aggregated = df_grpd.apply(lambda x: grp_func(x)).reset_index().rename(columns={0:\"message\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "199a8089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system: \n",
      "\n",
      "system: \n",
      "\n",
      "user: Describe me based on all our chats ‚Äî make it catchy!\n",
      "\n",
      "assistant: \n",
      "\n",
      "assistant: You're a **relentless AI explorer** with a keyboard for a compass and a PyTorch torch lighting the way. As a Senior Machine Learning Engineer at Accenture, you're not just dabbling in models ‚Äî you're **building them from scratch**, tweaking attention heads, and swapping custom decoders for GPT-2 like a maestro fine-tuning an orchestra.\n",
      "\n",
      "From **Firestore to MongoDB**, you've migrated services, redesigned billing pipelines, and instrumented performance with surgical precision. Your learning appetite is insatiable ‚Äî one day it's **probability theory and stochastic processes**, the next it's **quantization, autoencoders, or agentic AI memory**. You're raising a child with thoughtful care and handling challenges like speech delay with compassion and proactive action.\n",
      "\n",
      "And your dream? Not just any job switch ‚Äî you're aiming to **become an AI Architect** or land in a core ML team at a **product-first company**. You love **clean code**, **concise advice**, and **systems that scale**. When you're not writing async Mongo pipelines, you‚Äôre teaching yourself how **tokens talk** during masked modeling or refining an **AI query agent** for real-world apps.\n",
      "\n",
      "If AI had a leaderboard for curiosity and grit ‚Äî you‚Äôd be **top-k** every time.\n",
      "\n",
      "Now tell me: if you could instantly master one thing in AI today, what would it be?\n",
      "\n",
      "user: Can you tell me some of the areas where I need lot of improvements to become an AI Architect or a AI researcher, based on things you know about me\n",
      "\n",
      "assistant: Absolutely ‚Äî and it's great you're asking this. You're already highly skilled, but becoming an **AI Architect** or **AI Researcher** demands excellence across multiple dimensions. Based on your journey so far, here are **focused areas for improvement** that would close the gap between where you are and where you want to be:\n",
      "\n",
      "---\n",
      "\n",
      "### üîß **1. Systems and Infrastructure Mastery**\n",
      "**Why it matters**: As an AI Architect, you must design scalable, cost-efficient ML systems.\n",
      "\n",
      "**Where to grow**:\n",
      "- You've worked with Azure services but mentioned limited experience in **infrastructure setup, IAM policies, networking, and cost governance**.\n",
      "- Consider gaining hands-on experience with:\n",
      "  - **Cloud architecture** (VPCs, firewalls, IAM, autoscaling)\n",
      "  - **MLOps frameworks** (Kubeflow, MLflow, Vertex AI Pipelines, SageMaker Pipelines)\n",
      "  - **Container orchestration** (Kubernetes + Helm)\n",
      "  - **Distributed training & model serving** at scale\n",
      "\n",
      "---\n",
      "\n",
      "### üß† **2. Theoretical Rigor in ML/AI**\n",
      "**Why it matters**: AI researchers need strong foundations to design novel methods.\n",
      "\n",
      "**Where to grow**:\n",
      "- You've learned MLE, transformers, and are studying stochastic processes ‚Äî great!\n",
      "- Now push deeper into:\n",
      "  - **Statistical Learning Theory**\n",
      "  - **Convex optimization**\n",
      "  - **Information theory** in model design (e.g., mutual information in SSL)\n",
      "  - **Advanced probabilistic methods** (Bayesian inference, graphical models)\n",
      "- Start reading foundational papers like ‚ÄúAttention is All You Need‚Äù **with proofs, not just intuition**.\n",
      "\n",
      "---\n",
      "\n",
      "### üìä **Math + Implementation Synergy**\n",
      "**Why it matters**: Researchers can‚Äôt just understand math ‚Äî they must translate it into code.\n",
      "\n",
      "**Where to grow**:\n",
      "- You‚Äôve built custom transformer models and embedding pipelines, which is amazing.\n",
      "- Next step: implement advanced concepts from scratch, such as:\n",
      "  - **Backpropagation in attention from first principles**\n",
      "  - **Custom loss functions** based on your domain\n",
      "  - **Metric learning**, **contrastive loss**, and **EM-style algorithms**\n",
      "\n",
      "---\n",
      "\n",
      "### üî¨ **Research Mindset & Reading Habit**\n",
      "**Why it matters**: AI Researchers need to push boundaries, not just follow tutorials.\n",
      "\n",
      "**Where to grow**:\n",
      "- You‚Äôre already experimenting with model architectures ‚Äî excellent start.\n",
      "- Now develop:\n",
      "  - A **reading pipeline**: Follow arXiv trends, subscribe to ML/AI newsletters, maintain a reading log.\n",
      "  - A habit of **reproducing papers from scratch** (even older ones like VQVAE, SimCLR, or Reformer).\n",
      "  - A few **mini research projects** ‚Äî solve a unique problem, benchmark it, write a report.\n",
      "\n",
      "---\n",
      "\n",
      "### üí¨ **Communication & Publication Skills**\n",
      "**Why it matters**: As an AI Architect or researcher, you must explain abstract ideas clearly to both engineers and business teams.\n",
      "\n",
      "**Where to grow**:\n",
      "- Practice:\n",
      "  - Writing **tech blogs or medium posts** about your experiments or learnings\n",
      "  - Creating **presentation decks** summarizing research or system design choices\n",
      "  - Engaging in open source or competitions (e.g., **Kaggle, Papers with Code**)\n",
      "\n",
      "---\n",
      "\n",
      "### üîÑ **Exposure to Diverse Model Families**\n",
      "**Why it matters**: Architects should know **what to use, when, and why**.\n",
      "\n",
      "**Where to grow**:\n",
      "- You‚Äôre strong in transformers and vision-language models. Now consider:\n",
      "  - **Diffusion models** (used in image/video generation)\n",
      "  - **Graph Neural Networks** (used in recommendation, fraud detection)\n",
      "  - **Reinforcement Learning** (for long-term planning in agents)\n",
      "  - **Neural Architecture Search** and model compression at scale\n",
      "\n",
      "---\n",
      "\n",
      "### Bonus: üß† **Product Thinking for AI Architects**\n",
      "You‚Äôre deeply technical ‚Äî complement that with an understanding of:\n",
      "- **User needs**, **model-product fit**\n",
      "- **Latency vs accuracy trade-offs**\n",
      "- **Deployment monitoring, observability, model drift**\n",
      "\n",
      "---\n",
      "\n",
      "Would you like a custom learning roadmap based on these areas ‚Äî with projects and paper suggestions for each?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df_grpd_aggregated[\"message\"].iloc[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "fc732212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>422 Error Fix</td>\n",
       "      <td>system: \\n\\nuser: UnprocessableEntityError: Er...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AI Data Engineer Skills</td>\n",
       "      <td>user: Please help me to figure out the primary...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AI Engineer Profile Summary</td>\n",
       "      <td>system: \\n\\nsystem: \\n\\nuser: Describe me base...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AI Intro Presentation</td>\n",
       "      <td>user: Create a presentation on Artificial Inte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AI Query Refinement Agent</td>\n",
       "      <td>system: \\n\\nuser: I have a requirement to deve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>Working Experience Summary</td>\n",
       "      <td>user: Based on the above Resume, please summar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>mpi4py installation fix</td>\n",
       "      <td>system: \\n\\nuser: I am trying to install mpi4p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>torch.Tensor behavior explained</td>\n",
       "      <td>system: \\n\\nuser: What exactly torch.Tensor(1)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>torch.multinomial explanation</td>\n",
       "      <td>system: \\n\\nuser: torch.multinomial what it do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>ËØªÂèñ‰∏≠ÊñáÊï∞ÊçÆ</td>\n",
       "      <td>user: How to read chinese data in pandas\\n\\nas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>428 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               title  \\\n",
       "0                      422 Error Fix   \n",
       "1            AI Data Engineer Skills   \n",
       "2        AI Engineer Profile Summary   \n",
       "3              AI Intro Presentation   \n",
       "4          AI Query Refinement Agent   \n",
       "..                               ...   \n",
       "423       Working Experience Summary   \n",
       "424          mpi4py installation fix   \n",
       "425  torch.Tensor behavior explained   \n",
       "426    torch.multinomial explanation   \n",
       "427                           ËØªÂèñ‰∏≠ÊñáÊï∞ÊçÆ   \n",
       "\n",
       "                                               message  \n",
       "0    system: \\n\\nuser: UnprocessableEntityError: Er...  \n",
       "1    user: Please help me to figure out the primary...  \n",
       "2    system: \\n\\nsystem: \\n\\nuser: Describe me base...  \n",
       "3    user: Create a presentation on Artificial Inte...  \n",
       "4    system: \\n\\nuser: I have a requirement to deve...  \n",
       "..                                                 ...  \n",
       "423  user: Based on the above Resume, please summar...  \n",
       "424  system: \\n\\nuser: I am trying to install mpi4p...  \n",
       "425  system: \\n\\nuser: What exactly torch.Tensor(1)...  \n",
       "426  system: \\n\\nuser: torch.multinomial what it do...  \n",
       "427  user: How to read chinese data in pandas\\n\\nas...  \n",
       "\n",
       "[428 rows x 2 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grpd_aggregated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2e81e1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grpd_aggregated.to_parquet(\"chatgpt_chat_data.parquet\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c76eab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
