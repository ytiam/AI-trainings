{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "tHktDmcxoQBC"
   },
   "outputs": [],
   "source": [
    "# !pip install transformers datasets tokenizers\n",
    "# !wget http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip\n",
    "# !unzip -qq cornell_movie_dialogs_corpus.zip\n",
    "# !rm cornell_movie_dialogs_corpus.zip\n",
    "# !mkdir datasets\n",
    "# !mv cornell\\ movie-dialogs\\ corpus/movie_conversations.txt ./datasets\n",
    "# !mv cornell\\ movie-dialogs\\ corpus/movie_lines.txt ./datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trained on two objectives\n",
    "- Next Sentence Prediction\n",
    "- Masked Language Modeling i.e. masked word prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "zsvxdkMmPMsg"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import re\n",
    "import random\n",
    "import transformers, datasets\n",
    "from tokenizers import BertWordPieceTokenizer\n",
    "from transformers import BertTokenizer\n",
    "import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import itertools\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DyRDEfhtoDRk"
   },
   "source": [
    "# 1 ) Tokenization (Word Piece Tokenizer)\n",
    "\n",
    "[Huggingface WordPieceTokenizer](https://huggingface.co/learn/nlp-course/chapter6/6?fw=pt)\n",
    "\n",
    "The tokenizer's primary job is to split the input text into smaller tokens. These tokens are usually words, subwords (WordPiece tokens), or characters, depending on the specific tokenizer and its configuration.\n",
    "\n",
    "Subword Tokenization (WordPiece): BERT often uses subword tokenization, where words are further divided into smaller units called subword tokens. For instance, \"unhappiness\" might be broken down into [\"un\", \"##hap\", \"##piness\"]\n",
    "\n",
    "\n",
    "By dividing the frequency of the pair by the product of the frequencies of each of its parts, the algorithm prioritizes the merging of pairs where the individual parts are less frequent in the vocabulary.\n",
    "\n",
    "**score=(freq_of_pair)/(freq_of_first_element√ófreq_of_second_element)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kKAlXUvhxC5Y"
   },
   "source": [
    "## 1.1 Tokenizer from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 615,
     "status": "ok",
     "timestamp": 1702700487200,
     "user": {
      "displayName": "Kean Chan",
      "userId": "05792587367281359063"
     },
     "user_tz": -480
    },
    "id": "lvotJZcyxMai",
    "outputId": "0ac5ef7c-98d0-41cb-9af6-16ae03ab44e9"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 615,
     "status": "ok",
     "timestamp": 1702700487200,
     "user": {
      "displayName": "Kean Chan",
      "userId": "05792587367281359063"
     },
     "user_tz": -480
    },
    "id": "lvotJZcyxMai",
    "outputId": "0ac5ef7c-98d0-41cb-9af6-16ae03ab44e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'the', 'Hugging', 'Face', 'Course', '.']\n",
      "['This', 'chapter', 'is', 'about', 'tokenization', '.']\n",
      "['This', 'section', 'shows', 'several', 'tokenizer', 'algorithms', '.']\n",
      "['Hopefully', ',', 'you', 'will', 'be', 'able', 'to', 'understand', 'how', 'they', 'are', 'trained', 'and', 'generate', 'tokens', '.']\n",
      "\n",
      "Final Word Frequency: defaultdict(<class 'int'>, {'This': 3, 'is': 2, 'the': 1, 'Hugging': 1, 'Face': 1, 'Course': 1, '.': 4, 'chapter': 1, 'about': 1, 'tokenization': 1, 'section': 1, 'shows': 1, 'several': 1, 'tokenizer': 1, 'algorithms': 1, 'Hopefully': 1, ',': 1, 'you': 1, 'will': 1, 'be': 1, 'able': 1, 'to': 1, 'understand': 1, 'how': 1, 'they': 1, 'are': 1, 'trained': 1, 'and': 1, 'generate': 1, 'tokens': 1})\n"
     ]
    }
   ],
   "source": [
    "corpus = [\n",
    "    \"This is the Hugging Face Course.\",\n",
    "    \"This chapter is about tokenization.\",\n",
    "    \"This section shows several tokenizer algorithms.\",\n",
    "    \"Hopefully, you will be able to understand how they are trained and generate tokens.\",\n",
    "]\n",
    "\n",
    "### get the frequency of each word ###\n",
    "word_freqs = defaultdict(int)\n",
    "for text in corpus:\n",
    "    words_with_offsets = tokenizer.backend_tokenizer.pre_tokenizer.pre_tokenize_str(text)\n",
    "    new_words = [word for word, offset in words_with_offsets]\n",
    "    print(new_words)\n",
    "    for word in new_words:\n",
    "        word_freqs[word] += 1\n",
    "\n",
    "print(f\"\\nFinal Word Frequency: {word_freqs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 522,
     "status": "ok",
     "timestamp": 1702700504613,
     "user": {
      "displayName": "Kean Chan",
      "userId": "05792587367281359063"
     },
     "user_tz": -480
    },
    "id": "FIHFIJwpxcbD",
    "outputId": "d0f83212-f6b0-4405-dc3f-c4b4cc64f039"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All alphabets: ['##a', '##b', '##c', '##d', '##e', '##f', '##g', '##h', '##i', '##k', '##l', '##m', '##n', '##o', '##p', '##r', '##s', '##t', '##u', '##v', '##w', '##y', '##z', ',', '.', 'C', 'F', 'H', 'T', 'a', 'b', 'c', 'g', 'h', 'i', 's', 't', 'u', 'w', 'y']\n"
     ]
    }
   ],
   "source": [
    "### split all word into alphabet ###\n",
    "alphabet = []\n",
    "for word in word_freqs.keys():\n",
    "    if word[0] not in alphabet:\n",
    "        alphabet.append(word[0])\n",
    "    for letter in word[1:]:\n",
    "        if f\"##{letter}\" not in alphabet:\n",
    "            alphabet.append(f\"##{letter}\")\n",
    "\n",
    "alphabet.sort()\n",
    "print(f'All alphabets: {alphabet}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 522,
     "status": "ok",
     "timestamp": 1702700504613,
     "user": {
      "displayName": "Kean Chan",
      "userId": "05792587367281359063"
     },
     "user_tz": -480
    },
    "id": "FIHFIJwpxcbD",
    "outputId": "d0f83212-f6b0-4405-dc3f-c4b4cc64f039"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Splitted Words: {'This': ['T', '##h', '##i', '##s'], 'is': ['i', '##s'], 'the': ['t', '##h', '##e'], 'Hugging': ['H', '##u', '##g', '##g', '##i', '##n', '##g'], 'Face': ['F', '##a', '##c', '##e'], 'Course': ['C', '##o', '##u', '##r', '##s', '##e'], '.': ['.'], 'chapter': ['c', '##h', '##a', '##p', '##t', '##e', '##r'], 'about': ['a', '##b', '##o', '##u', '##t'], 'tokenization': ['t', '##o', '##k', '##e', '##n', '##i', '##z', '##a', '##t', '##i', '##o', '##n'], 'section': ['s', '##e', '##c', '##t', '##i', '##o', '##n'], 'shows': ['s', '##h', '##o', '##w', '##s'], 'several': ['s', '##e', '##v', '##e', '##r', '##a', '##l'], 'tokenizer': ['t', '##o', '##k', '##e', '##n', '##i', '##z', '##e', '##r'], 'algorithms': ['a', '##l', '##g', '##o', '##r', '##i', '##t', '##h', '##m', '##s'], 'Hopefully': ['H', '##o', '##p', '##e', '##f', '##u', '##l', '##l', '##y'], ',': [','], 'you': ['y', '##o', '##u'], 'will': ['w', '##i', '##l', '##l'], 'be': ['b', '##e'], 'able': ['a', '##b', '##l', '##e'], 'to': ['t', '##o'], 'understand': ['u', '##n', '##d', '##e', '##r', '##s', '##t', '##a', '##n', '##d'], 'how': ['h', '##o', '##w'], 'they': ['t', '##h', '##e', '##y'], 'are': ['a', '##r', '##e'], 'trained': ['t', '##r', '##a', '##i', '##n', '##e', '##d'], 'and': ['a', '##n', '##d'], 'generate': ['g', '##e', '##n', '##e', '##r', '##a', '##t', '##e'], 'tokens': ['t', '##o', '##k', '##e', '##n', '##s']}\n"
     ]
    }
   ],
   "source": [
    "### insert special token and subword ###\n",
    "vocab = [\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"] + alphabet.copy()\n",
    "splits = {word: [c if i == 0 else f\"##{c}\" for i, c in enumerate(word)] for word in word_freqs.keys()}\n",
    "print(f'\\nSplitted Words: {splits}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 346,
     "status": "ok",
     "timestamp": 1702700508853,
     "user": {
      "displayName": "Kean Chan",
      "userId": "05792587367281359063"
     },
     "user_tz": -480
    },
    "id": "M5svp-f028FO",
    "outputId": "9af94a71-8447-411e-8449-675050eb69ac",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for each Pair: {('T', '##h'): 0.125, ('##h', '##i'): 0.03409090909090909, ('##i', '##s'): 0.02727272727272727, ('i', '##s'): 0.1, ('t', '##h'): 0.03571428571428571, ('##h', '##e'): 0.011904761904761904, ('H', '##u'): 0.1, ('##u', '##g'): 0.05, ('##g', '##g'): 0.0625, ('##g', '##i'): 0.022727272727272728, ('##i', '##n'): 0.01652892561983471, ('##n', '##g'): 0.022727272727272728, ('F', '##a'): 0.14285714285714285, ('##a', '##c'): 0.07142857142857142, ('##c', '##e'): 0.023809523809523808, ('C', '##o'): 0.07692307692307693, ('##o', '##u'): 0.046153846153846156, ('##u', '##r'): 0.022222222222222223, ('##r', '##s'): 0.022222222222222223, ('##s', '##e'): 0.004761904761904762, ('c', '##h'): 0.125, ('##h', '##a'): 0.017857142857142856, ('##a', '##p'): 0.07142857142857142, ('##p', '##t'): 0.07142857142857142, ('##t', '##e'): 0.013605442176870748, ('##e', '##r'): 0.026455026455026454, ('a', '##b'): 0.2, ('##b', '##o'): 0.038461538461538464, ('##u', '##t'): 0.02857142857142857, ('t', '##o'): 0.04395604395604396, ('##o', '##k'): 0.07692307692307693, ('##k', '##e'): 0.047619047619047616, ('##e', '##n'): 0.017316017316017316, ('##n', '##i'): 0.01652892561983471, ('##i', '##z'): 0.09090909090909091, ('##z', '##a'): 0.07142857142857142, ('##a', '##t'): 0.04081632653061224, ('##t', '##i'): 0.025974025974025976, ('##i', '##o'): 0.013986013986013986, ('##o', '##n'): 0.013986013986013986, ('s', '##e'): 0.031746031746031744, ('##e', '##c'): 0.023809523809523808, ('##c', '##t'): 0.07142857142857142, ('s', '##h'): 0.041666666666666664, ('##h', '##o'): 0.009615384615384616, ('##o', '##w'): 0.07692307692307693, ('##w', '##s'): 0.05, ('##e', '##v'): 0.047619047619047616, ('##v', '##e'): 0.047619047619047616, ('##r', '##a'): 0.047619047619047616, ('##a', '##l'): 0.02040816326530612, ('##z', '##e'): 0.023809523809523808, ('a', '##l'): 0.02857142857142857, ('##l', '##g'): 0.03571428571428571, ('##g', '##o'): 0.019230769230769232, ('##o', '##r'): 0.008547008547008548, ('##r', '##i'): 0.010101010101010102, ('##i', '##t'): 0.012987012987012988, ('##t', '##h'): 0.017857142857142856, ('##h', '##m'): 0.125, ('##m', '##s'): 0.1, ('H', '##o'): 0.038461538461538464, ('##o', '##p'): 0.038461538461538464, ('##p', '##e'): 0.023809523809523808, ('##e', '##f'): 0.047619047619047616, ('##f', '##u'): 0.2, ('##u', '##l'): 0.02857142857142857, ('##l', '##l'): 0.04081632653061224, ('##l', '##y'): 0.07142857142857142, ('y', '##o'): 0.07692307692307693, ('w', '##i'): 0.09090909090909091, ('##i', '##l'): 0.012987012987012988, ('b', '##e'): 0.047619047619047616, ('##b', '##l'): 0.07142857142857142, ('##l', '##e'): 0.006802721088435374, ('u', '##n'): 0.09090909090909091, ('##n', '##d'): 0.06818181818181818, ('##d', '##e'): 0.011904761904761904, ('##s', '##t'): 0.014285714285714285, ('##t', '##a'): 0.02040816326530612, ('##a', '##n'): 0.012987012987012988, ('h', '##o'): 0.07692307692307693, ('##e', '##y'): 0.023809523809523808, ('a', '##r'): 0.022222222222222223, ('##r', '##e'): 0.005291005291005291, ('t', '##r'): 0.015873015873015872, ('##a', '##i'): 0.012987012987012988, ('##n', '##e'): 0.008658008658008658, ('##e', '##d'): 0.011904761904761904, ('a', '##n'): 0.01818181818181818, ('g', '##e'): 0.047619047619047616, ('##n', '##s'): 0.00909090909090909}\n"
     ]
    }
   ],
   "source": [
    " ### compute score for merging ###\n",
    "def compute_pair_scores(splits):\n",
    "    letter_freqs = defaultdict(int)\n",
    "    pair_freqs = defaultdict(int)\n",
    "\n",
    "    for word, freq in word_freqs.items():\n",
    "        split = splits[word]\n",
    "        if len(split) == 1:\n",
    "            letter_freqs[split[0]] += freq\n",
    "            continue\n",
    "        for i in range(len(split) - 1):\n",
    "            pair = (split[i], split[i + 1])\n",
    "            letter_freqs[split[i]] += freq\n",
    "            pair_freqs[pair] += freq\n",
    "        letter_freqs[split[-1]] += freq\n",
    "\n",
    "    scores = {\n",
    "        pair: freq / (letter_freqs[pair[0]] * letter_freqs[pair[1]])\n",
    "        for pair, freq in pair_freqs.items()\n",
    "    }\n",
    "    return scores\n",
    "\n",
    "pair_scores = compute_pair_scores(splits)\n",
    "print(f'Scores for each Pair: {pair_scores}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 327,
     "status": "ok",
     "timestamp": 1702700639209,
     "user": {
      "displayName": "Kean Chan",
      "userId": "05792587367281359063"
     },
     "user_tz": -480
    },
    "id": "dkcQKo1r2-c5",
    "outputId": "40267815-b5c2-4148-cdbc-8a8cb211cf65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a', '##b') 0.2\n",
      "['ab', '##o', '##u', '##t']\n"
     ]
    }
   ],
   "source": [
    "### finding pair with best score ###\n",
    "best_pair = \"\"\n",
    "max_score = None\n",
    "for pair, score in pair_scores.items():\n",
    "    if max_score is None or max_score < score:\n",
    "        best_pair = pair\n",
    "        max_score = score\n",
    "\n",
    "print(best_pair, max_score)\n",
    "vocab.append(\"ab\")\n",
    "\n",
    "### merge pair ###\n",
    "def merge_pair(a, b, splits):\n",
    "    for word in word_freqs:\n",
    "        split = splits[word]\n",
    "        if len(split) == 1:\n",
    "            continue\n",
    "        i = 0\n",
    "        while i < len(split) - 1:\n",
    "            if split[i] == a and split[i + 1] == b:\n",
    "                merge = a + b[2:] if b.startswith(\"##\") else a + b\n",
    "                split = split[:i] + [merge] + split[i + 2 :]\n",
    "            else:\n",
    "                i += 1\n",
    "        splits[word] = split\n",
    "    return splits\n",
    "\n",
    "splits = merge_pair(\"a\", \"##b\", splits)\n",
    "print(splits[\"about\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 350,
     "status": "ok",
     "timestamp": 1702700824732,
     "user": {
      "displayName": "Kean Chan",
      "userId": "05792587367281359063"
     },
     "user_tz": -480
    },
    "id": "bc6S6Tj93sh8",
    "outputId": "1afabfb5-50ce-4752-f07f-2776d62a5c4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Vocab: ['[PAD]', '[UNK]', '[CLS]', '[SEP]', '[MASK]', '##a', '##b', '##c', '##d', '##e', '##f', '##g', '##h', '##i', '##k', '##l', '##m', '##n', '##o', '##p', '##r', '##s', '##t', '##u', '##v', '##w', '##y', '##z', ',', '.', 'C', 'F', 'H', 'T', 'a', 'b', 'c', 'g', 'h', 'i', 's', 't', 'u', 'w', 'y', 'ab', '##fu', 'Fa', 'Fac', '##ct', '##ful', '##full', '##fully', 'Th', 'ch', '##hm', 'cha', 'chap', 'chapt', '##thm', 'Hu', 'Hug', 'Hugg', 'sh', 'th', 'is', '##thms', '##za', '##zat', '##ut']\n"
     ]
    }
   ],
   "source": [
    "### keep looping to merge more pair\n",
    "vocab_size = 70\n",
    "while len(vocab) < vocab_size:\n",
    "    scores = compute_pair_scores(splits)\n",
    "    best_pair, max_score = \"\", None\n",
    "    for pair, score in scores.items():\n",
    "        if max_score is None or max_score < score:\n",
    "            best_pair = pair\n",
    "            max_score = score\n",
    "    splits = merge_pair(*best_pair, splits)\n",
    "    new_token = (\n",
    "        best_pair[0] + best_pair[1][2:]\n",
    "        if best_pair[1].startswith(\"##\")\n",
    "        else best_pair[0] + best_pair[1]\n",
    "    )\n",
    "    vocab.append(new_token)\n",
    "\n",
    "print(f'Final Vocab: {vocab}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 357,
     "status": "ok",
     "timestamp": 1702700889155,
     "user": {
      "displayName": "Kean Chan",
      "userId": "05792587367281359063"
     },
     "user_tz": -480
    },
    "id": "vFVyHHe84Vbi",
    "outputId": "afb79be0-eda1-40a3-8a77-dc2f2078019b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hugg', '##i', '##n', '##g']\n",
      "['[UNK]']\n"
     ]
    }
   ],
   "source": [
    "### ro encode a word ###\n",
    "def encode_word(word):\n",
    "    tokens = []\n",
    "    while len(word) > 0:\n",
    "        i = len(word)\n",
    "        while i > 0 and word[:i] not in vocab:\n",
    "            i -= 1\n",
    "        if i == 0:\n",
    "            return [\"[UNK]\"]\n",
    "        tokens.append(word[:i])\n",
    "        word = word[i:]\n",
    "        if len(word) > 0:\n",
    "            word = f\"##{word}\"\n",
    "    return tokens\n",
    "\n",
    "print(encode_word(\"Hugging\"))\n",
    "print(encode_word(\"HOgging\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5jaQsRw4xC-x"
   },
   "source": [
    "## 1.2 Tokenizer Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1961,
     "status": "ok",
     "timestamp": 1665133698134,
     "user": {
      "displayName": "Kean Chan",
      "userId": "05792587367281359063"
     },
     "user_tz": -480
    },
    "id": "ER4dwYJDoZFU",
    "outputId": "c0ca8f0c-4610-4dc2-f386-09be4d2f139f"
   },
   "outputs": [],
   "source": [
    "### data processing\n",
    "MAX_LEN = 64\n",
    "\n",
    "### loading all data into memory\n",
    "corpus_movie_conv = '../../data/movie_conversations.txt'\n",
    "corpus_movie_lines = '../../data/movie_lines.txt'\n",
    "with open(corpus_movie_conv, 'r', encoding='iso-8859-1') as c:\n",
    "    conv = c.readlines()\n",
    "with open(corpus_movie_lines, 'r', encoding='iso-8859-1') as l:\n",
    "    lines = l.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1961,
     "status": "ok",
     "timestamp": 1665133698134,
     "user": {
      "displayName": "Kean Chan",
      "userId": "05792587367281359063"
     },
     "user_tz": -480
    },
    "id": "ER4dwYJDoZFU",
    "outputId": "c0ca8f0c-4610-4dc2-f386-09be4d2f139f"
   },
   "outputs": [],
   "source": [
    "### splitting text using special lines\n",
    "lines_dic = {}\n",
    "for line in lines:\n",
    "    objects = line.split(\" +++$+++ \")\n",
    "    lines_dic[objects[0]] = objects[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'L1045': 'They do not!\\n',\n",
       " 'L1044': 'They do to!\\n',\n",
       " 'L985': 'I hope so.\\n',\n",
       " 'L984': 'She okay?\\n',\n",
       " 'L925': \"Let's go.\\n\",\n",
       " 'L924': 'Wow\\n',\n",
       " 'L872': \"Okay -- you're gonna need to learn how to lie.\\n\",\n",
       " 'L871': 'No\\n',\n",
       " 'L870': 'I\\'m kidding.  You know how sometimes you just become this \"persona\"?  And you don\\'t know how to quit?\\n',\n",
       " 'L869': 'Like my fear of wearing pastels?\\n',\n",
       " 'L868': 'The \"real you\".\\n',\n",
       " 'L867': 'What good stuff?\\n',\n",
       " 'L866': \"I figured you'd get to the good stuff eventually.\\n\",\n",
       " 'L865': 'Thank God!  If I had to hear one more story about your coiffure...\\n',\n",
       " 'L864': \"Me.  This endless ...blonde babble. I'm like, boring myself.\\n\",\n",
       " 'L863': 'What crap?\\n',\n",
       " 'L862': 'do you listen to this crap?\\n',\n",
       " 'L861': 'No...\\n',\n",
       " 'L860': 'Then Guillermo says, \"If you go any lighter, you\\'re gonna look like an extra on 90210.\"\\n',\n",
       " 'L699': 'You always been this selfish?\\n',\n",
       " 'L698': 'But\\n',\n",
       " 'L697': \"Then that's all you had to say.\\n\",\n",
       " 'L696': 'Well, no...\\n',\n",
       " 'L695': \"You never wanted to go out with 'me, did you?\\n\",\n",
       " 'L694': 'I was?\\n',\n",
       " 'L693': 'I looked for you back at the party, but you always seemed to be \"occupied\".\\n',\n",
       " 'L663': 'Tons\\n',\n",
       " 'L662': 'Have fun tonight?\\n',\n",
       " 'L578': 'I believe we share an art instructor\\n',\n",
       " 'L577': 'You know Chastity?\\n',\n",
       " 'L576': 'Looks like things worked out tonight, huh?\\n',\n",
       " 'L575': 'Hi.\\n',\n",
       " 'L407': \"Who knows?  All I've ever heard her say is that she'd dip before dating a guy that smokes.\\n\",\n",
       " 'L406': \"So that's the kind of guy she likes? Pretty ones?\\n\",\n",
       " 'L405': \"Lesbian?  No. I found a picture of Jared Leto in one of her drawers, so I'm pretty sure she's not harboring same-sex tendencies.\\n\",\n",
       " 'L404': \"She's not a...\\n\",\n",
       " 'L403': \"I'm workin' on it. But she doesn't seem to be goin' for him.\\n\",\n",
       " 'L402': \"I really, really, really wanna go, but I can't.  Not unless my sister goes.\\n\",\n",
       " 'L401': 'Sure have.\\n',\n",
       " 'L368': \"Eber's Deep Conditioner every two days. And I never, ever use a blowdryer without the diffuser attachment.\\n\",\n",
       " 'L367': 'How do you get your hair to look like that?\\n',\n",
       " 'L366': \"You're sweet.\\n\",\n",
       " 'L365': 'You have my word.  As a gentleman\\n',\n",
       " 'L364': \"I counted on you to help my cause. You and that thug are obviously failing. Aren't we ever going on our date?\\n\",\n",
       " 'L363': 'You got something on your mind?\\n',\n",
       " 'L281': 'Where?\\n',\n",
       " 'L280': 'There.\\n',\n",
       " 'L277': \"Well, there's someone I think might be --\\n\",\n",
       " 'L276': 'How is our little Find the Wench A Date plan progressing?\\n',\n",
       " 'L275': 'Forget French.\\n',\n",
       " 'L274': \"That's because it's such a nice one.\\n\",\n",
       " 'L273': \"I don't want to know how to say that though.  I want to know useful things. Like where the good stores are.  How much does champagne cost?  Stuff like Chat.  I have never in my life had to point out my head to someone.\\n\",\n",
       " 'L272': \"Right.  See?  You're ready for the quiz.\\n\",\n",
       " 'L271': \"C'esc ma tete. This is my head\\n\",\n",
       " 'L208': 'Let me see what I can do.\\n',\n",
       " 'L207': 'Gosh, if only we could find Kat a boyfriend...\\n',\n",
       " 'L206': \"That's a shame.\\n\",\n",
       " 'L205': 'Unsolved mystery.  She used to be really popular when she started high school, then it was just like she got sick of it or something.\\n',\n",
       " 'L204': 'Why?\\n',\n",
       " 'L203': 'Seems like she could get a date easy enough...\\n',\n",
       " 'L202': \"The thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does.\\n\",\n",
       " 'L201': 'Cameron.\\n',\n",
       " 'L200': \"No, no, it's my fault -- we didn't have a proper introduction ---\\n\",\n",
       " 'L199': 'Forget it.\\n',\n",
       " 'L198': \"You're asking me out.  That's so cute. What's your name again?\\n\",\n",
       " 'L197': \"Okay... then how 'bout we try out some French cuisine.  Saturday?  Night?\\n\",\n",
       " 'L196': 'Not the hacking and gagging and spitting part.  Please.\\n',\n",
       " 'L195': \"Well, I thought we'd start with pronunciation, if that's okay with you.\\n\",\n",
       " 'L194': 'Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.\\n',\n",
       " 'L953': 'I did.\\n',\n",
       " 'L952': \"You think you ' re the only sophomore at the prom?\\n\",\n",
       " 'L660': \"I don't have to be home 'til two.\\n\",\n",
       " 'L659': 'I have to be home in twenty minutes.\\n',\n",
       " 'L600': \"All I know is -- I'd give up my private line to go out with a guy like Joey.\\n\",\n",
       " 'L599': \"Sometimes I wonder if the guys we're supposed to want to go out with are the ones we actually want to go out with, you know?\\n\",\n",
       " 'L598': \"Bianca, I don't think the highlights of dating Joey Dorsey are going to include door-opening and coat-holding.\\n\",\n",
       " 'L597': \"Combination.  I don't know -- I thought he'd be different.  More of a gentleman...\\n\",\n",
       " 'L596': 'Is he oily or dry?\\n',\n",
       " 'L595': \"He practically proposed when he found out we had the same dermatologist. I mean. Dr. Bonchowski is great an all, but he's not exactly relevant party conversation.\\n\",\n",
       " 'L580': 'Would you mind getting me a drink, Cameron?\\n',\n",
       " 'L579': 'Great\\n',\n",
       " 'L573': 'Joey.\\n',\n",
       " 'L572': 'Who?\\n',\n",
       " 'L571': 'Where did he go?  He was just here.\\n',\n",
       " 'L51': 'You might wanna think about it\\n',\n",
       " 'L50': 'No.\\n',\n",
       " 'L49': 'Did you change your hair?\\n',\n",
       " 'L760': \"You know the deal.  I can ' t go if Kat doesn't go --\\n\",\n",
       " 'L759': 'Listen, I want to talk to you about the prom.\\n',\n",
       " 'L758': \"You're concentrating awfully hard considering it's gym class.\\n\",\n",
       " 'L757': 'Hi, Joey.\\n',\n",
       " 'L756': 'Hey, sweet cheeks.\\n',\n",
       " 'L593': \"My agent says I've got a good shot at being the Prada guy next year.\\n\",\n",
       " 'L592': 'Neat...\\n',\n",
       " 'L591': \"It's a gay cruise line, but I'll be, like, wearing a uniform and stuff.\\n\",\n",
       " 'L590': 'Queen Harry?\\n',\n",
       " 'L589': 'So yeah, I\\'ve got the Sears catalog thing going -- and the tube sock gig \" that\\'s gonna be huge.  And then I\\'m up for an ad for Queen Harry next week.\\n',\n",
       " 'L397': 'Hopefully.\\n',\n",
       " 'L396': \"Exactly  So, you going to Bogey Lowenbrau's thing on Saturday?\\n\",\n",
       " 'L395': 'Expensive?\\n',\n",
       " 'L394': \"It's more\\n\",\n",
       " 'L1052': 'Perm?\\n',\n",
       " 'L1051': 'Patrick -- is that- a.\\n',\n",
       " 'L1022': \"It's just you.\\n\",\n",
       " 'L1021': 'Is that woman a complete fruit-loop or is it just me?\\n',\n",
       " 'L1011': 'No! I just wanted\\n',\n",
       " 'L1010': 'What? To completely damage me?  To send me to therapy forever? What?\\n',\n",
       " 'L1009': 'I just wanted --\\n',\n",
       " 'L1008': 'You set me up.\\n',\n",
       " 'L1007': 'Let go!\\n',\n",
       " 'L983': 'So did you\\n',\n",
       " 'L982': 'You looked beautiful last night, you know.\\n',\n",
       " 'L914': \"I guess I'll never know, will I?\\n\",\n",
       " 'L913': \"Not all experiences are good, Bianca. You can't always trust the people you want to.\\n\",\n",
       " 'L912': \"God, you're just like him! Just keep me locked away in the dark, so I can't experience anything for myself\\n\",\n",
       " 'L911': 'I guess I thought I was protecting you.\\n',\n",
       " 'L910': \"I'm not stupid enough to repeat your mistakes.\\n\",\n",
       " 'L909': \"That's not\\n\",\n",
       " 'L908': \"No. you didn't!  If you really thought I could make my own decisions, you would've let me go out with him instead of helping Daddy hold me hostage.\\n\",\n",
       " 'L907': 'I wanted to let you make up your own mind about him.\\n',\n",
       " 'L906': \"Why didn't you tell me?\\n\",\n",
       " 'L905': 'After that, I swore I\\'d never do anything just because \"everyone else\" was doing it.  And I haven\\'t since. Except for Bogey\\'s party, and my stunning gastro-intestinal display --\\n',\n",
       " 'L904': 'But\\n',\n",
       " 'L903': \"Just once.  Afterwards, I told him I didn't want to anymore.  I wasn't ready. He got pissed.  Then he broke up with me.\\n\",\n",
       " 'L902': 'You did what?\\n',\n",
       " 'L901': 'He said everyone was doing it.  So I did it.\\n',\n",
       " 'L900': 'As in...\\n',\n",
       " 'L899': 'Now I do.  Back then, was a different story.\\n',\n",
       " 'L898': 'But you hate Joey\\n',\n",
       " 'L897': 'He was, like, a total babe\\n',\n",
       " 'L896': 'Why?\\n',\n",
       " 'L895': 'In 9th.  For a month\\n',\n",
       " 'L894': 'What?\\n',\n",
       " 'L893': 'Joey never told you we went out, did he?\\n',\n",
       " 'L892': \"I wish I had that luxury. I'm the only sophomore that got asked to the prom and I can't go, because you won ' t.\\n\",\n",
       " 'L891': \"I do care. But I'm a firm believer in doing something for your own reasons, not someone else ' s .\\n\",\n",
       " 'L890': 'Like you care.\\n',\n",
       " 'L889': \"Listen, I know you hate having to sit home because I'm not Susie High School.\\n\",\n",
       " 'L656': \"You're welcome.\\n\",\n",
       " 'L655': \"I don't get you.  You act like you're too good for any of this, and then you go totally apeshit when you get here.\\n\",\n",
       " 'L602': \"I really don't think I need any social advice from you right now.\\n\",\n",
       " 'L601': 'Bianca, I need to talk to you -- I need to tell you --\\n',\n",
       " 'L543': 'Can we go now?\\n',\n",
       " 'L542': 'You are so completely unbalanced.\\n',\n",
       " 'L533': \"Yeah, he's your freak friend Mandella's boyfriend.  I guess since I'm not allowed to go out, I should obsess over a dead guy, too.\\n\",\n",
       " 'L532': \"It's Shakespeare.  Maybe you've heard of him?\\n\",\n",
       " 'L531': \"Like I'm supposed to know what that even means.\\n\",\n",
       " 'L530': \"At least I'm not a clouted fen- sucked hedge-pig.\\n\",\n",
       " 'L529': \"Can't you forget for just one night that you're completely wretched?\\n\",\n",
       " 'L527': \"Bogey Lowenstein's party is normal, but you're too busy listening to Bitches Who Need Prozac to know that.\\n\",\n",
       " 'L526': \"What's normal?\\n\",\n",
       " 'L525': \"You're ruining my life'  Because you won't be normal, I can't be normal.\\n\",\n",
       " 'L445': \"I think you're a freak.  I think you do this to torture me.  And I think you suck.\\n\",\n",
       " 'L444': 'What do you think?\\n',\n",
       " 'L443': \"Oh, I thought you might have a date  I don't know why I'm bothering to ask, but are you going to Bogey Lowenstein's party Saturday night?\\n\",\n",
       " 'L442': \"It means that Gigglepuss is playing at Club Skunk and we're going.\\n\",\n",
       " 'L441': \"Oh my God, does this mean you're becoming normal?\\n\",\n",
       " 'L320': 'Can you at least start wearing a bra?\\n',\n",
       " 'L319': \"I have the potential to smack the crap out of you if you don't get out of my way.\\n\",\n",
       " 'L165': 'Nowhere... Hi, Daddy.\\n',\n",
       " 'L164': \"Where've you been?\\n\",\n",
       " 'L923': \"I have a date, Daddy.  And he ' s not a captain of oppression like some men we know.\\n\",\n",
       " 'L922': \"I'm missing something.\\n\",\n",
       " 'L884': \"Fine.  I see that I'm a prisoner in my own house.  I'm not a daughter. I'm a possession!\\n\",\n",
       " 'L883': \"You're not going unless your sister goes.  End of story.\\n\",\n",
       " 'L882': 'He\\'s not a \"hot rod\".  Whatever that is.\\n',\n",
       " 'L881': \"It's that hot rod Joey, right? That ' s who you want me to bend my rules for?\\n\",\n",
       " 'L880': 'No, but\\n',\n",
       " 'L879': 'The prom?  Kat has a date?\\n',\n",
       " 'L878': \"Daddy, I want to discuss the prom with you. It's tomorrow night --\\n\",\n",
       " 'L546': \"Because she'll scare them away.\\n\",\n",
       " 'L545': 'Why?\\n',\n",
       " 'L544': \"Promise me you won't talk to any boys unless your sister is present.\\n\",\n",
       " 'L540': 'Just for a minute\\n',\n",
       " 'L539': 'Daddy, no!\\n',\n",
       " 'L538': 'Wear the belly before you go.\\n',\n",
       " 'L537': \"It's just a party. Daddy.\\n\",\n",
       " 'L536': \"Oh, God.  It's starting.\\n\",\n",
       " 'L524': \"If Kat's not going, you're not going.\\n\",\n",
       " 'L523': 'Daddy, people expect me to be there!\\n',\n",
       " 'L521': 'It\\'s just a party. Daddy, but I knew you\\'d forbid me to go since \"Gloria Steinem\" over there isn\\'t going --\\n',\n",
       " 'L520': 'Otherwise known as an orgy?\\n',\n",
       " 'L519': 'If you must know, we were attempting to go to a small study group of friends.\\n',\n",
       " 'L518': \"And where're you going?\\n\",\n",
       " 'L517': 'Daddy, I --\\n',\n",
       " 'L190': 'Exactly my point\\n',\n",
       " 'L189': \"But she doesn't want to date.\\n\",\n",
       " 'L183': \"But it's not fair -- she's a mutant, Daddy!\\n\",\n",
       " 'L182': \"Then neither will you.  And I'll get to sleep at night.\\n\",\n",
       " 'L181': 'What if she never starts dating?\\n',\n",
       " 'L180': \"No! You're not dating until your sister starts dating.  End of discussion.\\n\",\n",
       " 'L179': \"Now don't get upset. Daddy, but there's this boy... and I think he might ask...\\n\",\n",
       " 'L463': \"Just sent 'em through.\\n\",\n",
       " 'L462': 'Padua girls.  One tall, decent body. The other one kinda short and undersexed?\\n',\n",
       " 'L461': 'Never\\n',\n",
       " 'L460': 'Fan of a fan.  You see a couple of minors come in?\\n',\n",
       " 'L459': \"Didn't have you pegged for a Gigglepuss fan.  Aren't they a little too pre-teen belly-button ring for you?\\n\",\n",
       " 'L458': 'Always a pleasure, Brucie.\\n',\n",
       " 'L779': \"Best case scenario, you're back on the payroll for awhile.\\n\",\n",
       " 'L778': 'You humiliated the woman! Sacrifice yourself on the altar of dignity and even the score.\\n',\n",
       " 'L586': \"No, I ' m not.\\n\",\n",
       " 'L585': \"Buttholus extremus.  But hey, you're making progress.\\n\",\n",
       " 'L584': \"The hell is that?  What kind of 'guy just picks up a girl and carries her away while you're talking to her?\\n\",\n",
       " 'L583': 'Extremely unfortunate maneuver.\\n',\n",
       " 'L500': \"Hell, I've just been going over the whole thing in my head and -\\n\",\n",
       " 'L499': 'You told me that part already.\\n',\n",
       " 'L433': \"It's her favorite band.\\n\",\n",
       " 'L432': 'Assail your ears for one night.\\n',\n",
       " 'L425': \"Okay!  I wasn't sure\\n\",\n",
       " 'L424': \"He's pretty!\\n\",\n",
       " 'L419': 'Dead at forty-one.\\n',\n",
       " 'L418': 'Her favorite uncle\\n',\n",
       " 'L417': \"It's a lung cancer issue\\n\",\n",
       " 'L416': 'Number one.  She hates smokers\\n',\n",
       " 'L391': \"Are you kidding?  He'll piss himself with joy.  He's the ultimate kiss ass.\\n\",\n",
       " 'L390': 'Will Bogey get bent?\\n',\n",
       " 'L389': \"In that case, we'll need to make it a school-wide blow out.\\n\",\n",
       " 'L388': 'This is it.  A golden opportunity. Patrick can ask Katarina to the party.\\n',\n",
       " 'L245': \"Like we had a choice?  Besides -- when you let the enemy think he's orchestrating the battle, you're in a position of power. We let him pretend he's calling the shots, and while he's busy setting up the plan, you have time to woo Bianca.\\n\",\n",
       " 'L244': 'You got him involved?\\n',\n",
       " 'L225': \"Hey -- I've gotta have a few clients when I get to Wall Street.\\n\",\n",
       " 'L224': 'I thought you hated those people.\\n',\n",
       " 'L223': \"You know, if you do go out with Bianca, you'd be set.  You'd outrank everyone. Strictly A-list.  With me by your side.\\n\",\n",
       " 'L222': \"That's what I just said\\n\",\n",
       " 'L221': \"Did she actually say she'd go out with you?\\n\",\n",
       " 'L220': \"Forget his reputation.  Do you think we've got a plan or not?\\n\",\n",
       " 'L219': \"I'm serious, man, he's whacked.  He sold his own liver on the black market so he could buy new speakers.\\n\",\n",
       " 'L218': 'They always let felons sit in on Honors Biology?\\n',\n",
       " 'L217': \"No kidding.  He's a criminal.  I heard he lit a state trooper on fire.  He just got out of Alcatraz...\\n\",\n",
       " 'L216': 'He seems like he thrives on danger\\n',\n",
       " 'L215': \"What makes you think he'll do it?\\n\",\n",
       " 'L213': 'You wanna go out with him?\\n',\n",
       " 'L212': 'What about him?\\n',\n",
       " 'L211': \"Unlikely, but even so, she still can't go out with you.  So what's the point?\\n\",\n",
       " 'L210': 'I teach her French, get to know her, dazzle her with charm and she falls in love with me.\\n',\n",
       " 'L159': 'The mewling, rampalian wretch herself.\\n',\n",
       " 'L158': \"That's her?  Bianca's sister?\\n\",\n",
       " 'L157': 'Yeah, just a minor encounter with the shrew.\\n',\n",
       " 'L147': 'You could consecrate with her, my friend.\\n',\n",
       " 'L146': \"You mean I'd get a chance to talk to her?\\n\",\n",
       " 'L145': 'Guess who just signed up for a tutor?\\n',\n",
       " 'L144': \"Sure do ... my Mom's from Canada\\n\",\n",
       " 'L143': 'You know French?\\n',\n",
       " 'L142': \"Joey Dorsey?  Perma-shit-grin.  I wish I could say he's a moron, but he's number twelve in the class.  And a model.  Mostly regional stuff, but he's rumored to have a big tube sock ad coming out.\\n\",\n",
       " 'L141': 'He always have that shit-eating grin?\\n',\n",
       " 'L140': \"Because they're bred to.  Their mothers liked guys like that, and their grandmothers before them. Their gene pool is rarely diluted.\\n\",\n",
       " 'L139': 'Why do girls like that always like guys like that?\\n',\n",
       " 'L92': \"I could start with your haircut, but it doesn't matter.  She's not allowed to date until her older sister does.  And that's an impossibility.\\n\",\n",
       " 'L91': 'Why not?\\n',\n",
       " 'L90': \"Bianca Stratford.  Sophomore. Don't even think about it\\n\",\n",
       " 'L89': 'Who is she?\\n',\n",
       " 'L88': 'You burn, you pine, you perish?\\n',\n",
       " 'L87': 'That girl -- I --\\n',\n",
       " 'L78': 'Yeah, but these guys have never seen a horse.  They just jack off to Clint Eastwood.\\n',\n",
       " 'L77': \"That I'm used to.\\n\",\n",
       " 'L74': 'Couple thousand. Most of them evil\\n',\n",
       " 'L73': 'How many people go here?\\n',\n",
       " 'L72': 'Get out!\\n',\n",
       " 'L71': 'Thirty-two.\\n',\n",
       " 'L70': 'How many people were in your old school?\\n',\n",
       " 'L69': \"Yeah.  A couple.  We're outnumbered by the cows, though.\\n\",\n",
       " 'L68': 'I was kidding. People actually live there?\\n',\n",
       " 'L67': \"North, actually.  How'd you   ?\\n\",\n",
       " 'L66': 'So -- which Dakota you from?\\n',\n",
       " 'L65': \"C'mon.  I'm supposed to give you the tour.\\n\",\n",
       " 'L64': 'So they tell me...\\n',\n",
       " 'L63': 'You the new guy?\\n',\n",
       " 'L781': 'You get the girl.\\n',\n",
       " 'L780': \"What's the worst?\\n\",\n",
       " 'L745': 'Where?\\n',\n",
       " 'L744': 'She kissed me.\\n',\n",
       " 'L743': \"You makin' any headway?\\n\",\n",
       " 'L741': \"She just needs time to cool off I'll give it a day.\\n\",\n",
       " 'L740': \"She hates you with the fire of a thousand suns .  That's a direct quote\\n\",\n",
       " 'L726': \"I don ' t know.  I decided not to nail her when she was too drunk to remember it.\\n\",\n",
       " 'L725': \"What'd you do to her?\\n\",\n",
       " 'L625': 'Then, go get her\\n',\n",
       " 'L624': 'Sure\\n',\n",
       " 'L623': 'Cameron -- do you like the girl?\\n',\n",
       " 'L622': \"She's partial to Joey, not me\\n\",\n",
       " 'L621': \"What 're you talking about?\\n\",\n",
       " 'L620': \"It's off. The whole thing.\\n\",\n",
       " 'L619': \"Cameron, I'm a little busy\\n\",\n",
       " 'L431': \"Don't make me do it, man\\n\",\n",
       " 'L430': 'Gigglepuss is playing there tomorrow night.\\n',\n",
       " 'L427': \"So what does that give me?  I'm supposed to buy her some noodles and a book and sit around listening to chicks who can't play their instruments?\\n\",\n",
       " 'L426': 'Okay -- Likes:  Thai food, feminist prose, and \"angry, stinky girl music of the indie-rock persuasion\".\\n',\n",
       " 'L412': \"I've retrieved certain pieces of information on Miss Katarina Stratford I think you'll find helpful.\\n\",\n",
       " 'L411': \"What've you got for me?\\n\",\n",
       " 'L386': \"Yeah -- we'll see.\\n\",\n",
       " 'L385': 'And he means that strictly in a non- prison-movie type of way.\\n',\n",
       " 'L558': 'And why would I do that?\\n',\n",
       " 'L557': 'Leave my sister alone.\\n',\n",
       " 'L556': 'Your sister here?\\n',\n",
       " 'L555': 'Away.\\n',\n",
       " 'L554': 'Where ya goin?\\n',\n",
       " 'L336': 'Not at all\\n',\n",
       " 'L335': 'Hey -- do you mind?\\n',\n",
       " 'L150': \"They're running the rest of me next month.\\n\",\n",
       " 'L149': 'Yeah, and I noticed the only part of you featured in your big Kmart spread was your elbow.  Tough break.\\n',\n",
       " 'L148': \"The vintage look is over, Kat. Haven't you been reading your Sassy?\\n\",\n",
       " 'L748': \"Enough with the Barbie n' Ken shit. I know.\\n\",\n",
       " 'L747': \"I don't know, Dorsey. ..the limo.-the flowers.  Another hundred for the tux --\\n\",\n",
       " 'L609': 'Get her to act like a human\\n',\n",
       " 'L608': 'Do what?\\n',\n",
       " 'L607': \"How'd you do it?\\n\",\n",
       " 'L606': \"A deal's a deal.\\n\",\n",
       " 'L605': \"It's about time.\\n\",\n",
       " 'L358': 'Forget her sister, then.\\n',\n",
       " 'L357': 'Forget it.\\n',\n",
       " 'L356': 'A hundred bucks a date.\\n',\n",
       " 'L355': 'What?\\n',\n",
       " 'L354': 'I just upped my price\\n',\n",
       " 'L352': 'I got her under control. She just acts crazed in public to keep up the image.\\n',\n",
       " 'L351': \"Watching the bitch trash my car doesn't count as a date.\\n\",\n",
       " 'L350': \"I'm on it\\n\",\n",
       " 'L349': 'When I shell out fifty, I expect results.\\n',\n",
       " 'L301': \"Fifty, and you've got your man.\\n\",\n",
       " 'L300': \"Take it or leave it.  This isn't a negotiation.\\n\",\n",
       " 'L299': 'Fine, thirty.\\n',\n",
       " 'L298': \"I can't take a girl like that out on twenty bucks.\\n\",\n",
       " 'L297': 'How much?\\n',\n",
       " 'L296': \"I can't date her sister until that one gets a boyfriend.  And that's the catch. She doesn't want a boyfriend.\\n\",\n",
       " 'L295': \"You're gonna pay me to take out some girl?\\n\",\n",
       " 'L294': 'You got it, Verona.  I pick up the tab, you do the honors.\\n',\n",
       " 'L292': \"But you'd go out with her if you had the cake?\\n\",\n",
       " 'L291': 'You need money to take a girl out\\n',\n",
       " 'L290': 'You just said\\n',\n",
       " 'L289': \"Sure, Sparky.  I'll get right on it.\\n\",\n",
       " 'L288': 'Yeah, whatever.  I want you to go out with her.\\n',\n",
       " 'L287': 'Two legs, nice rack...\\n',\n",
       " 'L286': 'What do you think?\\n',\n",
       " 'L285': 'Yeah\\n',\n",
       " 'L509': \"Hey -- it's all for the higher good right?\\n\",\n",
       " 'L508': \"You better not fuck this up.  I'm heavily invested.\\n\",\n",
       " 'L505': 'What?  We took bathes together when we were kids.\\n',\n",
       " 'L504': 'You and Verona?\\n',\n",
       " 'L503': \"Uh,  yeah.  We're old friend*\\n\",\n",
       " 'L502': \"I hear you're helpin' Verona.\\n\",\n",
       " 'L240': \"So what you need to do is recruit a guy who'll go out with her.  Someone who's up for the job.\\n\",\n",
       " 'L239': 'Does this conversation have a purpose?\\n',\n",
       " 'L238': \"But she can't go out with you because her sister is this insane head case and no one will go out with her. right?\\n\",\n",
       " 'L236': \"We're not.\\n\",\n",
       " 'L235': \"Well, actually, I thought I'd run an idea by you.  You know, just to see if you're interested.\\n\",\n",
       " 'L234': \"We don't chat.\\n\",\n",
       " 'L233': 'Nope - just came by to chat\\n',\n",
       " 'L232': 'Are you lost?\\n',\n",
       " 'L231': 'Hey.\\n',\n",
       " 'L949': \"Oh, honey -- tell me we haven't' progressed to full-on hallucinations.\\n\",\n",
       " 'L948': 'William - he asked me to meet him here.\\n',\n",
       " 'L947': 'Who?\\n',\n",
       " 'L946': 'Have you seen him?\\n',\n",
       " 'L755': 'Oh, good.  Something new and different for us.\\n',\n",
       " 'L754': \"You ' re looking at this from the wrong perspective.  We're making a statement.\\n\",\n",
       " 'L753': \"Okay, okay, we won't go.  It's not like I have a dress anyway\\n\",\n",
       " 'L752': 'Listen to you!  You sound like Betty, all pissed off because Archie is taking Veronica.\\n',\n",
       " 'L751': \"Well, I guess we're not, since we don't have dates .\\n\",\n",
       " 'L750': 'Can you even imagine?  Who the hell would go to this a bastion of commercial excess?\\n',\n",
       " 'L721': 'I got drunk.  I puked.  I got rejected. It was big fun.\\n',\n",
       " 'L720': \"You didn't\\n\",\n",
       " 'L719': 'I did Bianca a favor and it backfired.\\n',\n",
       " 'L718': \"You didn't have a choice?  Where's Kat and what have you done with her?\\n\",\n",
       " 'L717': \"I didn't have a choice.\\n\",\n",
       " 'L716': 'You went to the party?  I thought we were officially opposed to suburban social activity.\\n',\n",
       " 'L491': 'Who cares?\\n',\n",
       " 'L490': \"What'd he say?\\n\",\n",
       " 'L448': 'No fear.\\n',\n",
       " 'L447': \"You think this'll work?\\n\",\n",
       " 'L254': 'If I was Bianca, it would be, \"Any school you want, precious.  Don\\'t forget your tiara.\"\\n',\n",
       " 'L253': 'Does it matter?\\n',\n",
       " 'L252': \"I appreciate your efforts toward a speedy death, but I'm consuming.  Do you mind?\\n\",\n",
       " 'L251': 'Neither has his heterosexuality.\\n',\n",
       " 'L250': \"That's never been proven\\n\",\n",
       " 'L249': \"William didn't even go to high school\\n\",\n",
       " 'L248': 'William would never have gone to a state school.\\n',\n",
       " 'L247': 'So he has this huge raging fit about Sarah Lawrence and insists that I go to his male-dominated, puking frat boy, number one golf team school. I have no say at all.\\n',\n",
       " 'L152': \"You could always go with me.  I'm sure William has some friends.\\n\",\n",
       " 'L151': 'The people at this school are so incredibly foul.\\n',\n",
       " 'L134': \"But imagine the things he'd say during sex.\\n\",\n",
       " 'L133': \"I realize that the men of this fine institution are severely lacking, but killing yourself so you can be with William Shakespeare is beyond the scope of normal teenage obsessions.  You're venturing far past daytime talk show fodder and entering the world of those who need very expensive therapy.\\n\",\n",
       " 'L132': 'An attempted slit.\\n',\n",
       " 'L131': \"What's this?\\n\",\n",
       " 'L130': 'Just a little.\\n',\n",
       " 'L129': 'Mandella, eat.  Starving yourself is a very slow way to die.\\n',\n",
       " 'L128': 'Block E?\\n',\n",
       " 'L127': 'He always look so\\n',\n",
       " 'L126': \"I'm sure he's completely incapable of doing anything that interesting.\\n\",\n",
       " 'L125': \"That's Pat Verona? The one who was gone for a year? I heard he was doing porn movies.\\n\",\n",
       " 'L124': 'Patrick Verona   Random skid.\\n',\n",
       " 'L123': \"Who's that?\\n\",\n",
       " 'L1043': \"Don ' t you even dare. . .\\n\",\n",
       " 'L1042': 'Oh, Bianca?  Can you get me my freshman yearbook?\\n',\n",
       " 'L1041': 'Because I like to torture you.\\n',\n",
       " 'L1040': 'Why is my veggie burger the only burnt object on this grill?\\n',\n",
       " 'L1035': 'Yeah, but then I fucked up. I fell for her.\\n',\n",
       " 'L1034': 'Is that right?\\n',\n",
       " 'L1033': 'Besides, I had some extra cash. Some asshole paid me to take out a really great girl.\\n',\n",
       " 'L1032': 'I thought you could use it. When you start your band.\\n',\n",
       " 'L1031': 'A Fender Strat. You bought this?\\n',\n",
       " 'L977': \"I didn't care about the money.\\n\",\n",
       " 'L976': 'Really?  What was it like?  A down payment now, then a bonus for sleeping with me?\\n',\n",
       " 'L975': \"It wasn't like that.\\n\",\n",
       " 'L974': 'You were paid to take me out!  By -- the one person I truly hate.  I knew it was a set-up!\\n',\n",
       " 'L973': 'Wait I...\\n',\n",
       " 'L961': 'It gets worse -- you still have your freshman yearbook?\\n',\n",
       " 'L960': \"That ' s completely adorable!\\n\",\n",
       " 'L959': \"That's where I was last year.  She'd never lived alone -- my grandfather died -- I stayed with her.  I wasn't in jail, I don't know Marilyn Manson, and I've never slept with a Spice Girl.  I spent a year sitting next to my grandma on the couch watching Wheel of Fortune.  End of story.\\n\",\n",
       " 'L958': 'What?\\n',\n",
       " 'L957': \"My grandmother's .\\n\",\n",
       " 'L940': \"Look, I'm  -- sorry -- that I questioned your motives.  I was wrong.\\n\",\n",
       " 'L939': 'Oh huh\\n',\n",
       " 'L938': \"It's just something I had.  You know\\n\",\n",
       " 'L937': \"It's Scurvy's.  His date got convicted. Where'd you get the dress?\\n\",\n",
       " 'L936': \"How'd you get a tux at the last minute?\\n\",\n",
       " 'L857': \"Nothing!  There's nothing in it for me. Just the pleasure of your company.\\n\",\n",
       " 'L856': 'Answer the question, Patrick\\n',\n",
       " 'L855': 'You need therapy.  Has anyone ever told you that?\\n',\n",
       " 'L854': 'You tell me.\\n',\n",
       " 'L853': 'So I have to have a motive to be with you?\\n',\n",
       " 'L852': 'Create a little drama?  Start a new rumor?  What?\\n',\n",
       " 'L848': \"Because I don't want to. It's a stupid tradition.\\n\",\n",
       " 'L847': 'Why not?\\n',\n",
       " 'L846': \"No, I won't go with you\\n\",\n",
       " 'L845': 'No what?\\n',\n",
       " 'L844': 'No.\\n',\n",
       " 'L843': 'You know what I mean\\n',\n",
       " 'L842': 'Is that a request or a command?\\n',\n",
       " 'L841': 'Go to the prom with me\\n',\n",
       " 'L840': \"You're amazingly self-assured. Has anyone ever told you that?\\n\",\n",
       " 'L839': 'No one else knows\\n',\n",
       " 'L838': 'What?\\n',\n",
       " 'L837': \"You're sweet.  And sexy.  And completely hot for me.\\n\",\n",
       " 'L836': 'No -- something real.  Something no one else knows.\\n',\n",
       " 'L835': 'I hate peas.\\n',\n",
       " 'L834': 'Tell me something true.\\n',\n",
       " 'L832': \"I know the porn career's a lie.\\n\",\n",
       " 'L831': 'Hearsay.\\n',\n",
       " 'L830': 'The duck?\\n',\n",
       " 'L829': 'Fallacy.\\n',\n",
       " 'L828': 'State trooper?\\n',\n",
       " 'L825': 'For. . . ?\\n',\n",
       " 'L824': 'You up for it?\\n',\n",
       " 'L823': 'You never disappointed me.\\n',\n",
       " 'L822': 'How?\\n',\n",
       " 'L821': 'Then you screwed up\\n',\n",
       " 'L820': 'Something like that\\n',\n",
       " 'L819': \"So if you disappoint them from the start, you're covered?\\n\",\n",
       " 'L818': \"I don't like to do what people expect. Then they expect it all the time and they get disappointed when you change.\\n\",\n",
       " 'L817': 'Yes\\n',\n",
       " 'L816': 'Acting the way we do.\\n',\n",
       " 'L815': \"So what's your excuse?\\n\",\n",
       " 'L814': \"Yeah, well, don't let it get out\\n\",\n",
       " 'L813': 'A soft side? Who knew?\\n',\n",
       " 'L812': 'I dazzled him with my wit\\n',\n",
       " 'L811': \"So how'd you get Chapin to look the other way?\\n\",\n",
       " 'L810': 'Good call.\\n',\n",
       " 'L809': 'I figured it had to be something ridiculous to win your respect.  And piss you off.\\n',\n",
       " 'L808': 'The Partridge Family?\\n',\n",
       " 'L806': 'Maybe.\\n',\n",
       " 'L805': 'You want me to climb up and show you how to get down?\\n',\n",
       " 'L804': \"Forget it.  I'm stayin'.\\n\",\n",
       " 'L803': 'Put your right foot there --\\n',\n",
       " 'L802': \"Try lookin' at it from this angle\\n\",\n",
       " 'L801': \"C'mon.  It's not that bad\\n\",\n",
       " 'L800': \"I guess I never told you I'm afraid of heights.\\n\",\n",
       " 'L799': 'Look up, sunshine\\n',\n",
       " 'L798': 'He left!  I sprung the dickhead and he cruised on me.\\n',\n",
       " 'L774': 'Other than my upchuck reflex? Nothing.\\n',\n",
       " 'L773': 'So what did I have an effect on ?\\n',\n",
       " 'L772': \"Don't for one minute think that you had any effect whatsoever on my panties.\\n\",\n",
       " 'L771': 'Unwelcome?  I guess someone still has her panties in a twist.\\n',\n",
       " 'L770': 'Unwelcome.\\n',\n",
       " 'L769': 'Wholesome.\\n',\n",
       " 'L768': 'Pleasant?\\n',\n",
       " 'L767': \"You 're so --\\n\",\n",
       " 'L766': 'I heard there was a poetry reading.\\n',\n",
       " 'L765': 'What are you doing here?\\n',\n",
       " 'L764': 'Excuse me, have you seen The Feminine Mystique?  I lost my copy.\\n',\n",
       " 'L690': \"No offense, but you're sister is without.  I know everyone likes her and all, but ...\\n\",\n",
       " 'L689': 'BIANCA\\n',\n",
       " 'L688': 'Who?\\n',\n",
       " 'L687': \"He just wants me to be someone I'm not.\\n\",\n",
       " 'L686': \"So what ' s up with your dad?  He a pain in the ass?\\n\",\n",
       " 'L684': \"I'm gettin' there\\n\",\n",
       " 'L683': 'Oh, so now you think you know me?\\n',\n",
       " 'L682': \"You don't strike me as the type that would ask permission.\\n\",\n",
       " 'L681': \"My father wouldn't approve of that that\\n\",\n",
       " 'L680': 'Start a band?\\n',\n",
       " 'L679': 'This.\\n',\n",
       " 'L678': 'Do what?\\n',\n",
       " 'L677': 'I should do this.\\n',\n",
       " 'L676': \"Why'd you lie?\\n\",\n",
       " 'L675': \"Then why'd you ask?\\n\",\n",
       " 'L674': \"No, you weren't\\n\",\n",
       " 'L673': 'Maybe.\\n',\n",
       " 'L672': 'Were you in jail?\\n',\n",
       " 'L671': 'Busy\\n',\n",
       " 'L670': 'When you were gone last year -- where were you?\\n',\n",
       " 'L669': \"But it's Gigglepuss - I know you like them.  I saw you there.\\n\",\n",
       " 'L668': \"And I'm in control of it.\\n\",\n",
       " 'L651': 'What?\\n',\n",
       " 'L650': 'Kat! Wake up!\\n',\n",
       " 'L646': 'You know what they say\\n',\n",
       " 'L645': 'I thought you were above all that\\n',\n",
       " 'L644': 'Hey man. . .  You don \\' t think I can be \"cool\"?  You don\\'t think I can be \"laid back\" like everyone else?\\n',\n",
       " 'L643': \"I know.  It'd have to be a pretty big deal to get you to mainline tequila. You don't seem like the type.\\n\",\n",
       " 'L642': 'I hate him.\\n',\n",
       " 'L641': 'Dorsey.\\n',\n",
       " 'L640': 'Who?\\n',\n",
       " 'L639': \"Why'd you let him get to you?\\n\",\n",
       " 'L636': 'Just let me sit down.\\n',\n",
       " 'L635': \"See that?  Who needs affection when I've got blind hatred?\\n\",\n",
       " 'L634': 'Like you could find one\\n',\n",
       " 'L633': \"Because then I'd have to start taking out girls who like me.\\n\",\n",
       " 'L632': 'Why?\\n',\n",
       " 'L631': 'Sure, I do\\n',\n",
       " 'L630': \"You don't care if I die\\n\",\n",
       " 'L629': 'I told you\\n',\n",
       " 'L628': \"Why 're you doing this?\\n\",\n",
       " 'L627': \"Leave it to you to use big words when you're shitfaced.\\n\",\n",
       " 'L626': 'This is so patronizing.\\n',\n",
       " 'L616': 'What if you have a concussion? My dog went to sleep with a concussion and woke up a vegetable. Not that I could tell the difference...\\n',\n",
       " 'L615': 'I know, just let me sleep\\n',\n",
       " 'L614': \"Uh, uh. You lie down and you'll go to sleep\\n\",\n",
       " 'L613': 'I just need to lie down for awhile\\n',\n",
       " 'L612': \"You're not okay.\\n\",\n",
       " 'L611': \"I'm fine. I'm\\n\",\n",
       " 'L610': 'Okay?\\n',\n",
       " 'L567': \"Funny, you're the only one\\n\",\n",
       " 'L566': 'I say, do what you wanna do.\\n',\n",
       " 'L565': '\"I\\'m getting trashed, man.\" Isn\\'t that what you\\'re supposed to do at a party?\\n',\n",
       " 'L564': \"What's this?\\n\",\n",
       " 'L483': \"Why, don't you?\\n\",\n",
       " 'L482': 'You know who The Raincoats are?\\n',\n",
       " 'L481': \"You know, these guys are no Bikini Kill or The Raincoats, but they're right up there.\\n\",\n",
       " 'L477': \"Do you mind?  You're sort of ruining it for me.\\n\",\n",
       " 'L476': \"That's what you want, isn't it?\\n\",\n",
       " 'L475': 'Excuse me?\\n',\n",
       " 'L474': '\\n',\n",
       " 'L473': 'hey.  Great show, huh?\\n',\n",
       " 'L334': \"Depends on the topic. My fenders don't really whip me into a verbal frenzy.\\n\",\n",
       " 'L333': \"You're not a big talker, are you?\\n\",\n",
       " 'L332': 'Hi\\n',\n",
       " 'L331': \"I was in the laundromat. I saw your car. Thought I'd say hi.\\n\",\n",
       " 'L330': 'Are you following me?\\n',\n",
       " 'L328': 'Seven-thirty?\\n',\n",
       " 'L327': 'You -- covered in my vomit.\\n',\n",
       " 'L326': 'Come on -- the ponies, the flat beer, you with money in your eyes, me with my hand on your ass...\\n',\n",
       " 'L325': 'And why would I do that?\\n',\n",
       " 'L324': \"Then say you'll spend Dollar Night at the track with me.\\n\",\n",
       " 'L323': \"I don't really think you warrant that strong an emotion.\\n\",\n",
       " 'L322': \"You hate me don't you?\\n\",\n",
       " 'L313': 'I know a lot more than that\\n',\n",
       " 'L312': 'Like where?  The 7-Eleven on Burnside? Do you even know my name, screwboy?\\n',\n",
       " 'L311': \"The night I take you to places you've never been before.  And back.\\n\",\n",
       " 'L310': 'Oh, right.  Friday.\\n',\n",
       " 'L309': 'Pick you up Friday, then\\n',\n",
       " 'L307': 'My mission in life.\\n',\n",
       " 'L306': \"There's a way to get a guy's attention.\\n\",\n",
       " 'L305': 'Sweating like a pig, actually.  And yourself?\\n',\n",
       " 'L304': \"I mean Wo-man.  How ya doin'?\\n\",\n",
       " 'L1000': \"Oh, Christ.  Don't tell me you've changed your mind.  I already sent 'em a check.\\n\",\n",
       " 'L999': 'When I go?\\n',\n",
       " 'L998': \"You know, fathers don't like to admit that their daughters are capable of running their own lives.  It means we've become spectators.  Bianca still lets me play a few innings.  You've had me on the bleachers for years.  When you go to Sarah Lawrence, I won't even be able to watch the game.\\n\",\n",
       " 'L997': 'No -- impressed.\\n',\n",
       " 'L996': \"What's the matter?  Upset that I rubbed off on her?\\n\",\n",
       " 'L995': 'Bianca did what?\\n',\n",
       " 'L994': 'The part where Bianca beat the hell out of some guy.\\n',\n",
       " 'L993': 'Which parts?\\n',\n",
       " 'L992': 'Parts of it.\\n',\n",
       " 'L991': 'So tell me about this dance. Was it fun?\\n',\n",
       " 'L990': 'No, Daddy.\\n',\n",
       " 'L989': \"I don't understand the allure of dehydrated food.  Is this something I should be hip to?\\n\",\n",
       " 'L988': 'Funny.\\n',\n",
       " 'L987': 'Yeah.  She left with some bikers Big ones.  Full of sperm.\\n',\n",
       " 'L986': 'Was that your sister?\\n',\n",
       " 'L347': 'I want to go to an East Coast school! I want you to trust me to make my own choices.  I want --\\n',\n",
       " 'L346': \"You're eighteen.  You don't know what you want.  You won't know until you're forty-five and you don't have it.\\n\",\n",
       " 'L345': \"So what I want doesn't matter?\\n\",\n",
       " 'L344': \"As a parent, that's my right\\n\",\n",
       " 'L343': \"Because you're making decisions for me.\\n\",\n",
       " 'L342': \"Why can't we agree on this?\\n\",\n",
       " 'L341': 'I thought you were punishing me.\\n',\n",
       " 'L340': 'Is this about Sarah Lawrence? You punishing me?\\n',\n",
       " 'L339': 'Then tell them I had a seizure.\\n',\n",
       " 'L338': 'My insurance does not cover PMS\\n',\n",
       " 'L185': 'Enough!\\n',\n",
       " 'L184': 'This from someone whose diary is devoted to favorite grooming tips?\\n',\n",
       " 'L174': 'You decided.\\n',\n",
       " 'L173': 'I thought we decided you were going to school here.  At U of 0.\\n',\n",
       " 'L172': 'I know.\\n',\n",
       " 'L1018': 'Just smack her now.\\n',\n",
       " 'L1017': 'Am I supposed to feel better? Like, right now?  Or do I have some time to think about it?\\n',\n",
       " 'L109': 'No ... I believe \"heinous bitch\" is the term used most often.\\n',\n",
       " 'L108': 'Tempestuous?\\n',\n",
       " 'L107': 'The point is Kat -- people perceive you as somewhat ...\\n',\n",
       " 'L106': 'I still maintain that he kicked himself in the balls.  I was merely a spectator.\\n',\n",
       " 'L105': \"Well, yes, compared to your other choices of expression this year, today's events are quite mild.  By the way, Bobby Rictor's gonad retrieval operation went quite well, in case you're interested.\\n\",\n",
       " 'L104': 'Expressing my opinion is not a terrorist action.\\n',\n",
       " 'L103': \"Katarina Stratford.  My, my.  You've been terrorizing Ms. Blaise again.\\n\",\n",
       " 'L738': 'Yeah...\\n',\n",
       " 'L737': 'Kat a fan, too?\\n',\n",
       " 'L736': 'Right.\\n',\n",
       " 'L735': 'Macbeth, right?\\n',\n",
       " 'L733': 'Oh yeah.\\n',\n",
       " 'L732': 'You think?\\n',\n",
       " 'L731': 'Yeah.  I guess.\\n',\n",
       " 'L730': 'Cool pictures.  You a fan?\\n',\n",
       " 'L729': 'Hi.\\n',\n",
       " 'L728': 'Hey there.  Tired of breathing?\\n',\n",
       " 'L777': \"Man -- don't say shit like that to  me. People can hear you.\\n\",\n",
       " 'L776': 'Sweet love, renew thy force!\\n',\n",
       " 'L775': \"You were right. She's still pissed.\\n\",\n",
       " 'L724': \"No - I've got a sweet-payin' job that I'm about to lose.\\n\",\n",
       " 'L723': 'So you got cozy with she who stings?\\n',\n",
       " 'L437': \"I'm likin' you guys better\\n\",\n",
       " 'L436': 'I prefer to think of it simply as an alternative to what the law allows.\\n',\n",
       " 'L429': 'Yeah.\\n',\n",
       " 'L428': 'Ever been to Club Skunk?\\n',\n",
       " 'L421': 'Just for now.\\n',\n",
       " 'L420': 'Are you telling me I\\'m a -  \"non-smoker\"?\\n',\n",
       " 'L415': 'Good enough.\\n',\n",
       " 'L414': 'What?!\\n',\n",
       " 'L384': \"We're your guys.\\n\",\n",
       " 'L383': 'You two are gonna help me tame the wild beast?\\n',\n",
       " 'L382': \"Patrick, Pat, you're not looking at the big picture.  Joey's just a pawn. We set this whole thing up so Cameron can get the girl.\\n\",\n",
       " 'L381': 'So Dorsey can get the girl?\\n',\n",
       " 'L380': \"That's where we can help you.  With Kat.\\n\",\n",
       " 'L379': \"Dorsey can plow whoever he wants. I'm just in this for the cash.\\n\",\n",
       " 'L378': \"I think I speak correctly when I say that Cameron's love is pure.  Purer than say -- Joey Dorsey's.\\n\",\n",
       " 'L377': 'What is it with this chick?  She have three tits?\\n',\n",
       " 'L376': 'The situation is, my man Cameron here has a major jones for Bianca Stratford.\\n',\n",
       " 'L375': 'What plan?\\n',\n",
       " 'L373': \"Whatever the hell it is you're standin' there waitin' to say.\\n\",\n",
       " 'L372': 'What?\\n',\n",
       " 'L371': 'Say it\\n',\n",
       " 'L512': 'See you next week!\\n',\n",
       " 'L511': \"You're completely demented.\\n\",\n",
       " 'L264': \"Well, you know -- there's the prestige of the job title... and the benefits package is pretty good...\\n\",\n",
       " 'L263': \"You weren't abused, you aren't stupid, and as far as I can tell, you're only slightly psychotic -- so why is it that you're such a fuck-up?\\n\",\n",
       " 'L262': \"What's to discuss?\\n\",\n",
       " 'L261': \"Why don't we discuss your driving need to be a hemorrhoid?\\n\",\n",
       " 'L259': \"I'm at a loss, then.  What should we talk about? Your year of absence?\\n\",\n",
       " 'L258': 'Touch of the flu.\\n',\n",
       " 'L257': \"I don't understand, Patrick.  You haven't done anything asinine this week. Are you not feeling well?\\n\",\n",
       " 'L62': 'With the teeth of your zipper?\\n',\n",
       " 'L61': 'It was a bratwurst.  I was eating lunch.\\n',\n",
       " 'L60': 'It says here you exposed yourself to a group of freshmen girls.\\n',\n",
       " 'L59': 'I missed you.\\n',\n",
       " 'L933': \"That ' s what I thought\\n\",\n",
       " 'L932': 'Absolutely not.\\n',\n",
       " 'L931': 'Did I have anything to say about it?\\n',\n",
       " 'L930': 'Your daughters went to the prom.\\n',\n",
       " 'L929': 'What just happened?\\n',\n",
       " 'L927': 'But -- who -- what --?\\n',\n",
       " 'L926': 'Have a great time, honey!\\n',\n",
       " 'L918': 'Dr. Ruth?\\n',\n",
       " 'L917': \"What do you wanna watch?  We've got crap, crap, crap or crap\\n\",\n",
       " 'L887': \"Kissing?  Is that what you think happens?  Kissing isn't what keeps me up to my elbows in placenta all day.\\n\",\n",
       " 'L886': \"They'll dance, they'll kiss, they'll come home.  Let her go.\\n\",\n",
       " 'L877': 'Pirate -- no question.\\n',\n",
       " 'L876': 'Would you rather be ravished by a pirate or a British rear admiral?\\n',\n",
       " 'L193': \"You're not helping.\\n\",\n",
       " 'L192': 'Tumescent!\\n',\n",
       " 'L191': 'Jesus!  Can a man even grab a sandwich before you women start dilating?\\n',\n",
       " 'L171': 'Sarah Lawrence is on the other side of the country.\\n',\n",
       " 'L170': \"What's a synonym for throbbing?\\n\",\n",
       " 'L162': 'Make anyone cry today?\\n',\n",
       " 'L161': 'In the microwave.\\n',\n",
       " 'L2181': \"Can't be that far, I say.  Also, I don't like the smell of the sea around here.  Smells like a cunt. Bad sign...\\n\",\n",
       " 'L2180': \"We left three weeks ago, Alonso. Can't be that near.\\n\",\n",
       " 'L2179': 'We should have seen land.\\n',\n",
       " 'L2177': \"We'll all go crazy...\\n\",\n",
       " 'L2176': \"He's the devil's child...\\n\",\n",
       " 'L2175': \"With a face like that?  I don't want you looking at me.  You hear?\\n\",\n",
       " 'L2174': \"Ah, leave him alone.  He's doing no harm.\\n\",\n",
       " 'L2173': 'What are you listening to, chicken ass?\\n',\n",
       " 'L2172': \"You'll be drinking your own piss... For the glory of Spain... and Admiral Colon...!  Bastard!\\n\",\n",
       " 'L2171': \"The water's going putrid in the barrels.\\n\",\n",
       " 'L2170': 'I never seen heat like this!  Not even in Las Minas!\\n',\n",
       " 'L2025': 'IF-GOD-WILLS-IT!\\n',\n",
       " 'L2024': 'Asia can be found to the west -- and I will prove it.\\n',\n",
       " 'L2023': 'Blind faith is what I consider heresy!\\n',\n",
       " 'L2022': \"Don't you realize your words could be considered heretical?\\n\",\n",
       " 'L2020': \"Did He not choose a carpenter's son to reveal Himself to the world?\\n\",\n",
       " 'L2019': 'If God intended our proximity to Asia, do you believe he would have waited for you to show it to the world?\\n',\n",
       " 'L2016': 'No.  The Portuguese have already discovered black-skinned people.  I, too, will find other populations -- and bring them to the word of God.\\n',\n",
       " 'L2015': 'Is that all that interests you? Gold?\\n',\n",
       " 'L2014': 'Trade, Your Excellency.  According to Marco Polo, the Kingdom of China is one of the richest of the world. Even the meanest buildings are roofed with gold.\\n',\n",
       " 'L2012': 'If they agree to follow me, yes.\\n',\n",
       " 'L2011': 'Your life, and that of others!\\n',\n",
       " 'L2010': 'Your Eminence, there is only one way to settle the matter.  And that is to make the journey.  I am ready to risk my life to prove it possible.\\n',\n",
       " 'L2006': 'Excellency, you are right.\\n',\n",
       " 'L2005': 'Senor Colon, an experienced captain such as yourself will understand our concern with the crew.  I am not willing to have on my conscience the loss of men who would have relied upon our judgment.\\n',\n",
       " 'L1993': 'Then you cannot ignore that according to their calculations, the circumference of the Earth is approximately...  22,000 leagues or more.  Which makes the ocean... uncrossable.\\n',\n",
       " 'L1992': 'I am, Your Eminence\\n',\n",
       " 'L1991': 'Unfortunately, Don Colon, that is precisely where our opinions differ...  Are you familiar with the work of Aristotle?  Erathostene?  Ptolemeus?\\n',\n",
       " 'L1990': 'Yes, your Eminence.  The voyage should not take more than six or seven weeks.\\n',\n",
       " 'L1989': 'You say Asia can be found by sailing west?\\n',\n",
       " 'L2524': 'A waste...?  Let me tell you something, Arojaz.  If your name, or mine, is ever remembered -- it will only be because of his.\\n',\n",
       " 'L2523': 'What a tragedy... what a waste of a life...\\n',\n",
       " 'L2522': 'You can see for yourself.\\n',\n",
       " 'L2275': 'On the contrary, Your Eminence.  It seems to me the man is preparing his own cross.\\n',\n",
       " 'L2274': \"It won't be easy to get rid of your prophet now, Don Sanchez.\\n\",\n",
       " 'L2031': 'Indeed.  The world is full of mercenaries -- and states often make use of them, when it benefits them.  My only concern is the welfare and prosperity of Spain.\\n',\n",
       " 'L2030': 'He is a mercenary!  Did he not already try to convince the King of Portugal of his absurd notions?\\n',\n",
       " 'L2029': 'Naturally.  But I would really deplore the loss of such a potential opportunity for Spain for a... dispute over a point of geography.\\n',\n",
       " 'L2028': 'The Judgment is ours!\\n',\n",
       " 'L2027': \"The State has some reason to be interested in this man's proposition, Your Eminence...\\n\",\n",
       " 'L2540': \"I can't keep my eyes off you.  I would like to catch up with all the moments I didn't spend with you.\\n\",\n",
       " 'L2539': 'What is it, now?  Tell me...\\n',\n",
       " 'L2538': 'I am busy inside.\\n',\n",
       " 'L2537': \"Can't you stay with us a little?\\n\",\n",
       " 'L2474': \"Not everything... Do you think I care?  I'm a free man again.  Riches don't make a man rich, they only make him busier...\\n\",\n",
       " 'L2473': 'They took everything...\\n',\n",
       " 'L2472': \"They tried... but I didn't let them.\\n\",\n",
       " 'L2471': \"God... you're so beautiful!  I can't believe no other man has ever taken you away from me...\\n\",\n",
       " 'L2320': 'I can arrange for the Queen to take Fernando and Diego into her service.\\n',\n",
       " 'L2319': \"You don't usually ask.\\n\",\n",
       " 'L2318': 'Beatrix, I want to ask you something.\\n',\n",
       " 'L2123': \"That's something you can't decide.\\n\",\n",
       " 'L2122': \"I don't want you to wait for me.\\n\",\n",
       " 'L2121': \"I'm not asking you to swear to anything.\\n\",\n",
       " 'L2119': 'Thank God...\\n',\n",
       " 'L2118': 'She said yes.\\n',\n",
       " 'L1986': 'I find that hard to believe.\\n',\n",
       " 'L1985': 'Perhaps I was never meant to live with a woman...\\n',\n",
       " 'L1984': \"I'd love to argue with you sometimes.  But you're never here!\\n\",\n",
       " 'L1983': 'Are we going to argue?\\n',\n",
       " 'L1982': \"Well... that's true.  I have a child by a man who won't marry me!  Who's always leaving...\\n\",\n",
       " 'L1981': \"I haven't given you much of a life.\\n\",\n",
       " 'L1980': 'I know.\\n',\n",
       " 'L1979': 'I could be gone for years.\\n',\n",
       " 'L2432': 'I am afraid this is not the worst news.\\n',\n",
       " 'L2431': 'How could I be?  The mainland has been found.  Exactly as I said it would.\\n',\n",
       " 'L2430': 'I am not a seaman.  But I heard it is no more than a week at sea.  I hope you are not too disappointed.\\n',\n",
       " 'L2429': 'How far from here?\\n',\n",
       " 'L2426': 'Congratulations.  Then I am free to search for the mainland.\\n',\n",
       " 'L2425': 'Viceroy of the West Indies.\\n',\n",
       " 'L2424': 'Appointment to what?\\n',\n",
       " 'L2423': 'My letters of appointment.\\n',\n",
       " 'L2422': 'Yes... I remember...\\n',\n",
       " 'L2421': 'Don Alonso de Bobadilla.\\n',\n",
       " 'L2293': 'Bartolome and Giacomo Colon.\\n',\n",
       " 'L2292': 'May I ask by whom?\\n',\n",
       " 'L2291': 'Forgive me, Don Bobadilla -- those positions have already been taken.\\n',\n",
       " 'L2290': 'I understand that you will soon be appointing Governors for the islands?  Is it not so?\\n',\n",
       " 'L2552': 'Tell me the first thing that comes to your mind.\\n',\n",
       " 'L2551': \"Really?  God... I wouldn't know where to start... and yet...\\n\",\n",
       " 'L2550': 'I want you to tell me everything you remember, Father.  From the beginning.  Everything.\\n',\n",
       " 'L2549': 'He never had one... except aboard my ships!\\n',\n",
       " 'L2548': 'He asks when he can come to visit you.  He left his address.\\n',\n",
       " 'L2547': 'What does he say?\\n',\n",
       " 'L2542': \"I am not listening, Father.  But I can't help hearing.\\n\",\n",
       " 'L2541': 'What are you listening to?\\n',\n",
       " 'L2501': 'There must be a passage to that other ocean.\\n',\n",
       " 'L2500': 'Father...\\n',\n",
       " 'L2485': 'Not bad.\\n',\n",
       " 'L2484': 'How are you feeling, Fernando?\\n',\n",
       " 'L2440': 'This time with me!\\n',\n",
       " 'L2439': 'I have to explore the mainland.\\n',\n",
       " 'L2131': 'Yes... Yes, I do... On all of them!\\n',\n",
       " 'L2130': 'Do you swear on all the Holy Saints in heaven?\\n',\n",
       " 'L2129': 'You promise?  Do you swear on St. Christopher...?\\n',\n",
       " 'L2128': \"There'll be a time.\\n\",\n",
       " 'L2127': 'I want to go with you!\\n',\n",
       " 'L2469': 'All of them created by people like me.\\n',\n",
       " 'L2468': 'Roofs... towers, palaces... spires...\\n',\n",
       " 'L2467': 'What do you see?\\n',\n",
       " 'L2466': 'Look out of that window.\\n',\n",
       " 'L2465': 'I am not afraid of you.  You are nothing but a dreamer.\\n',\n",
       " 'L2464': 'Call them.\\n',\n",
       " 'L2463': 'All I have to do is call the guards.\\n',\n",
       " 'L2301': 'To rise so high, in so short a time, is a dangerous occupation.  A little hypocrisy goes a long way.\\n',\n",
       " 'L2300': 'What...?  Do I have so many already?\\n',\n",
       " 'L2299': 'You seem to have a special talent for making friends.\\n',\n",
       " 'L2297': 'Good!  We are also in need of judges.  Except there are no thieves!\\n',\n",
       " 'L2296': 'Don Bobadilla is already a judge, my Dear Don Cristobal.\\n',\n",
       " 'L2295': 'But we do have a lack of notaries. You should contact my administration.\\n',\n",
       " 'L2287': '... for a commoner?\\n',\n",
       " 'L2286': 'You defend yourself admirably...\\n',\n",
       " 'L2282': 'Forgive me, Don Colon.  But what about gold?\\n',\n",
       " 'L2281': \"They don't see sin in their nakedness.  They live according to nature, in a never ending summer. The islands are covered with trees, filled with blossoms and fruits. And...\\n\",\n",
       " 'L2110': \"If you won't accept our proposal, we'll simply find someone who will.\\n\",\n",
       " 'L2109': 'And were you never ambitious, Excellency?  Or is ambition only a virtue among the nobles, a fault for the rest of us?\\n',\n",
       " 'L2108': 'Then you are too ambitious.\\n',\n",
       " 'L2107': \"I'm not bargaining!\\n\",\n",
       " 'L2106': 'I remind you, Senor Colon, that you are in no position to bargain with me.\\n',\n",
       " 'L2105': 'NO...!  I have waited too long, fought too hard.  Now you expect me to take all the risks while you take the profit!  No... I will not be your servant!\\n',\n",
       " 'L2104': 'No?\\n',\n",
       " 'L2103': 'No...\\n',\n",
       " 'L2410': 'You never learned how to speak my language.\\n',\n",
       " 'L2409': \"Utapan, won't you speak to me?  You used to know how to speak to me.\\n\",\n",
       " 'L2394': 'You did the same to your God!\\n',\n",
       " 'L2393': 'You have to find them, Utapan.  Look what they did!\\n',\n",
       " 'L2343': 'Ask him if he will help.\\n',\n",
       " 'L2342': 'He understands.\\n',\n",
       " 'L2341': 'We will work with his people.  We want peace.  Ask the Chief if he understands?\\n',\n",
       " 'L2260': 'He has medicine.  Tell him we admire his people.\\n',\n",
       " 'L2259': 'Chief says...\\n',\n",
       " 'L2258': '... and also to bring medicine.\\n',\n",
       " 'L2257': 'Chief says -- he has a God.\\n',\n",
       " 'L2256': 'To bring the word of God.\\n',\n",
       " 'L2255': 'Why?\\n',\n",
       " 'L2254': 'Thousands.\\n',\n",
       " 'L2253': 'Chief says -- how many?\\n',\n",
       " 'L2251': 'Tell him his country is very beautiful.  Tell him we are leaving men here -- to build a fort.\\n',\n",
       " 'L2250': 'Chief knows.\\n',\n",
       " 'L2249': 'Tell the Chief we thank him.\\n',\n",
       " 'L2248': 'You come!  You speak first!\\n',\n",
       " 'L2239': 'Island.  Far.\\n',\n",
       " 'L2238': 'What is it?  A tribe?  An island?\\n',\n",
       " 'L2237': 'Say not here!  Cuba!\\n',\n",
       " 'L2535': \"I don't know... I have the impression that I didn't change that much.  I still can't accept the world as it is!\\n\",\n",
       " 'L2534': 'Oh?  So you are a new man?\\n',\n",
       " 'L2533': 'New worlds create new people.\\n',\n",
       " 'L2532': 'I knew you would.\\n',\n",
       " 'L2531': 'I have to disagree.\\n',\n",
       " 'L2526': \"You'll always be older than me, Father.\\n\",\n",
       " 'L2525': \"I suppose we're both old men now.\\n\",\n",
       " 'L2145': 'Give me absolution.\\n',\n",
       " 'L2144': 'I believed in you...\\n',\n",
       " 'L2143': 'You are bound by an oath, Father.\\n',\n",
       " 'L2142': \"My son, my son...  Your certitudes are sometimes frightening...  Christopher, you must speak to them. And if you don't I will.\\n\",\n",
       " 'L2141': \"If I tell them, they won't follow me.  You know that I am right, Father.  You trust me...\\n\",\n",
       " 'L2140': 'May God forgive you...!  You must tell them!  You must tell your men!\\n',\n",
       " 'L2139': 'I am not sure... It could be twice the distance.\\n',\n",
       " 'L2138': 'How long?\\n',\n",
       " 'L2137': 'I lied.  The journey will be longer than I said.\\n',\n",
       " 'L2136': 'What are you saying?\\n',\n",
       " 'L2135': 'Father, I have betrayed my family. I betrayed my men.  And I betrayed you.\\n',\n",
       " 'L2134': 'I am listening, my son.\\n',\n",
       " 'L2133': 'Forgive me, Father.  For I have sinned.\\n',\n",
       " 'L2132': 'In Nomine Patris et Filius, et Spiritus Sancti.\\n',\n",
       " 'L2046': \"Colon!  Don't!\\n\",\n",
       " 'L2045': 'All of them!  Just lies!\\n',\n",
       " 'L2042': 'Damn all of you!  You all set up theories based on what?  You never leave the safety of your studies! Go out!  Find out what the world is about and then tell me something I can listen to!\\n',\n",
       " 'L2041': 'Colon!\\n',\n",
       " 'L2040': 'Damn God!\\n',\n",
       " 'L2039': 'If God intends you to go, then you will go.\\n',\n",
       " 'L2038': \"Wait!  I've waited seven years already!  How much longer do you want me to wait?\\n\",\n",
       " 'L2037': \"You mustn't give way to despair. You must wait.\\n\",\n",
       " 'L1969': 'Only God knows the meaning of such words, my son.\\n',\n",
       " 'L1968': \"I've been contradicted all my life... Eternity!\\n\",\n",
       " 'L1967': 'You get so carried away when you are being contradicted!\\n',\n",
       " 'L1966': 'Passion is something one cannot control!\\n',\n",
       " 'L1965': 'Father Marchena!\\n',\n",
       " 'L1964': \"I'll try to remember that, Marchena...\\n\",\n",
       " 'L1963': \"Two minutes... and already you're a dead man.  Don't let passion overwhelm you, Colon.\\n\",\n",
       " 'L1962': 'So was Christ!\\n',\n",
       " 'L1961': 'Esdras is a Jew.\\n',\n",
       " 'L1960': 'The calculations of Toscanelli Marin de Tyr, Esdras...\\n',\n",
       " 'L1959': 'How can you be so certain?\\n',\n",
       " 'L1958': 'Ignorance!  I believe the Indies are no more than 750 leagues west of the Canary Islands.\\n',\n",
       " 'L1957': 'How can you be so certain?  The Ocean is said to be infinite.\\n',\n",
       " 'L1952': 'To open a new route to Asia.  At the moment there are only two ways of reaching it...\\n',\n",
       " 'L1951': 'Why do you wish to sail west?\\n',\n",
       " 'L1950': 'With some difficulty.  I had to promise them you were not a total fool.\\n',\n",
       " 'L1949': 'How did you manage it?\\n',\n",
       " 'L1948': \"That's what it says.\\n\",\n",
       " 'L1947': \"God... That's in a week!\\n\",\n",
       " 'L1943': 'Father, I am doing what I think is the best for him.  And he has the teacher I would have chosen for myself.\\n',\n",
       " 'L1942': 'Diego is a bright boy -- a pleasure to teach -- but so serious... Brothers should be raised together, Colon.  Even brothers from different mothers...\\n',\n",
       " 'L2459': 'Your Majesty -- some men are content to read about things.  I must see them with my own eyes.  I cannot be other than I am.\\n',\n",
       " 'L2458': \"There is one thing I'd like to understand... Why do you want to go back, after all this?\\n\",\n",
       " 'L2457': 'Thank you.\\n',\n",
       " 'L2456': 'But without your brothers.  Nor are you to return to Santo Domingo or any of the other colonies.  You may explore the continent.\\n',\n",
       " 'L2280': 'They come and go as naked as the day God created them...\\n',\n",
       " 'L2279': 'Do they have such thoughts?\\n',\n",
       " 'L2086': 'Thirty seven, Your Majesty... And you?\\n',\n",
       " 'L2085': 'How old are you, Senor Colon?\\n',\n",
       " 'L2082': 'A woman?\\n',\n",
       " 'L2081': 'I know what I see.  I see someone who doesn\\'t accept the world as it is.  Who\\'s not afraid.  I see a women who thinks... \"What if?\"...\\n',\n",
       " 'L2080': 'You show no inclination to speak otherwise!\\n',\n",
       " 'L2079': 'May I speak freely?\\n',\n",
       " 'L2077': 'Surely you can do anything you want.\\n',\n",
       " 'L2076': 'I cannot ignore the verdict of my council.\\n',\n",
       " 'L2075': 'That she was impregnable.\\n',\n",
       " 'L2074': 'What did they say about Granada before today?\\n',\n",
       " 'L2073': 'The ocean is uncrossable?\\n',\n",
       " 'L2072': 'No more than the woman who said she would take Granada from the Moors.\\n',\n",
       " 'L2071': 'I should not even be listening to you, since my council said no.  But Santangel tells me you are a man of honor and sincerity... And Sanchez, that you are not a fool.\\n',\n",
       " 'L2389': 'You will regret this.\\n',\n",
       " 'L2388': \"You'll be held in detention, deprived of your privileges and possessions.  Until you are returned to Spain where you will be judged. Have you anything to say?\\n\",\n",
       " 'L2387': 'Savagery is what monkeys understand.\\n',\n",
       " 'L2386': 'In one act of brutality, you have created chaos.  Tribes who were fighting each other are now joining forces against us!  All that because of your criminal savagery!\\n',\n",
       " 'L2348': 'You did not hear me, Don Colon.  Not my horse.\\n',\n",
       " 'L2347': 'Don Moxica -- we all have to work.\\n',\n",
       " 'L2346': \"My horse doesn't work.\\n\",\n",
       " 'L2345': \"We can't raise the wheel without it.\\n\",\n",
       " 'L2333': 'We came here to stay!  To build! Not to start a crusade.  In this forest, there is enough danger to sweep us away in days!  So we will be brave and swallow our grief.  And in the name of those who died, we will accomplish what we came for.\\n',\n",
       " 'L2332': \"We don't need to know.\\n\",\n",
       " 'L2331': 'You want a war?  Fine.  We are a thousand.  They outnumber us by ten! Who will you kill?  Which tribe?\\n',\n",
       " 'L2329': \"If you want to keep your head on your shoulders, you'll do as I say.\\n\",\n",
       " 'L2328': 'We lost cousins, friends.  We will wash this in blood.\\n',\n",
       " 'L2278': 'The Indians have no such word, Don Moxica.\\n',\n",
       " 'L2277': \"And you say this is an Indian vice? By God!  I don't see any kind of pleasure that would make this a sin.\\n\",\n",
       " 'L2492': \"We can't be.\\n\",\n",
       " 'L2491': \"He's drawing an isthmus... He's saying we're on an isthmus.\\n\",\n",
       " 'L2490': \"What's he doing?\\n\",\n",
       " 'L2165': 'Twenty eight.\\n',\n",
       " 'L2164': 'What do you read?\\n',\n",
       " 'L2160': 'Come over here.\\n',\n",
       " 'L2159': \"Well, I surely know what a quadrant is!  But I've never seen it used at night before.\\n\",\n",
       " 'L2158': 'And what do you think Mendez?\\n',\n",
       " 'L2157': \"Well... It's the men, Sir.  They wonder how you know our position. We've lost sight from land days ago...\\n\",\n",
       " 'L2155': 'God be with us admiral.\\n',\n",
       " 'L2154': 'Due west, Captain Mendez.  And may God be with us...\\n',\n",
       " 'L2211': \"You're right.  Let the men decide.\\n\",\n",
       " 'L2210': 'You tell that to them!\\n',\n",
       " 'L2209': 'Pinzon, Pinzon... All we can do now is go forward!  Think about that!\\n',\n",
       " 'L2208': 'You bloody...\\n',\n",
       " 'L2207': 'You never did.  You did all the talking for both of us, remember?\\n',\n",
       " 'L2206': 'Jesus Maria!  I should have never listened to you!\\n',\n",
       " 'L2205': 'And then what?  Half of the water has gone, the rest is nearly putrid! You know that!\\n',\n",
       " 'L2204': \"You don't know anything!  Listen Colon, these are my ships, right? So I'm telling you we're turning back!\\n\",\n",
       " 'L2203': 'The land is there.  I know it!\\n',\n",
       " 'L2202': \"We're lost!\\n\",\n",
       " 'L2201': \"You think I don't know that?\\n\",\n",
       " 'L2200': \"We're on the verge of a mutiny, Colon!\\n\",\n",
       " 'L2199': 'We have to keep the hopes of these men alive!\\n',\n",
       " 'L2198': 'You must be mad...!\\n',\n",
       " 'L2197': 'Six days ago, yes.\\n',\n",
       " 'L2196': \"You lied!  You cheated!  We're way past 750 leagues!\\n\",\n",
       " 'L2065': 'Immediately.\\n',\n",
       " 'L2064': 'Where can I meet this man?\\n',\n",
       " 'L2462': 'Because he is not afraid of me.\\n',\n",
       " 'L2461': 'Then why?\\n',\n",
       " 'L2460': 'I know, I should not tolerate his impertinence.\\n',\n",
       " 'L2419': 'And who would you think of, for such a task?\\n',\n",
       " 'L2418': 'He must be replaced.\\n',\n",
       " 'L2417': 'Then, what do you suggest, Don Sanchez?\\n',\n",
       " 'L2415': 'Is this true, Brother Buyl?\\n',\n",
       " 'L2414': '... But there is worse.  He ordered the execution of five members of the nobility...\\n',\n",
       " 'L2377': \"We weren't expecting immediate profits, were we?  We must have faith.  We must give time for time.\\n\",\n",
       " 'L2376': 'Every ship returns with a cargo of sick and dying.  But with no gold! The new world proves expensive, Your Majesty.\\n',\n",
       " 'L2116': \"Yes.  It would be a pity, wouldn't it?  Call him back!\\n\",\n",
       " 'L2115': '... Into a monk...\\n',\n",
       " 'L2113': 'Never, Your Majesty.  Although...\\n',\n",
       " 'L2112': 'You were right, Don Sanchez... His demands could never be granted.\\n',\n",
       " 'L1931': 'Yes, Your Majesty.\\n',\n",
       " 'L1930': 'Is that the man I knew, Treasurer Sanchez?\\n',\n",
       " 'L3546': \"Officers, there's your killer, do your duty, arrest him!\\n\",\n",
       " 'L3545': '...so we kill someone famous and if we are caught, we are sent to mental hospital...\\n',\n",
       " 'L3497': \"I don't think it's abuse, I think it's torture.\\n\",\n",
       " 'L3496': \"I'm abused.  Don't you think?\\n\",\n",
       " 'L3493': 'Can I see your back?\\n',\n",
       " 'L3492': 'Out on my back when I was a small boy.\\n',\n",
       " 'L3491': 'Your father put cigarettes out on you?\\n',\n",
       " 'L3490': \"That's what he did to me.  He put cigarettes out on me.\\n\",\n",
       " 'L3489': 'Yeah, he hated me from day when I was born.  Put it out.  Can you put the cigarette out?\\n',\n",
       " 'L3488': \"Your father blamed you for your mother's blindness?\\n\",\n",
       " 'L3487': 'Yeah, yeah...bad doctor gave her bad drugs which made her go blind.  And my father blamed me for her blindness...\\n',\n",
       " 'L3486': 'Back in the Czech Republic?\\n',\n",
       " 'L3485': 'Yeah, she went blind giving birth to me. She went to fucking black market doctor to induce me.\\n',\n",
       " 'L3484': 'Your mother was blind?\\n',\n",
       " 'L3483': 'My father always degraded me.  Killed my self-esteem.  And my mother was blind.\\n',\n",
       " 'L3482': 'Tell me about yourself.  What you did as a young boy... what your parents were like.\\n',\n",
       " 'L3481': 'Give me another one, please.\\n',\n",
       " 'L3480': \"I need to know about your background.  I need to know about your upbringing.  Why you're here.\\n\",\n",
       " 'L3479': 'What else do you need?\\n',\n",
       " 'L3478': 'This is not about money, Emil.  I need your trust in me.\\n',\n",
       " 'L3477': \"Thirty-percent.  No more.  Or I call another lawyer.  This is the biggest case of your life.  Don't try to negotiate.  Thirty percent.  Say yes or no.\\n\",\n",
       " 'L3476': \"But it's...\\n\",\n",
       " 'L3475': 'No.  No way.\\n',\n",
       " 'L3474': 'I would say...half.  Half is fair.\\n',\n",
       " 'L3473': \"What's your cut?  How much?\\n\",\n",
       " 'L3472': \"Look, I haven't really focused on that kind of thing.\\n\",\n",
       " 'L3471': 'What about my movie rights?  Book rights?\\n',\n",
       " 'L3470': \"Don't worry about him.  Think about yourself.\\n\",\n",
       " 'L3469': 'No, he is here.  Shit...\\n',\n",
       " 'L3468': \"Disappeared.  They're looking everywhere.  Maybe he went back to Czechoslovakia.\\n\",\n",
       " 'L3467': 'What about Oleg?\\n',\n",
       " 'L3466': \"Well, you didn't appreciate the severity of it until recently.  No question about that.\\n\",\n",
       " 'L3465': 'I was all of these.\\n',\n",
       " 'L3464': '...delusions and paranoia.\\n',\n",
       " 'L3461': 'Oh, sure.\\n',\n",
       " 'L3460': 'You bring the cigarettes?\\n',\n",
       " 'L3459': \"I brought you some letters.  It's really fan mail.  Women mostly.  One wants to buy you clothes, another sent a check. Another wants a check.\\n\",\n",
       " 'L3396': \"I'm invoking rights - this man is represented by counsel.  I'm coming with him.\\n\",\n",
       " 'L3395': 'Yes.  Yes, come with me!\\n',\n",
       " 'L3394': \"I'm coming with you.\\n\",\n",
       " 'L3393': 'Where are we going?\\n',\n",
       " 'L3392': \"Don't say anything.\\n\",\n",
       " 'L3385': 'He has the camera!  He took the movie!\\n',\n",
       " 'L3384': 'Emil.  Take it easy.  Stay with me.  Sit down.  What do you need?  What are you looking for?\\n',\n",
       " 'L3383': 'Oh no!  No!  Shit!\\n',\n",
       " 'L3382': 'Here.  I have your money.\\n',\n",
       " 'L3381': \"I'm not your lawyer until I see the money.\\n\",\n",
       " 'L3380': \"Are you my attorney?  I'm Emil.  I'm insane.\\n\",\n",
       " 'L3517': 'Daphne, I...\\n',\n",
       " 'L3516': \"I don't want to drag you down with me.\\n\",\n",
       " 'L3515': '...Do you really want me to forget about you?\\n',\n",
       " 'L3514': 'Forget about me.  You have enough problems of your own.\\n',\n",
       " 'L3330': 'Pouring it out!\\n',\n",
       " 'L3329': 'What are you doing?\\n',\n",
       " 'L3318': \"I'll get my clothes.\\n\",\n",
       " 'L3317': \"I'll make some for us.\\n\",\n",
       " 'L3316': 'In the kitchen.\\n',\n",
       " 'L3315': 'Do you have coffee?\\n',\n",
       " ...}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1961,
     "status": "ok",
     "timestamp": 1665133698134,
     "user": {
      "displayName": "Kean Chan",
      "userId": "05792587367281359063"
     },
     "user_tz": -480
    },
    "id": "ER4dwYJDoZFU",
    "outputId": "c0ca8f0c-4610-4dc2-f386-09be4d2f139f"
   },
   "outputs": [],
   "source": [
    "### generate question answer pairs\n",
    "pairs = []\n",
    "for con in conv:\n",
    "    ids = eval(con.split(\" +++$+++ \")[-1])\n",
    "    for i in range(len(ids)):\n",
    "        qa_pairs = []\n",
    "\n",
    "        if i == len(ids) - 1:\n",
    "            break\n",
    "\n",
    "        first = lines_dic[ids[i]].strip()\n",
    "        second = lines_dic[ids[i+1]].strip()\n",
    "\n",
    "        qa_pairs.append(' '.join(first.split()[:MAX_LEN]))\n",
    "        qa_pairs.append(' '.join(second.split()[:MAX_LEN]))\n",
    "        pairs.append(qa_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1961,
     "status": "ok",
     "timestamp": 1665133698134,
     "user": {
      "displayName": "Kean Chan",
      "userId": "05792587367281359063"
     },
     "user_tz": -480
    },
    "id": "ER4dwYJDoZFU",
    "outputId": "c0ca8f0c-4610-4dc2-f386-09be4d2f139f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"I really, really, really wanna go, but I can't. Not unless my sister goes.\", \"I'm workin' on it. But she doesn't seem to be goin' for him.\"]\n"
     ]
    }
   ],
   "source": [
    "# sample\n",
    "print(pairs[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 868,
     "status": "ok",
     "timestamp": 1665133759805,
     "user": {
      "displayName": "Kean Chan",
      "userId": "05792587367281359063"
     },
     "user_tz": -480
    },
    "id": "c4K2nIFalnOz",
    "outputId": "9cda79b0-7da1-467a-ba83-09f1f0f9095d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 221616/221616 [00:00<00:00, 1934156.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# WordPiece tokenizer\n",
    "\n",
    "### save data as txt file\n",
    "# os.mkdir('./data')\n",
    "text_data = []\n",
    "file_count = 0\n",
    "\n",
    "for sample in tqdm.tqdm([x[0] for x in pairs]):\n",
    "    text_data.append(sample)\n",
    "\n",
    "    # once we hit the 10K mark, save to file\n",
    "    if len(text_data) == 10000:\n",
    "        with open(f'../../data/text_{file_count}.txt', 'w', encoding='utf-8') as fp:\n",
    "            fp.write('\\n'.join(text_data))\n",
    "        text_data = []\n",
    "        file_count += 1\n",
    "\n",
    "paths = [str(x) for x in Path('../../data').glob('**/text_*.txt')]\n",
    "print(len(paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3975,
     "status": "ok",
     "timestamp": 1665133790644,
     "user": {
      "displayName": "Kean Chan",
      "userId": "05792587367281359063"
     },
     "user_tz": -480
    },
    "id": "TzMa6PMWrJZj",
    "outputId": "9ba1f2ff-c7c5-42a3-a4d3-5de0ea35b338"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### training own tokenizer\n",
    "tokenizer = BertWordPieceTokenizer(\n",
    "    clean_text=True,\n",
    "    handle_chinese_chars=False,\n",
    "    strip_accents=False,\n",
    "    lowercase=True\n",
    ")\n",
    "\n",
    "tokenizer.train(\n",
    "    files=paths,\n",
    "    vocab_size=30_000,\n",
    "    min_frequency=5,\n",
    "    limit_alphabet=1000,\n",
    "    wordpieces_prefix='##',\n",
    "    special_tokens=['[PAD]', '[CLS]', '[SEP]', '[MASK]', '[UNK]']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3975,
     "status": "ok",
     "timestamp": 1665133790644,
     "user": {
      "displayName": "Kean Chan",
      "userId": "05792587367281359063"
     },
     "user_tz": -480
    },
    "id": "TzMa6PMWrJZj",
    "outputId": "9ba1f2ff-c7c5-42a3-a4d3-5de0ea35b338"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 48, 250, 4038, 3625, 154, 5, 2]\n",
      "['[CLS]', 'i', 'like', 'surf', '##board', '##ing', '!', '[SEP]']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2107: FutureWarning: Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated and won't be possible anymore in v5. Use a model identifier or the path to a directory instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# os.mkdir('../../data/bert-it-1')\n",
    "# tokenizer.save_model('../../data/bert-it-1', 'bert-it')\n",
    "tokenizer = BertTokenizer.from_pretrained('../../data/bert-it-1/bert-it-vocab.txt', local_files_only=True)\n",
    "token_ids = tokenizer('I like surfboarding!')['input_ids']\n",
    "print(token_ids)\n",
    "print(tokenizer.convert_ids_to_tokens(token_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab[\"[MASK]\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sbBU9BTdvlQ0"
   },
   "source": [
    "# 2) Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "bXCsfR3tmajw"
   },
   "outputs": [],
   "source": [
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, data_pair, tokenizer, seq_len=64):\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "        self.seq_len = seq_len\n",
    "        self.corpus_lines = len(data_pair)\n",
    "        self.lines = data_pair\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.corpus_lines\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "\n",
    "        # Step 1: get random sentence pair, either negative or positive (saved as is_next_label)\n",
    "        t1, t2, is_next_label = self.get_sent(item)\n",
    "\n",
    "        # Step 2: replace random words in sentence with mask / random words\n",
    "        t1_random, t1_label = self.random_word(t1)\n",
    "        t2_random, t2_label = self.random_word(t2)\n",
    "\n",
    "        # Step 3: Adding CLS and SEP tokens to the start and end of sentences\n",
    "        # Adding PAD token for labels\n",
    "        t1 = [self.tokenizer.vocab['[CLS]']] + t1_random + [self.tokenizer.vocab['[SEP]']]\n",
    "        t2 = t2_random + [self.tokenizer.vocab['[SEP]']]\n",
    "        t1_label = [self.tokenizer.vocab['[PAD]']] + t1_label + [self.tokenizer.vocab['[PAD]']]\n",
    "        t2_label = t2_label + [self.tokenizer.vocab['[PAD]']]\n",
    "\n",
    "        # Step 4: combine sentence 1 and 2 as one input\n",
    "        # adding PAD tokens to make the sentence same length as seq_len\n",
    "        segment_label = ([1 for _ in range(len(t1))] + [2 for _ in range(len(t2))])[:self.seq_len]\n",
    "        bert_input = (t1 + t2)[:self.seq_len]\n",
    "        bert_label = (t1_label + t2_label)[:self.seq_len]\n",
    "        padding = [self.tokenizer.vocab['[PAD]'] for _ in range(self.seq_len - len(bert_input))]\n",
    "        bert_input.extend(padding), bert_label.extend(padding), segment_label.extend(padding)\n",
    "\n",
    "        output = {\"bert_input\": bert_input,\n",
    "                  \"bert_label\": bert_label,\n",
    "                  \"segment_label\": segment_label,\n",
    "                  \"is_next\": is_next_label}\n",
    "\n",
    "        return {key: torch.tensor(value).to(\"cuda\") for key, value in output.items()}\n",
    "\n",
    "    def random_word(self, sentence):\n",
    "        tokens = sentence.split()\n",
    "        output_label = []\n",
    "        output = []\n",
    "\n",
    "        # 15% of the tokens would be replaced\n",
    "        for i, token in enumerate(tokens):\n",
    "            prob = random.random()\n",
    "\n",
    "            # remove cls and sep token\n",
    "            token_id = self.tokenizer(token)['input_ids'][1:-1]\n",
    "            #print(token, \"--->\", token_id)\n",
    "            # 15% chance of altering token\n",
    "            if prob < 0.15:\n",
    "                prob /= 0.15\n",
    "\n",
    "                # 80% chance change token to mask token\n",
    "                if prob < 0.8:\n",
    "                    for i in range(len(token_id)):\n",
    "                        if i/len(token_id) < prob:\n",
    "                            output.append(self.tokenizer.vocab['[MASK]'])\n",
    "                        else:\n",
    "                            output.append(token_id[i])\n",
    "\n",
    "                # 10% chance change token to random token\n",
    "                elif prob < 0.9:\n",
    "                    for i in range(len(token_id)):\n",
    "                        if i/len(token_id) < prob:\n",
    "                            output.append(random.randrange(len(self.tokenizer.vocab)))\n",
    "                        else:\n",
    "                            output.append(token_id[i])\n",
    "\n",
    "                # 10% chance change token to current token\n",
    "                else:\n",
    "                    output.append(token_id)\n",
    "\n",
    "                output_label.append(token_id)\n",
    "\n",
    "            else:\n",
    "                output.append(token_id)\n",
    "                for i in range(len(token_id)):\n",
    "                    output_label.append(0)\n",
    "\n",
    "        # flattening\n",
    "        output = list(itertools.chain(*[[x] if not isinstance(x, list) else x for x in output]))\n",
    "        output_label = list(itertools.chain(*[[x] if not isinstance(x, list) else x for x in output_label]))\n",
    "        assert len(output) == len(output_label)\n",
    "        return output, output_label\n",
    "\n",
    "    def get_sent(self, index):\n",
    "        '''return random sentence pair'''\n",
    "        t1, t2 = self.get_corpus_line(index)\n",
    "\n",
    "        # negative or positive pair, for next sentence prediction\n",
    "        if random.random() > 0.5:\n",
    "            return t1, t2, 1\n",
    "        else:\n",
    "            return t1, self.get_random_line(), 0\n",
    "\n",
    "    def get_corpus_line(self, item):\n",
    "        '''return sentence pair'''\n",
    "        return self.lines[item][0], self.lines[item][1]\n",
    "\n",
    "    def get_random_line(self):\n",
    "        '''return random single sentence'''\n",
    "        return self.lines[random.randrange(len(self.lines))][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4637,
     "status": "ok",
     "timestamp": 1665133798321,
     "user": {
      "displayName": "Kean Chan",
      "userId": "05792587367281359063"
     },
     "user_tz": -480
    },
    "id": "5RD5ta6KA_wK",
    "outputId": "3b408feb-a0ff-4d66-89a7-6e7e32a57ee3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "print(\"\\n\")\n",
    "train_data = BERTDataset(pairs, seq_len=MAX_LEN, tokenizer=tokenizer)\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True, pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4637,
     "status": "ok",
     "timestamp": 1665133798321,
     "user": {
      "displayName": "Kean Chan",
      "userId": "05792587367281359063"
     },
     "user_tz": -480
    },
    "id": "5RD5ta6KA_wK",
    "outputId": "3b408feb-a0ff-4d66-89a7-6e7e32a57ee3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size torch.Size([32, 64])\n"
     ]
    }
   ],
   "source": [
    "sample_data = next(iter(train_loader))\n",
    "print('Batch Size', sample_data['bert_input'].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bert_input': tensor([[    1, 11709,    11,  ...,     0,     0,     0],\n",
       "         [    1,    48,    11,  ...,     0,     0,     0],\n",
       "         [    1,   247,   146,  ...,     0,     0,     0],\n",
       "         ...,\n",
       "         [    1,   178,     3,  ...,     0,     0,     0],\n",
       "         [    1,   185,    34,  ...,     0,     0,     0],\n",
       "         [    1, 10075,   460,  ...,     0,     0,     0]], device='cuda:0'),\n",
       " 'bert_label': tensor([[  0,   0,   0,  ...,   0,   0,   0],\n",
       "         [  0,   0,   0,  ...,   0,   0,   0],\n",
       "         [  0,   0,   0,  ...,   0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0, 182,  ...,   0,   0,   0],\n",
       "         [  0, 185,  34,  ...,   0,   0,   0],\n",
       "         [  0, 146,   0,  ...,   0,   0,   0]], device='cuda:0'),\n",
       " 'segment_label': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'),\n",
       " 'is_next': tensor([0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1,\n",
       "         0, 1, 1, 1, 1, 0, 0, 1], device='cuda:0')}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'hot',\n",
       " 'dogs',\n",
       " '?',\n",
       " '[SEP]',\n",
       " '[MASK]',\n",
       " 'don',\n",
       " \"'\",\n",
       " 't',\n",
       " '[MASK]',\n",
       " 'so',\n",
       " '.',\n",
       " '[SEP]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(sample_data['bert_input'][9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4637,
     "status": "ok",
     "timestamp": 1665133798321,
     "user": {
      "displayName": "Kean Chan",
      "userId": "05792587367281359063"
     },
     "user_tz": -480
    },
    "id": "5RD5ta6KA_wK",
    "outputId": "3b408feb-a0ff-4d66-89a7-6e7e32a57ee3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bert_input': tensor([    1,   443,     3,     3,    48,   514,   146,   358,   700,    17,\n",
       "            48,   301,   146, 12389,   393,   211,  4885,  3436,  9685,    17,\n",
       "             2,     3,    15,   237,    48,  1850,   274,    17,   146,   231,\n",
       "           410,   162,    17,     3,    17,     2,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0], device='cuda:0'),\n",
       " 'bert_label': tensor([    0,     0,  1060,    15,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0, 18633,     0,     0,     0,     0,     0,     0,\n",
       "             0,   368,    15,     0,     0,     0,     0,     0,     0,     0,\n",
       "           410,   162,    17,   430,    17,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0], device='cuda:0'),\n",
       " 'segment_label': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0'),\n",
       " 'is_next': tensor(0, device='cuda:0')}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3 is MASK\n",
    "result = train_data[random.randrange(len(train_data))]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_ = BERTDataset(pairs[11:12], seq_len=MAX_LEN, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Right. See? You're ready for the quiz.\",\n",
       " \"I don't want to know how to say that though. I want to know useful things. Like where the good stores are. How much does champagne cost? Stuff like Chat. I have never in my life had to point out my head to someone.\"]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bert_input': tensor([    1,   308,    17,   301,    34,   146,    11,   181,  1144,   202,\n",
       "           150, 19713,    17,     2,     3,   204,    11,    59,   258,   153,\n",
       "           210,   268,   153,   311,   173,  1342,    17,    48,   258,   153,\n",
       "           210,  5690,   583,    17,   250,   333,   150,   334,  9108,   235,\n",
       "            17,   268,     3,   420,  4501,  1740,    34,     3,   250,  4151,\n",
       "            17,    48,   217,   408,   171,   218,   552,   387,   153,   972,\n",
       "           254,   218,   731,     3], device='cuda:0'),\n",
       " 'bert_label': tensor([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          48,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0, 153,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         493,   0,   0,   0,   0, 919,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0, 153], device='cuda:0'),\n",
       " 'segment_label': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " 'is_next': tensor(0, device='cuda:0')}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AT-uR5BXChcM"
   },
   "source": [
    "# 3) Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 804,
     "status": "ok",
     "timestamp": 1665133801248,
     "user": {
      "displayName": "Kean Chan",
      "userId": "05792587367281359063"
     },
     "user_tz": -480
    },
    "id": "S6Nr8gMt49dF",
    "outputId": "e834d002-629f-4d93-a5dd-4e56bf07ec1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64, 768])\n"
     ]
    }
   ],
   "source": [
    "### embedding\n",
    "class PositionalEmbedding_(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, max_len=128):\n",
    "        super().__init__()\n",
    "\n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model).float()\n",
    "        pe.require_grad = False\n",
    "\n",
    "        for pos in range(max_len):\n",
    "            # for each dimension of the each position\n",
    "            for i in range(0, d_model, 2):\n",
    "                pe[pos, i] = math.sin(pos / (10000 ** ((2 * i)/d_model)))\n",
    "                pe[pos, i + 1] = math.cos(pos / (10000 ** ((2 * (i + 1))/d_model)))\n",
    "\n",
    "        # include the batch size\n",
    "        self.pe = pe.unsqueeze(0)\n",
    "        # self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pe\n",
    "    \n",
    "\n",
    "class PositionalEmbedding(torch.nn.Module):\n",
    "    def __init__(self, d_model, max_len=128):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model).float()\n",
    "        for pos in range(max_len):\n",
    "            for i in range(0, d_model, 2):\n",
    "                pe[pos, i] = math.sin(pos / (10000 ** ((2 * i)/d_model)))\n",
    "                pe[pos, i + 1] = math.cos(pos / (10000 ** ((2 * (i + 1))/d_model)))\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))  # Ensures correct device handling\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pe[:, :x.size(1), :].to(x.device) \n",
    "    \n",
    "\n",
    "class BERTEmbedding(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    BERT Embedding which is consisted with under features\n",
    "        1. TokenEmbedding : normal embedding matrix\n",
    "        2. PositionalEmbedding : adding positional information using sin, cos\n",
    "        2. SegmentEmbedding : adding sentence segment info, (sent_A:1, sent_B:2)\n",
    "        sum of all these features are output of BERTEmbedding\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, embed_size, seq_len=128, dropout=0.1):\n",
    "        \"\"\"\n",
    "        :param vocab_size: total vocab size\n",
    "        :param embed_size: embedding size of token embedding\n",
    "        :param dropout: dropout rate\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "        self.embed_size = embed_size\n",
    "        # (m, seq_len) --> (m, seq_len, embed_size)\n",
    "        # padding_idx is not updated during training, remains as fixed pad (0)\n",
    "        self.token = torch.nn.Embedding(vocab_size, embed_size, padding_idx=0)\n",
    "        self.segment = torch.nn.Embedding(3, embed_size, padding_idx=0)\n",
    "        self.position = PositionalEmbedding(d_model=embed_size, max_len=seq_len)\n",
    "        self.dropout = torch.nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, sequence, segment_label):\n",
    "        x = self.token(sequence) + self.position(sequence) + self.segment(segment_label)\n",
    "        return self.dropout(x)\n",
    "\n",
    "### testing\n",
    "embed_layer = BERTEmbedding(vocab_size=len(tokenizer.vocab), embed_size=768, seq_len=MAX_LEN).to(\"cuda\")\n",
    "embed_result = embed_layer(sample_data['bert_input'], sample_data['segment_label'])\n",
    "print(embed_result.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1036,
     "status": "ok",
     "timestamp": 1665133802282,
     "user": {
      "displayName": "Kean Chan",
      "userId": "05792587367281359063"
     },
     "user_tz": -480
    },
    "id": "g7n6FOkOBWK2",
    "outputId": "61857fc3-c499-4a4f-a97d-2d5af268e2b1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 64, 768])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### attention layers\n",
    "class MultiHeadedAttention(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, heads, d_model, dropout=0.1):\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "\n",
    "        assert d_model % heads == 0\n",
    "        self.d_k = d_model // heads\n",
    "        self.heads = heads\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "        self.query = torch.nn.Linear(d_model, d_model)\n",
    "        self.key = torch.nn.Linear(d_model, d_model)\n",
    "        self.value = torch.nn.Linear(d_model, d_model)\n",
    "        self.output_linear = torch.nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, query, key, value, mask):\n",
    "        \"\"\"\n",
    "        query, key, value of shape: (batch_size, max_len, d_model)\n",
    "        mask of shape: (batch_size, 1, 1, max_words)\n",
    "        \"\"\"\n",
    "        # (batch_size, max_len, d_model)\n",
    "        query = self.query(query)\n",
    "        key = self.key(key)\n",
    "        value = self.value(value)\n",
    "\n",
    "        # (batch_size, max_len, d_model) --> (batch_size, max_len, h, d_k) --> (batch_size, h, max_len, d_k)\n",
    "        query = query.view(query.shape[0], -1, self.heads, self.d_k).permute(0, 2, 1, 3)\n",
    "        key = key.view(key.shape[0], -1, self.heads, self.d_k).permute(0, 2, 1, 3)\n",
    "        value = value.view(value.shape[0], -1, self.heads, self.d_k).permute(0, 2, 1, 3)\n",
    "\n",
    "        # (batch_size, h, max_len, d_k) matmul (batch_size, h, d_k, max_len) --> (batch_size, h, max_len, max_len)\n",
    "        scores = torch.matmul(query, key.permute(0, 1, 3, 2)) / math.sqrt(query.size(-1))\n",
    "\n",
    "        # fill 0 mask with super small number so it wont affect the softmax weight\n",
    "        # (batch_size, h, max_len, max_len)\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "\n",
    "        # (batch_size, h, max_len, max_len)\n",
    "        # softmax to put attention weight for all non-pad tokens\n",
    "        # max_len X max_len matrix of attention\n",
    "        weights = F.softmax(scores, dim=-1)\n",
    "        weights = self.dropout(weights)\n",
    "\n",
    "        # (batch_size, h, max_len, max_len) matmul (batch_size, h, max_len, d_k) --> (batch_size, h, max_len, d_k)\n",
    "        context = torch.matmul(weights, value)\n",
    "\n",
    "        # (batch_size, h, max_len, d_k) --> (batch_size, max_len, h, d_k) --> (batch_size, max_len, d_model)\n",
    "        context = context.permute(0, 2, 1, 3).contiguous().view(context.shape[0], -1, self.heads * self.d_k)\n",
    "\n",
    "        # (batch_size, max_len, d_model)\n",
    "        return self.output_linear(context)\n",
    "\n",
    "class FeedForward(torch.nn.Module):\n",
    "    \"Implements FFN equation\"\n",
    "\n",
    "    def __init__(self, d_model, middle_dim=2048, dropout=0.1):\n",
    "        super(FeedForward, self).__init__()\n",
    "\n",
    "        self.fc1 = torch.nn.Linear(d_model, middle_dim)\n",
    "        self.fc2 = torch.nn.Linear(middle_dim, d_model)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        self.activation = torch.nn.GELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.activation(self.fc1(x))\n",
    "        out = self.fc2(self.dropout(out))\n",
    "        return out\n",
    "\n",
    "class EncoderLayer(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_model=768,\n",
    "        heads=12,\n",
    "        feed_forward_hidden=768 * 4,\n",
    "        dropout=0.1\n",
    "        ):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.layernorm = torch.nn.LayerNorm(d_model)\n",
    "        self.self_multihead = MultiHeadedAttention(heads, d_model)\n",
    "        self.feed_forward = FeedForward(d_model, middle_dim=feed_forward_hidden)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, embeddings, mask):\n",
    "        # embeddings: (batch_size, max_len, d_model)\n",
    "        # encoder mask: (batch_size, 1, 1, max_len)\n",
    "        # result: (batch_size, max_len, d_model)\n",
    "        interacted = self.dropout(self.self_multihead(embeddings, embeddings, embeddings, mask))\n",
    "        # residual layer\n",
    "        interacted = self.layernorm(interacted + embeddings)\n",
    "        # bottleneck\n",
    "        feed_forward_out = self.dropout(self.feed_forward(interacted))\n",
    "        encoded = self.layernorm(feed_forward_out + interacted)\n",
    "        return encoded\n",
    "\n",
    "### testing\n",
    "mask = (sample_data['bert_input'] > 0).unsqueeze(1).repeat(1, sample_data['bert_input'].size(1), 1).unsqueeze(1)\n",
    "transformer_block = EncoderLayer().to(\"cuda\")\n",
    "transformer_result = transformer_block(embed_result, mask)\n",
    "transformer_result.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15539,
     "status": "ok",
     "timestamp": 1665133817819,
     "user": {
      "displayName": "Kean Chan",
      "userId": "05792587367281359063"
     },
     "user_tz": -480
    },
    "id": "T4am76N6Cimj",
    "outputId": "e0b849c5-50c2-4f15-b1f0-f08fbe95fc90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64, 256])\n",
      "torch.Size([32, 2]) torch.Size([32, 64, 21304])\n"
     ]
    }
   ],
   "source": [
    "class BERT(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    BERT model : Bidirectional Encoder Representations from Transformers.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, d_model=256, n_layers=8, heads=4, max_len=128, dropout=0.1):\n",
    "        \"\"\"\n",
    "        :param vocab_size: vocab_size of total words\n",
    "        :param hidden: BERT model hidden size\n",
    "        :param n_layers: numbers of Transformer blocks(layers)\n",
    "        :param attn_heads: number of attention heads\n",
    "        :param dropout: dropout rate\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.n_layers = n_layers\n",
    "        self.heads = heads\n",
    "\n",
    "        # paper noted they used 4*hidden_size for ff_network_hidden_size\n",
    "        self.feed_forward_hidden = d_model * 4\n",
    "\n",
    "        # embedding for BERT, sum of positional, segment, token embeddings\n",
    "        self.embedding = BERTEmbedding(vocab_size=vocab_size, embed_size=d_model, seq_len=max_len).to(\"cuda\")\n",
    "\n",
    "        # multi-layers transformer blocks, deep network\n",
    "        self.encoder_blocks = torch.nn.ModuleList(\n",
    "            [EncoderLayer(d_model, heads, d_model * 4, dropout).to(\"cuda\") for _ in range(n_layers)])\n",
    "\n",
    "    def forward(self, x, segment_info):\n",
    "        # attention masking for padded token\n",
    "        # (batch_size, 1, seq_len, seq_len)\n",
    "        mask = (x > 0).unsqueeze(1).repeat(1, x.size(1), 1).unsqueeze(1)\n",
    "\n",
    "        # embedding the indexed sequence to sequence of vectors\n",
    "        x = self.embedding(x, segment_info)\n",
    "        \n",
    "        # running over multiple transformer blocks\n",
    "        for encoder in self.encoder_blocks:\n",
    "            x = encoder.forward(x, mask)\n",
    "        return x\n",
    "\n",
    "class NextSentencePrediction(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    2-class classification model : is_next, is_not_next\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hidden):\n",
    "        \"\"\"\n",
    "        :param hidden: BERT model output size\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(hidden, 2)\n",
    "        self.softmax = torch.nn.LogSoftmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # use only the first token which is the [CLS]\n",
    "        return self.softmax(self.linear(x[:, 0]))\n",
    "\n",
    "class MaskedLanguageModel(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    predicting origin token from masked input sequence\n",
    "    n-class classification problem, n-class = vocab_size\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hidden, vocab_size):\n",
    "        \"\"\"\n",
    "        :param hidden: output size of BERT model\n",
    "        :param vocab_size: total vocab size\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(hidden, vocab_size)\n",
    "        self.softmax = torch.nn.LogSoftmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.softmax(self.linear(x))\n",
    "\n",
    "class BERTLM(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    BERT Language Model\n",
    "    Next Sentence Prediction Model + Masked Language Model\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, bert: BERT, vocab_size):\n",
    "        \"\"\"\n",
    "        :param bert: BERT model which should be trained\n",
    "        :param vocab_size: total vocab size for masked_lm\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "        self.bert = bert\n",
    "        self.next_sentence = NextSentencePrediction(self.bert.d_model)\n",
    "        self.mask_lm = MaskedLanguageModel(self.bert.d_model, vocab_size)\n",
    "\n",
    "    def forward(self, x, segment_label):\n",
    "        x = self.bert(x, segment_label)\n",
    "        return self.next_sentence(x), self.mask_lm(x)\n",
    "\n",
    "### test\n",
    "bert_model = BERT(len(tokenizer.vocab)).to(\"cuda\")\n",
    "bert_result = bert_model(sample_data['bert_input'], sample_data['segment_label'])\n",
    "print(bert_result.size())\n",
    "\n",
    "bert_lm = BERTLM(bert_model, len(tokenizer.vocab)).to(\"cuda\")\n",
    "final_result = bert_lm(sample_data['bert_input'], sample_data['segment_label'])\n",
    "print(final_result[0].size(), final_result[1].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nnp98JEZWwgN"
   },
   "source": [
    "# 4) Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "0PPi4L1sCjBf"
   },
   "outputs": [],
   "source": [
    "### optimizer\n",
    "class ScheduledOptim():\n",
    "    '''A simple wrapper class for learning rate scheduling'''\n",
    "\n",
    "    def __init__(self, optimizer, d_model, n_warmup_steps):\n",
    "        self._optimizer = optimizer\n",
    "        self.n_warmup_steps = n_warmup_steps\n",
    "        self.n_current_steps = 0\n",
    "        self.init_lr = np.power(d_model, -0.5)\n",
    "\n",
    "    def step_and_update_lr(self):\n",
    "        \"Step with the inner optimizer\"\n",
    "        self._update_learning_rate()\n",
    "        self._optimizer.step()\n",
    "\n",
    "    def zero_grad(self):\n",
    "        \"Zero out the gradients by the inner optimizer\"\n",
    "        self._optimizer.zero_grad()\n",
    "\n",
    "    def _get_lr_scale(self):\n",
    "        return np.min([\n",
    "            np.power(self.n_current_steps, -0.5),\n",
    "            np.power(self.n_warmup_steps, -1.5) * self.n_current_steps])\n",
    "\n",
    "    def _update_learning_rate(self):\n",
    "        ''' Learning rate scheduling per step '''\n",
    "\n",
    "        self.n_current_steps += 1\n",
    "        lr = self.init_lr * self._get_lr_scale()\n",
    "\n",
    "        for param_group in self._optimizer.param_groups:\n",
    "            param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IEggGpx2kUXx",
    "outputId": "578f0c3c-930b-41a8-8b3c-592d3888ecac",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters: 17244218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:   0%|| 1/3463 [00:00<17:41,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 0, 'avg_loss': 11.064160346984863, 'avg_acc': 48.4375, 'loss': 11.064160346984863}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:   0%|| 11/3463 [00:02<15:04,  3.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 10, 'avg_loss': 11.042526591907848, 'avg_acc': 49.715909090909086, 'loss': 10.989319801330566}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:   1%|| 21/3463 [00:05<14:40,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 20, 'avg_loss': 10.952872821262904, 'avg_acc': 49.107142857142854, 'loss': 10.732012748718262}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:   1%|| 31/3463 [00:08<14:37,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 30, 'avg_loss': 10.81309066280242, 'avg_acc': 49.596774193548384, 'loss': 10.323813438415527}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:   1%|| 41/3463 [00:10<15:02,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 40, 'avg_loss': 10.620949303231589, 'avg_acc': 49.885670731707314, 'loss': 9.710350036621094}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:   1%|| 51/3463 [00:13<15:32,  3.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 50, 'avg_loss': 10.377413001714968, 'avg_acc': 50.18382352941176, 'loss': 9.083040237426758}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:   2%|| 61/3463 [00:16<15:44,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 60, 'avg_loss': 10.094384881316639, 'avg_acc': 50.435450819672134, 'loss': 8.253893852233887}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:   2%|| 71/3463 [00:19<15:28,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 70, 'avg_loss': 9.764720191418284, 'avg_acc': 50.63820422535211, 'loss': 7.337224960327148}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:   2%|| 81/3463 [00:21<14:49,  3.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 80, 'avg_loss': 9.403566766668249, 'avg_acc': 50.88734567901234, 'loss': 6.45443058013916}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:   3%|| 91/3463 [00:24<15:38,  3.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 90, 'avg_loss': 9.031156277918553, 'avg_acc': 50.94436813186813, 'loss': 5.697570323944092}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:   3%|| 101/3463 [00:27<15:30,  3.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 100, 'avg_loss': 8.651605417232702, 'avg_acc': 50.58787128712871, 'loss': 4.902891159057617}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:   3%|| 111/3463 [00:29<14:57,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 110, 'avg_loss': 8.274990867924046, 'avg_acc': 50.54898648648649, 'loss': 4.161083698272705}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:   3%|| 121/3463 [00:32<15:14,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 120, 'avg_loss': 7.912814902865197, 'avg_acc': 50.503615702479344, 'loss': 3.644195795059204}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:   4%|| 131/3463 [00:35<15:35,  3.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 130, 'avg_loss': 7.575759179719531, 'avg_acc': 50.50095419847328, 'loss': 3.22108793258667}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:   4%|| 141/3463 [00:38<15:19,  3.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 140, 'avg_loss': 7.265835645351004, 'avg_acc': 50.47650709219859, 'loss': 3.1240081787109375}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:   4%|| 151/3463 [00:41<15:24,  3.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 150, 'avg_loss': 6.981944695213772, 'avg_acc': 50.403559602649004, 'loss': 2.8914730548858643}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:   5%|| 161/3463 [00:43<15:20,  3.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 160, 'avg_loss': 6.71947419421273, 'avg_acc': 50.38819875776398, 'loss': 2.731844902038574}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:   5%|| 171/3463 [00:46<15:14,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 170, 'avg_loss': 6.48205214076572, 'avg_acc': 50.447733918128655, 'loss': 2.5523569583892822}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:   5%|| 181/3463 [00:49<15:59,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 180, 'avg_loss': 6.265881206449224, 'avg_acc': 50.58701657458563, 'loss': 2.5329079627990723}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:   6%|| 191/3463 [00:52<15:52,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 190, 'avg_loss': 6.06890596769243, 'avg_acc': 50.646269633507856, 'loss': 2.5480520725250244}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:   6%|| 201/3463 [00:55<14:55,  3.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 200, 'avg_loss': 5.887733497429843, 'avg_acc': 50.60634328358209, 'loss': 2.4269275665283203}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:   6%|| 211/3463 [00:58<15:47,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 210, 'avg_loss': 5.721935821370491, 'avg_acc': 50.770142180094794, 'loss': 2.4148659706115723}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:   6%|| 221/3463 [01:00<14:43,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 220, 'avg_loss': 5.569748076917898, 'avg_acc': 50.664592760180994, 'loss': 2.3990750312805176}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:   7%|| 231/3463 [01:03<14:54,  3.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 230, 'avg_loss': 5.427403742100769, 'avg_acc': 50.62229437229438, 'loss': 2.2664451599121094}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:   7%|| 241/3463 [01:06<15:02,  3.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 240, 'avg_loss': 5.295655626479026, 'avg_acc': 50.615923236514526, 'loss': 2.1995253562927246}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:   7%|| 251/3463 [01:09<14:57,  3.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 250, 'avg_loss': 5.173335044032549, 'avg_acc': 50.535358565737056, 'loss': 2.256549119949341}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:   8%|| 261/3463 [01:12<14:36,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 260, 'avg_loss': 5.057576077194506, 'avg_acc': 50.71240421455939, 'loss': 2.0968105792999268}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:   8%|| 271/3463 [01:14<14:41,  3.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 270, 'avg_loss': 4.948595905655864, 'avg_acc': 50.743773062730625, 'loss': 2.0928256511688232}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:   8%|| 281/3463 [01:17<14:16,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 280, 'avg_loss': 4.844958416931994, 'avg_acc': 50.70062277580071, 'loss': 2.063168525695801}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:   8%|| 291/3463 [01:20<15:03,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 290, 'avg_loss': 4.748857915606286, 'avg_acc': 50.69802405498282, 'loss': 2.2306814193725586}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:   9%|| 301/3463 [01:23<15:24,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 300, 'avg_loss': 4.658086286826784, 'avg_acc': 50.814991694352166, 'loss': 2.0115902423858643}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:   9%|| 311/3463 [01:25<14:10,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 310, 'avg_loss': 4.571768634572289, 'avg_acc': 50.854099678456585, 'loss': 1.8984904289245605}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:   9%|| 321/3463 [01:28<14:49,  3.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 320, 'avg_loss': 4.490426055738859, 'avg_acc': 50.803154205607484, 'loss': 1.9634464979171753}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  10%|| 331/3463 [01:31<14:45,  3.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 330, 'avg_loss': 4.412451852844561, 'avg_acc': 50.807212990936556, 'loss': 1.8468270301818848}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  10%|| 341/3463 [01:34<14:30,  3.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 340, 'avg_loss': 4.337791433082647, 'avg_acc': 50.81103372434017, 'loss': 1.8333005905151367}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  10%|| 351/3463 [01:37<14:13,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 350, 'avg_loss': 4.266229127207373, 'avg_acc': 50.81463675213676, 'loss': 1.8416192531585693}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  10%|| 361/3463 [01:39<14:42,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 360, 'avg_loss': 4.199109389841391, 'avg_acc': 50.76610110803325, 'loss': 1.809220314025879}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  11%|| 371/3463 [01:42<14:21,  3.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 370, 'avg_loss': 4.1335630741402145, 'avg_acc': 50.787567385444746, 'loss': 1.7230408191680908}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  11%|| 381/3463 [01:45<14:59,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 380, 'avg_loss': 4.071981276114156, 'avg_acc': 50.799704724409445, 'loss': 1.7700457572937012}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  11%|| 391/3463 [01:48<14:20,  3.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 390, 'avg_loss': 4.012487551745246, 'avg_acc': 50.80322890025576, 'loss': 1.7577838897705078}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  12%|| 401/3463 [01:51<14:18,  3.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 400, 'avg_loss': 3.955343697433757, 'avg_acc': 50.76371571072319, 'loss': 1.7360895872116089}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  12%|| 411/3463 [01:54<16:04,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 410, 'avg_loss': 3.900573527435897, 'avg_acc': 50.669099756691, 'loss': 1.7131435871124268}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  12%|| 421/3463 [01:56<14:12,  3.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 420, 'avg_loss': 3.8484418547918, 'avg_acc': 50.638361045130644, 'loss': 1.6981916427612305}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  12%|| 431/3463 [01:59<14:20,  3.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 430, 'avg_loss': 3.7980961368144803, 'avg_acc': 50.605423433874705, 'loss': 1.6600944995880127}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  13%|| 441/3463 [02:02<14:02,  3.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 440, 'avg_loss': 3.749583765763004, 'avg_acc': 50.577522675736965, 'loss': 1.5634042024612427}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  13%|| 451/3463 [02:05<13:51,  3.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 450, 'avg_loss': 3.703138023416642, 'avg_acc': 50.50235587583148, 'loss': 1.7224621772766113}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  13%|| 461/3463 [02:08<13:46,  3.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 460, 'avg_loss': 3.6580476104049517, 'avg_acc': 50.508405639913235, 'loss': 1.60787034034729}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  14%|| 471/3463 [02:11<14:00,  3.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 470, 'avg_loss': 3.6136383623074573, 'avg_acc': 50.43789808917197, 'loss': 1.6017255783081055}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  14%|| 481/3463 [02:13<13:56,  3.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 480, 'avg_loss': 3.570725475923931, 'avg_acc': 50.432042619542614, 'loss': 1.6276061534881592}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  14%|| 491/3463 [02:16<13:54,  3.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 490, 'avg_loss': 3.5299169793876755, 'avg_acc': 50.40414969450102, 'loss': 1.606286644935608}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  14%|| 501/3463 [02:19<13:41,  3.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 500, 'avg_loss': 3.4910830625754867, 'avg_acc': 50.358657684630735, 'loss': 1.608565092086792}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  15%|| 511/3463 [02:22<13:29,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 510, 'avg_loss': 3.453098151781788, 'avg_acc': 50.34246575342466, 'loss': 1.558274745941162}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  15%|| 521/3463 [02:25<15:31,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 520, 'avg_loss': 3.4168233102663006, 'avg_acc': 50.437859884836854, 'loss': 1.5082417726516724}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  15%|| 531/3463 [02:27<13:33,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 530, 'avg_loss': 3.381413204297283, 'avg_acc': 50.43255649717514, 'loss': 1.594383716583252}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  16%|| 541/3463 [02:30<14:15,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 540, 'avg_loss': 3.3473126297737448, 'avg_acc': 50.447666358595185, 'loss': 1.594757080078125}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  16%|| 551/3463 [02:33<13:11,  3.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 550, 'avg_loss': 3.314580990484968, 'avg_acc': 50.46506352087115, 'loss': 1.4976401329040527}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  16%|| 561/3463 [02:36<13:05,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 560, 'avg_loss': 3.2819234683126903, 'avg_acc': 50.453988413547236, 'loss': 1.4764823913574219}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  16%|| 571/3463 [02:39<13:41,  3.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 570, 'avg_loss': 3.250801617543877, 'avg_acc': 50.470665499124344, 'loss': 1.5681931972503662}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  17%|| 581/3463 [02:41<13:18,  3.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 580, 'avg_loss': 3.2205489580479423, 'avg_acc': 50.47870051635112, 'loss': 1.4308552742004395}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  17%|| 591/3463 [02:44<14:13,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 590, 'avg_loss': 3.191144521264659, 'avg_acc': 50.452093908629436, 'loss': 1.5001676082611084}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  17%|| 601/3463 [02:47<13:28,  3.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 600, 'avg_loss': 3.1624712515591384, 'avg_acc': 50.49656821963394, 'loss': 1.423638105392456}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  18%|| 611/3463 [02:50<13:36,  3.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 610, 'avg_loss': 3.134768659276385, 'avg_acc': 50.508899345335514, 'loss': 1.4674564599990845}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  18%|| 621/3463 [02:53<13:17,  3.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 620, 'avg_loss': 3.107339857089155, 'avg_acc': 50.40760869565217, 'loss': 1.4554481506347656}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  18%|| 631/3463 [02:56<13:54,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 630, 'avg_loss': 3.0805273828718063, 'avg_acc': 50.41848256735341, 'loss': 1.4262667894363403}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  19%|| 641/3463 [02:58<12:39,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 640, 'avg_loss': 3.0543331871166615, 'avg_acc': 50.40220358814352, 'loss': 1.3779809474945068}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  19%|| 651/3463 [03:01<13:09,  3.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 650, 'avg_loss': 3.0292575562604562, 'avg_acc': 50.403225806451616, 'loss': 1.4157928228378296}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  19%|| 661/3463 [03:04<13:45,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 660, 'avg_loss': 3.005180526248626, 'avg_acc': 50.34512102874432, 'loss': 1.3684340715408325}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  19%|| 671/3463 [03:07<13:43,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 670, 'avg_loss': 2.9817725976071308, 'avg_acc': 50.36093517138599, 'loss': 1.4405956268310547}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  20%|| 681/3463 [03:10<13:31,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 680, 'avg_loss': 2.959290549443507, 'avg_acc': 50.37628487518355, 'loss': 1.512922763824463}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  20%|| 691/3463 [03:13<12:37,  3.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 690, 'avg_loss': 2.9366892143199825, 'avg_acc': 50.43415340086831, 'loss': 1.366170883178711}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  20%|| 701/3463 [03:16<12:25,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 700, 'avg_loss': 2.9149484464343365, 'avg_acc': 50.44579172610556, 'loss': 1.3542821407318115}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  21%|| 711/3463 [03:18<12:26,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 710, 'avg_loss': 2.8943546929942907, 'avg_acc': 50.4395218002813, 'loss': 1.4410353899002075}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  21%|| 721/3463 [03:21<12:44,  3.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 720, 'avg_loss': 2.87339600594133, 'avg_acc': 50.452929958391124, 'loss': 1.3356707096099854}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  21%|| 731/3463 [03:24<13:14,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 730, 'avg_loss': 2.8534834681718357, 'avg_acc': 50.40825923392613, 'loss': 1.5284442901611328}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  21%|| 741/3463 [03:27<13:03,  3.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 740, 'avg_loss': 2.8339926832922395, 'avg_acc': 50.45335695006747, 'loss': 1.4517512321472168}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  22%|| 751/3463 [03:30<12:19,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 750, 'avg_loss': 2.814842209517559, 'avg_acc': 50.45148135818908, 'loss': 1.2829430103302002}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  22%|| 761/3463 [03:33<12:13,  3.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 760, 'avg_loss': 2.7960522978440534, 'avg_acc': 50.41475032851511, 'loss': 1.3780567646026611}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  22%|| 771/3463 [03:35<12:09,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 770, 'avg_loss': 2.777261776064466, 'avg_acc': 50.39721141374838, 'loss': 1.4085432291030884}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  23%|| 781/3463 [03:38<12:25,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 780, 'avg_loss': 2.7593118503365415, 'avg_acc': 50.3661171574904, 'loss': 1.3366742134094238}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  23%|| 791/3463 [03:41<12:20,  3.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 790, 'avg_loss': 2.74227611289163, 'avg_acc': 50.32988305941846, 'loss': 1.3747334480285645}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  23%|| 801/3463 [03:44<12:05,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 800, 'avg_loss': 2.7256634820266608, 'avg_acc': 50.34917290886391, 'loss': 1.5586915016174316}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  23%|| 811/3463 [03:46<12:16,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 810, 'avg_loss': 2.708668427608457, 'avg_acc': 50.33523427866831, 'loss': 1.362011194229126}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  24%|| 821/3463 [03:49<12:30,  3.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 820, 'avg_loss': 2.692187973991236, 'avg_acc': 50.28547503045067, 'loss': 1.3111262321472168}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  24%|| 831/3463 [03:52<12:57,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 830, 'avg_loss': 2.675907356070554, 'avg_acc': 50.312123947051745, 'loss': 1.328399896621704}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  24%|| 841/3463 [03:55<12:08,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 840, 'avg_loss': 2.6604885272548824, 'avg_acc': 50.32141795481569, 'loss': 1.2746193408966064}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  25%|| 851/3463 [03:58<12:14,  3.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 850, 'avg_loss': 2.645149083871539, 'avg_acc': 50.31029670975323, 'loss': 1.3657395839691162}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  25%|| 861/3463 [04:01<12:56,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 860, 'avg_loss': 2.6305550598516696, 'avg_acc': 50.31213704994193, 'loss': 1.3961849212646484}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  25%|| 871/3463 [04:04<12:38,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 870, 'avg_loss': 2.6162464286101264, 'avg_acc': 50.30675947187141, 'loss': 1.3866848945617676}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  25%|| 881/3463 [04:07<13:03,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 880, 'avg_loss': 2.6019778825368025, 'avg_acc': 50.299730419977294, 'loss': 1.285130500793457}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  26%|| 891/3463 [04:10<12:03,  3.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 890, 'avg_loss': 2.5879397659858334, 'avg_acc': 50.292859147025816, 'loss': 1.28025221824646}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  26%|| 901/3463 [04:12<11:53,  3.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 900, 'avg_loss': 2.5739492794517407, 'avg_acc': 50.27920366259712, 'loss': 1.2865521907806396}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  26%|| 911/3463 [04:15<11:41,  3.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 910, 'avg_loss': 2.560358509143281, 'avg_acc': 50.27785400658617, 'loss': 1.2998626232147217}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  27%|| 921/3463 [04:18<11:40,  3.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 920, 'avg_loss': 2.5468354341649855, 'avg_acc': 50.283319761129206, 'loss': 1.286390781402588}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  27%|| 931/3463 [04:21<11:25,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 930, 'avg_loss': 2.533210014938412, 'avg_acc': 50.243353920515574, 'loss': 1.257272720336914}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  27%|| 941/3463 [04:23<11:53,  3.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 940, 'avg_loss': 2.5200879219107875, 'avg_acc': 50.244088735387884, 'loss': 1.2907686233520508}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  27%|| 951/3463 [04:26<11:25,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 950, 'avg_loss': 2.5066945141672963, 'avg_acc': 50.262881177707676, 'loss': 1.245567798614502}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  28%|| 961/3463 [04:29<11:31,  3.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 960, 'avg_loss': 2.4938028357403583, 'avg_acc': 50.26339750260146, 'loss': 1.2750887870788574}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  28%|| 971/3463 [04:32<12:09,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 970, 'avg_loss': 2.4812558176097617, 'avg_acc': 50.236547373841404, 'loss': 1.2847785949707031}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  28%|| 981/3463 [04:35<11:50,  3.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 980, 'avg_loss': 2.469045634420397, 'avg_acc': 50.24687818552498, 'loss': 1.2826626300811768}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  29%|| 991/3463 [04:38<12:22,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 990, 'avg_loss': 2.456616582591406, 'avg_acc': 50.2412336024218, 'loss': 1.3360941410064697}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  29%|| 1001/3463 [04:40<11:28,  3.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 1000, 'avg_loss': 2.4447295157225817, 'avg_acc': 50.22633616383616, 'loss': 1.311579942703247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  29%|| 1011/3463 [04:43<11:35,  3.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 1010, 'avg_loss': 2.4327931996033287, 'avg_acc': 50.211733432245296, 'loss': 1.2316865921020508}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  29%|| 1021/3463 [04:46<13:10,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 1020, 'avg_loss': 2.421010383779692, 'avg_acc': 50.17446131243879, 'loss': 1.2435944080352783}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  30%|| 1031/3463 [04:49<11:17,  3.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 1030, 'avg_loss': 2.409359481239874, 'avg_acc': 50.16973811833172, 'loss': 1.2200098037719727}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  30%|| 1041/3463 [04:52<11:16,  3.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 1040, 'avg_loss': 2.3982503834421194, 'avg_acc': 50.14109029779059, 'loss': 1.247941255569458}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  30%|| 1051/3463 [04:55<11:06,  3.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 1050, 'avg_loss': 2.3870420992431134, 'avg_acc': 50.13826117982874, 'loss': 1.2000298500061035}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  31%|| 1061/3463 [04:58<10:39,  3.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 1060, 'avg_loss': 2.3760672289734175, 'avg_acc': 50.138430725730444, 'loss': 1.1713216304779053}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  31%|| 1071/3463 [05:00<10:56,  3.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 1070, 'avg_loss': 2.365300089482611, 'avg_acc': 50.14443277310925, 'loss': 1.262951135635376}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  31%|| 1081/3463 [05:03<11:02,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 1080, 'avg_loss': 2.354667057051469, 'avg_acc': 50.141651248843665, 'loss': 1.272630214691162}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  32%|| 1091/3463 [05:06<11:10,  3.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 1090, 'avg_loss': 2.344434586060801, 'avg_acc': 50.16183547204399, 'loss': 1.2246350049972534}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  32%|| 1101/3463 [05:09<10:45,  3.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 1100, 'avg_loss': 2.3341735950066327, 'avg_acc': 50.127724795640326, 'loss': 1.2125701904296875}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  32%|| 1111/3463 [05:12<11:46,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 1110, 'avg_loss': 2.324049287932505, 'avg_acc': 50.129387938793876, 'loss': 1.2234764099121094}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  32%|| 1121/3463 [05:15<10:58,  3.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 1120, 'avg_loss': 2.3143255259712077, 'avg_acc': 50.12126449598573, 'loss': 1.1562248468399048}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  33%|| 1131/3463 [05:17<10:52,  3.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 1130, 'avg_loss': 2.304487832872136, 'avg_acc': 50.12295534924846, 'loss': 1.111325979232788}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  33%|| 1141/3463 [05:20<10:35,  3.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 1140, 'avg_loss': 2.2948139567421153, 'avg_acc': 50.09859772129711, 'loss': 1.1846946477890015}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  33%|| 1151/3463 [05:23<11:10,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 1150, 'avg_loss': 2.2854293671822568, 'avg_acc': 50.130321459600346, 'loss': 1.2541110515594482}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  34%|| 1161/3463 [05:26<10:51,  3.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 1160, 'avg_loss': 2.2761021644056716, 'avg_acc': 50.11170327304049, 'loss': 1.2434971332550049}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  34%|| 1171/3463 [05:29<10:36,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 1170, 'avg_loss': 2.2668288026886247, 'avg_acc': 50.086731426131514, 'loss': 1.1802557706832886}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  34%|| 1181/3463 [05:32<10:18,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 1180, 'avg_loss': 2.2577186783524916, 'avg_acc': 50.113780694326834, 'loss': 1.1805131435394287}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  34%|| 1191/3463 [05:34<10:30,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 1190, 'avg_loss': 2.248835112446001, 'avg_acc': 50.10888958858103, 'loss': 1.1993134021759033}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  35%|| 1201/3463 [05:37<10:38,  3.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 1200, 'avg_loss': 2.239850432846965, 'avg_acc': 50.096273938384684, 'loss': 1.2066700458526611}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  35%|| 1211/3463 [05:40<10:27,  3.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 1210, 'avg_loss': 2.231117353273954, 'avg_acc': 50.09289843104872, 'loss': 1.1009774208068848}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  35%|| 1221/3463 [05:43<10:37,  3.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 1220, 'avg_loss': 2.2226515340570736, 'avg_acc': 50.09981572481572, 'loss': 1.1882449388504028}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  36%|| 1231/3463 [05:46<10:06,  3.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 1230, 'avg_loss': 2.214237671378761, 'avg_acc': 50.10281275385865, 'loss': 1.1781153678894043}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  36%|| 1241/3463 [05:48<09:54,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 1240, 'avg_loss': 2.206079930187136, 'avg_acc': 50.09317082997583, 'loss': 1.245970606803894}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  36%|| 1251/3463 [05:51<10:10,  3.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 1250, 'avg_loss': 2.1979075444402167, 'avg_acc': 50.093675059952034, 'loss': 1.112560510635376}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  36%|| 1261/3463 [05:54<10:05,  3.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 1260, 'avg_loss': 2.190162719477745, 'avg_acc': 50.08178033306899, 'loss': 1.1941791772842407}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  37%|| 1271/3463 [05:57<09:43,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 1270, 'avg_loss': 2.1823636913374593, 'avg_acc': 50.08113690007868, 'loss': 1.2143113613128662}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  37%|| 1281/3463 [05:59<10:10,  3.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 1280, 'avg_loss': 2.174781060423542, 'avg_acc': 50.069525761124126, 'loss': 1.1712523698806763}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  37%|| 1291/3463 [06:02<09:55,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 1290, 'avg_loss': 2.167163279608735, 'avg_acc': 50.10045507358637, 'loss': 1.208480715751648}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  38%|| 1301/3463 [06:05<09:52,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 1300, 'avg_loss': 2.159665753894545, 'avg_acc': 50.080466948501154, 'loss': 1.1881229877471924}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  38%|| 1311/3463 [06:08<09:57,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 1310, 'avg_loss': 2.1523328715840155, 'avg_acc': 50.07746948893974, 'loss': 1.110529899597168}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  38%|| 1321/3463 [06:10<09:58,  3.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 1320, 'avg_loss': 2.145122343351406, 'avg_acc': 50.049678274034825, 'loss': 1.1320679187774658}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  38%|| 1331/3463 [06:13<09:50,  3.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 1330, 'avg_loss': 2.137879894336841, 'avg_acc': 50.04930503380917, 'loss': 1.1510555744171143}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  39%|| 1341/3463 [06:16<10:16,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 1340, 'avg_loss': 2.1308690274855167, 'avg_acc': 50.044276659209544, 'loss': 1.2081165313720703}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  39%|| 1351/3463 [06:19<10:14,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 1350, 'avg_loss': 2.1237339920507017, 'avg_acc': 50.03122686898593, 'loss': 1.224137783050537}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  39%|| 1361/3463 [06:22<09:43,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 1360, 'avg_loss': 2.116785938471753, 'avg_acc': 50.01262858192506, 'loss': 1.1473636627197266}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  40%|| 1371/3463 [06:25<09:33,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 1370, 'avg_loss': 2.1102195661664442, 'avg_acc': 50.00341903719912, 'loss': 1.1557636260986328}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  40%|| 1381/3463 [06:27<09:20,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 1380, 'avg_loss': 2.103677218846011, 'avg_acc': 49.97284576393917, 'loss': 1.1652355194091797}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  40%|| 1391/3463 [06:30<09:50,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 1390, 'avg_loss': 2.0971670415571144, 'avg_acc': 49.962931344356576, 'loss': 1.220190167427063}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  40%|| 1401/3463 [06:33<09:47,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 1400, 'avg_loss': 2.0907805212730173, 'avg_acc': 49.9810403283369, 'loss': 1.146816372871399}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  41%|| 1411/3463 [06:36<09:33,  3.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 1410, 'avg_loss': 2.084295285753457, 'avg_acc': 50.00775159461375, 'loss': 1.2042193412780762}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  41%|| 1421/3463 [06:39<09:50,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 1420, 'avg_loss': 2.0781177347768454, 'avg_acc': 50.01099577762139, 'loss': 1.163205862045288}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  41%|| 1431/3463 [06:42<09:24,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 1430, 'avg_loss': 2.071785831601365, 'avg_acc': 50.026205450733755, 'loss': 1.1277780532836914}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  42%|| 1441/3463 [06:44<09:22,  3.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 1440, 'avg_loss': 2.0657215955603214, 'avg_acc': 50.01084316446912, 'loss': 1.1900396347045898}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  42%|| 1451/3463 [06:47<09:12,  3.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 1450, 'avg_loss': 2.059652869657021, 'avg_acc': 50.01507580978636, 'loss': 1.1511467695236206}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  42%|| 1461/3463 [06:50<09:03,  3.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 1460, 'avg_loss': 2.053619984075845, 'avg_acc': 50.0, 'loss': 1.2009360790252686}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  42%|| 1471/3463 [06:53<09:01,  3.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 1470, 'avg_loss': 2.047599948481748, 'avg_acc': 49.97344493541808, 'loss': 1.2592476606369019}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  43%|| 1481/3463 [06:55<09:01,  3.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 1480, 'avg_loss': 2.041714364334508, 'avg_acc': 49.977844361917626, 'loss': 1.133382797241211}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  43%|| 1491/3463 [06:58<08:53,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 1490, 'avg_loss': 2.0358972288793082, 'avg_acc': 49.9790409121395, 'loss': 1.141322135925293}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0:  43%|| 1500/3463 [07:01<09:11,  3.56it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 110\u001b[0m\n\u001b[1;32m    107\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m--> 110\u001b[0m     \u001b[43mbert_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[34], line 33\u001b[0m, in \u001b[0;36mBERTTrainer.train\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m, epoch):\n\u001b[0;32m---> 33\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[34], line 54\u001b[0m, in \u001b[0;36mBERTTrainer.iteration\u001b[0;34m(self, epoch, data_loader, train)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# progress bar\u001b[39;00m\n\u001b[1;32m     47\u001b[0m data_iter \u001b[38;5;241m=\u001b[39m tqdm\u001b[38;5;241m.\u001b[39mtqdm(\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28menumerate\u001b[39m(data_loader),\n\u001b[1;32m     49\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEP_\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (mode, epoch),\n\u001b[1;32m     50\u001b[0m     total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(data_loader),\n\u001b[1;32m     51\u001b[0m     bar_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{l_bar}\u001b[39;00m\u001b[38;5;132;01m{r_bar}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     52\u001b[0m )\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m data_iter:\n\u001b[1;32m     55\u001b[0m \n\u001b[1;32m     56\u001b[0m     \u001b[38;5;66;03m# 0. batch_data will be sent into the device(GPU or cpu)\u001b[39;00m\n\u001b[1;32m     57\u001b[0m     data \u001b[38;5;241m=\u001b[39m {key: value\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# 1. forward the next_sentence_prediction and masked_lm model\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[19], line 19\u001b[0m, in \u001b[0;36mBERTDataset.__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Step 2: replace random words in sentence with mask / random words\u001b[39;00m\n\u001b[1;32m     18\u001b[0m t1_random, t1_label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_word(t1)\n\u001b[0;32m---> 19\u001b[0m t2_random, t2_label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_word\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Step 3: Adding CLS and SEP tokens to the start and end of sentences\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Adding PAD token for labels\u001b[39;00m\n\u001b[1;32m     23\u001b[0m t1 \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mvocab[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[CLS]\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m+\u001b[39m t1_random \u001b[38;5;241m+\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mvocab[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[SEP]\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "Cell \u001b[0;32mIn[19], line 53\u001b[0m, in \u001b[0;36mBERTDataset.random_word\u001b[0;34m(self, sentence)\u001b[0m\n\u001b[1;32m     50\u001b[0m prob \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mrandom()\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# remove cls and sep token\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m token_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m#print(token, \"--->\", token_id)\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# 15% chance of altering token\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prob \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.15\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3021\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   3019\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n\u001b[1;32m   3020\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_input_mode()\n\u001b[0;32m-> 3021\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mall_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3022\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3023\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_target_mode()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3131\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m   3109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_encode_plus(\n\u001b[1;32m   3110\u001b[0m         batch_text_or_text_pairs\u001b[38;5;241m=\u001b[39mbatch_text_or_text_pairs,\n\u001b[1;32m   3111\u001b[0m         add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3128\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3129\u001b[0m     )\n\u001b[1;32m   3130\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3132\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3133\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3134\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3135\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3136\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3137\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3138\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3141\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3150\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3151\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3152\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3207\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   3197\u001b[0m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[1;32m   3198\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[1;32m   3199\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[1;32m   3200\u001b[0m     truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3204\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3205\u001b[0m )\n\u001b[0;32m-> 3207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3208\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3210\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3211\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3216\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3226\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msplit_special_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3227\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3228\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils.py:801\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    792\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_offsets_mapping:\n\u001b[1;32m    793\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    794\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn_offset_mapping is not available when using Python tokenizers. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    795\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo use this feature, change your tokenizer to one deriving from \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    798\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://github.com/huggingface/transformers/pull/2674\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    799\u001b[0m     )\n\u001b[0;32m--> 801\u001b[0m first_ids \u001b[38;5;241m=\u001b[39m \u001b[43mget_input_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    802\u001b[0m second_ids \u001b[38;5;241m=\u001b[39m get_input_ids(text_pair) \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_for_model(\n\u001b[1;32m    805\u001b[0m     first_ids,\n\u001b[1;32m    806\u001b[0m     pair_ids\u001b[38;5;241m=\u001b[39msecond_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    821\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m    822\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils.py:768\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._encode_plus.<locals>.get_input_ids\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    766\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_input_ids\u001b[39m(text):\n\u001b[1;32m    767\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(text, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 768\u001b[0m         tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    769\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_tokens_to_ids(tokens)\n\u001b[1;32m    770\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(text, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(text) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(text[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils.py:647\u001b[0m, in \u001b[0;36mPreTrainedTokenizer.tokenize\u001b[0;34m(self, text, **kwargs)\u001b[0m\n\u001b[1;32m    643\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKeyword arguments \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not recognized.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    645\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo_lower_case\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_lower_case:\n\u001b[1;32m    646\u001b[0m     \u001b[38;5;66;03m# convert non-special tokens to lowercase. Might be super slow as well?\u001b[39;00m\n\u001b[0;32m--> 647\u001b[0m     escaped_special_toks \u001b[38;5;241m=\u001b[39m [re\u001b[38;5;241m.\u001b[39mescape(s_tok) \u001b[38;5;28;01mfor\u001b[39;00m s_tok \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall_special_tokens\u001b[49m)]\n\u001b[1;32m    648\u001b[0m     escaped_special_toks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    649\u001b[0m         re\u001b[38;5;241m.\u001b[39mescape(s_tok\u001b[38;5;241m.\u001b[39mcontent)\n\u001b[1;32m    650\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m s_tok \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_added_tokens_decoder\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[1;32m    651\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s_tok\u001b[38;5;241m.\u001b[39mspecial \u001b[38;5;129;01mand\u001b[39;00m s_tok\u001b[38;5;241m.\u001b[39mnormalized\n\u001b[1;32m    652\u001b[0m     ]\n\u001b[1;32m    653\u001b[0m     pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(escaped_special_toks) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)|\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(.+?)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1370\u001b[0m, in \u001b[0;36mSpecialTokensMixin.all_special_tokens\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1363\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m   1364\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mall_special_tokens\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m   1365\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1366\u001b[0m \u001b[38;5;124;03m    `List[str]`: A list of the unique special tokens (`'<unk>'`, `'<cls>'`, ..., etc.).\u001b[39;00m\n\u001b[1;32m   1367\u001b[0m \n\u001b[1;32m   1368\u001b[0m \u001b[38;5;124;03m    Convert tokens of `tokenizers.AddedToken` type to string.\u001b[39;00m\n\u001b[1;32m   1369\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1370\u001b[0m     all_toks \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mstr\u001b[39m(s) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall_special_tokens_extended\u001b[49m]\n\u001b[1;32m   1371\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m all_toks\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1354\u001b[0m, in \u001b[0;36mSpecialTokensMixin.all_special_tokens_extended\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1352\u001b[0m all_tokens \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   1353\u001b[0m seen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m-> 1354\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspecial_tokens_map_extended\u001b[49m\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m   1355\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m   1356\u001b[0m         tokens_to_add \u001b[38;5;241m=\u001b[39m [token \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m value \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(token) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m seen]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1337\u001b[0m, in \u001b[0;36mSpecialTokensMixin.special_tokens_map_extended\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1335\u001b[0m set_attr \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   1336\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mSPECIAL_TOKENS_ATTRIBUTES:\n\u001b[0;32m-> 1337\u001b[0m     attr_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1338\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attr_value:\n\u001b[1;32m   1339\u001b[0m         set_attr[attr] \u001b[38;5;241m=\u001b[39m attr_value\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### trainer\n",
    "class BERTTrainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        train_dataloader,\n",
    "        test_dataloader=None,\n",
    "        lr= 1e-5,\n",
    "        weight_decay=0.01,\n",
    "        betas=(0.9, 0.999),\n",
    "        warmup_steps=10000,\n",
    "        log_freq=10,\n",
    "        device='cuda'\n",
    "        ):\n",
    "\n",
    "        self.device = device\n",
    "        self.model = model\n",
    "        self.train_data = train_dataloader\n",
    "        self.test_data = test_dataloader\n",
    "\n",
    "        # Setting the Adam optimizer with hyper-param\n",
    "        self.optim = Adam(self.model.parameters(), lr=lr)\n",
    "        self.optim_schedule = ScheduledOptim(\n",
    "            self.optim, self.model.bert.d_model, n_warmup_steps=warmup_steps\n",
    "            )\n",
    "\n",
    "        # Using Negative Log Likelihood Loss function for predicting the masked_token\n",
    "        self.criterion = torch.nn.functional.cross_entropy #torch.nn.NLLLoss(ignore_index=0)\n",
    "        self.log_freq = log_freq\n",
    "        print(\"Total Parameters:\", sum([p.nelement() for p in self.model.parameters()]))\n",
    "\n",
    "    def train(self, epoch):\n",
    "        self.iteration(epoch, self.train_data)\n",
    "\n",
    "    def test(self, epoch):\n",
    "        self.iteration(epoch, self.test_data, train=False)\n",
    "\n",
    "    def iteration(self, epoch, data_loader, train=True):\n",
    "\n",
    "        avg_loss = 0.0\n",
    "        total_correct = 0\n",
    "        total_element = 0\n",
    "\n",
    "        mode = \"train\" if train else \"test\"\n",
    "\n",
    "        # progress bar\n",
    "        data_iter = tqdm.tqdm(\n",
    "            enumerate(data_loader),\n",
    "            desc=\"EP_%s:%d\" % (mode, epoch),\n",
    "            total=len(data_loader),\n",
    "            bar_format=\"{l_bar}{r_bar}\"\n",
    "        )\n",
    "\n",
    "        for i, data in data_iter:\n",
    "\n",
    "            # 0. batch_data will be sent into the device(GPU or cpu)\n",
    "            data = {key: value.to(self.device) for key, value in data.items()}\n",
    "\n",
    "            # 1. forward the next_sentence_prediction and masked_lm model\n",
    "            next_sent_output, mask_lm_output = self.model.forward(data[\"bert_input\"], data[\"segment_label\"])\n",
    "\n",
    "            # 2-1. NLL(negative log likelihood) loss of is_next classification result\n",
    "            next_loss = self.criterion(next_sent_output, data[\"is_next\"])\n",
    "\n",
    "            # 2-2. NLLLoss of predicting masked token word\n",
    "            # transpose to (m, vocab_size, seq_len) vs (m, seq_len)\n",
    "            # criterion(mask_lm_output.view(-1, mask_lm_output.size(-1)), data[\"bert_label\"].view(-1))\n",
    "            mask_loss = self.criterion(mask_lm_output.transpose(1, 2), data[\"bert_label\"])\n",
    "\n",
    "            # 2-3. Adding next_loss and mask_loss : 3.4 Pre-training Procedure\n",
    "            loss = next_loss + mask_loss\n",
    "\n",
    "            # 3. backward and optimization only in train\n",
    "            if train:\n",
    "                self.optim_schedule.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optim_schedule.step_and_update_lr()\n",
    "\n",
    "            # next sentence prediction accuracy\n",
    "            correct = next_sent_output.argmax(dim=-1).eq(data[\"is_next\"]).sum().item()\n",
    "            avg_loss += loss.item()\n",
    "            total_correct += correct\n",
    "            total_element += data[\"is_next\"].nelement()\n",
    "\n",
    "            post_fix = {\n",
    "                \"epoch\": epoch,\n",
    "                \"iter\": i,\n",
    "                \"avg_loss\": avg_loss / (i + 1),\n",
    "                \"avg_acc\": total_correct / total_element * 100,\n",
    "                \"loss\": loss.item()\n",
    "            }\n",
    "\n",
    "            if i % self.log_freq == 0:\n",
    "                data_iter.write(str(post_fix))\n",
    "        print(\n",
    "            f\"EP{epoch}, {mode}: \\\n",
    "            avg_loss={avg_loss / len(data_iter)}, \\\n",
    "            total_acc={total_correct * 100.0 / total_element}\"\n",
    "        )\n",
    "\n",
    "### test\n",
    "train_data = BERTDataset(pairs, seq_len=MAX_LEN, tokenizer=tokenizer)\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True, pin_memory=False)\n",
    "bert_model = BERT(len(tokenizer.vocab)).to(\"cuda\")\n",
    "bert_lm = BERTLM(bert_model, len(tokenizer.vocab)).to(\"cuda\")\n",
    "bert_trainer = BERTTrainer(bert_lm, train_loader, device='cuda')\n",
    "epochs = 2\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    bert_trainer.train(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hvIpgHXg6HOK"
   },
   "source": [
    "# 5) Reference\n",
    "\n",
    "[BERT from Scratch](https://medium.com/data-and-beyond/complete-guide-to-building-bert-model-from-sratch-3e6562228891) | [BERT vs Roberta vs XLM](https://towardsdatascience.com/bert-roberta-distilbert-xlnet-which-one-to-use-3d5ab82ba5f8) | [StructBert vs Albert vs LongForm](https://towardsdatascience.com/advancing-over-bert-bigbird-convbert-dynabert-bca78a45629c) | [BART](https://medium.com/analytics-vidhya/revealing-bart-a-denoising-objective-for-pretraining-c6e8f8009564)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KArJKXQchHNy"
   },
   "source": [
    "# 6) Context Guided BERT\n",
    "\n",
    "[CG-BERT REPO](https://github.com/frankaging/Quasi-Attention-ABSA/blob/main/code/model/CGBERT.py)\n",
    "\n",
    "```python\n",
    "# number of context classes\n",
    "context_id_map_sentihood = [\n",
    "    'location - 1 - general',\n",
    "    'location - 1 - price',\n",
    "    'location - 1 - safety',\n",
    "    'location - 1 - transit location',\n",
    "    'location - 2 - general',\n",
    "    'location - 2 - price',\n",
    "    'location - 2 - safety',\n",
    "    'location - 2 - transit location'\n",
    "]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tWeg7wbchJWk"
   },
   "outputs": [],
   "source": [
    "class BERTLayerNorm(nn.Module):\n",
    "    def __init__(self, config, variance_epsilon=1e-12):\n",
    "        super(BERTLayerNorm, self).__init__()\n",
    "        self.gamma = nn.Parameter(torch.ones(config.hidden_size))\n",
    "        self.beta = nn.Parameter(torch.zeros(config.hidden_size))\n",
    "        self.variance_epsilon = variance_epsilon\n",
    "\n",
    "    def forward(self, x):\n",
    "        u = x.mean(-1, keepdim=True)\n",
    "        s = (x - u).pow(2).mean(-1, keepdim=True)\n",
    "        x = (x - u) / torch.sqrt(s + self.variance_epsilon)\n",
    "        return self.gamma * x + self.beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i0-A5oWPha5j"
   },
   "outputs": [],
   "source": [
    "class ContextBERTSelfAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(ContextBERTSelfAttention, self).__init__()\n",
    "        self.num_attention_heads = config.num_attention_heads\n",
    "        self.attention_head_size = int(config.hidden_size / config.num_attention_heads)\n",
    "        self.all_head_size = self.num_attention_heads * self.attention_head_size\n",
    "\n",
    "        self.query = nn.Linear(config.hidden_size, self.all_head_size)\n",
    "        self.key = nn.Linear(config.hidden_size, self.all_head_size)\n",
    "        self.value = nn.Linear(config.hidden_size, self.all_head_size)\n",
    "        self.dropout = nn.Dropout(config.attention_probs_dropout_prob)\n",
    "\n",
    "        # learnable context integration factors\n",
    "        # enforce initialization to zero as to leave the pretrain model\n",
    "        # unperturbed in the beginning\n",
    "        self.context_for_q = nn.Linear(self.attention_head_size, self.attention_head_size)\n",
    "        self.context_for_k = nn.Linear(self.attention_head_size, self.attention_head_size)\n",
    "\n",
    "        self.lambda_q_context_layer = nn.Linear(self.attention_head_size, 1, bias=False)\n",
    "        self.lambda_q_query_layer = nn.Linear(self.attention_head_size, 1, bias=False)\n",
    "        self.lambda_k_context_layer = nn.Linear(self.attention_head_size, 1, bias=False)\n",
    "        self.lambda_k_key_layer = nn.Linear(self.attention_head_size, 1, bias=False)\n",
    "\n",
    "        # zero-centered activation function, specifically for re-arch fine tunning\n",
    "        self.lambda_sig = nn.Sigmoid()\n",
    "        self.quasi_act = nn.Sigmoid()\n",
    "\n",
    "    def transpose_for_scores(self, x):\n",
    "        new_x_shape = x.size()[:-1] + (self.num_attention_heads, self.attention_head_size)\n",
    "        x = x.view(*new_x_shape)\n",
    "        return x.permute(0, 2, 1, 3)\n",
    "\n",
    "    def forward(self, hidden_states, attention_mask,\n",
    "                # optional parameters for saving context information\n",
    "                device=None, context_embedded=None):\n",
    "\n",
    "        # (m, seq_len, hidden_dim)\n",
    "        mixed_query_layer = self.query(hidden_states)\n",
    "        mixed_key_layer = self.key(hidden_states)\n",
    "        mixed_value_layer = self.value(hidden_states)\n",
    "\n",
    "        # (m, num_head, seq_len, head_dim)\n",
    "        mixed_query_layer = self.transpose_for_scores(mixed_query_layer)\n",
    "        mixed_key_layer = self.transpose_for_scores(mixed_key_layer)\n",
    "\n",
    "        # (m, 1, hidden_dim) --> (m, num_head, 1, head_dim)\n",
    "        context_embedded = self.transpose_for_scores(context_embedded)\n",
    "        context_embedded_q = self.context_for_q(context_embedded)\n",
    "\n",
    "        # (m, num_head, 1, head_dim) --> (m, num_head, 1, 1)\n",
    "        lambda_q_context = self.lambda_q_context_layer(context_embedded_q)\n",
    "        # (m, num_head, seq_len, head_dim) --> (m, num_head, seq_len, 1)\n",
    "        lambda_q_query = self.lambda_q_query_layer(mixed_query_layer)\n",
    "        # (m, num_head, seq_len, 1)\n",
    "        lambda_q = lambda_q_context + lambda_q_query\n",
    "        lambda_q = self.lambda_sig(lambda_q)\n",
    "\n",
    "        # Q_context = (1-lambda_Q) * Q + lambda_Q * Context_Q\n",
    "        # K_context = (1-lambda_K) * K + lambda_K * Context_K\n",
    "        # the context is shared and is the same for every head.\n",
    "\n",
    "        # (m, num_head, seq_len, head_dim)\n",
    "        contextualized_query_layer = (1 - lambda_q) * mixed_query_layer + lambda_q * context_embedded_q\n",
    "\n",
    "        # repeat same for key\n",
    "        context_embedded_k = self.context_for_k(context_embedded)\n",
    "        lambda_k_context = self.lambda_k_context_layer(context_embedded_k)\n",
    "        lambda_k_key = self.lambda_k_key_layer(mixed_key_layer)\n",
    "        lambda_k = lambda_k_context + lambda_k_key\n",
    "        lambda_k = self.lambda_sig(lambda_k)\n",
    "\n",
    "        # (m, num_head, seq_len, head_dim)\n",
    "        contextualized_key_layer = (1 - lambda_k) * mixed_key_layer + lambda_k * context_embedded_k\n",
    "\n",
    "        ######################################################################\n",
    "\n",
    "        # (m, num_head, seq_len, seq_len)\n",
    "        attention_scores = torch.matmul(\n",
    "            contextualized_query_layer, contextualized_key_layer.transpose(-1, -2)\n",
    "        )\n",
    "        attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
    "        attention_scores = attention_scores + attention_mask\n",
    "        attention_probs = nn.Softmax(dim=-1)(attention_scores)\n",
    "        attention_probs = self.dropout(attention_probs)\n",
    "\n",
    "        # (m, num_head, seq_len, seq_len)\n",
    "        value_layer = self.transpose_for_scores(mixed_value_layer)\n",
    "\n",
    "        # (m, num_head, seq_len, head_dim)\n",
    "        context_layer = torch.matmul(attention_probs, value_layer)\n",
    "\n",
    "        # (m, seq_len, num_head, head_dim)\n",
    "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
    "\n",
    "        # (m, seq_len, hidden_dim)\n",
    "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
    "        context_layer = context_layer.view(*new_context_layer_shape)\n",
    "\n",
    "        return context_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0DpFJt7QxRZE"
   },
   "outputs": [],
   "source": [
    "class ContextBERTEncoder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(ContextBERTEncoder, self).__init__()\n",
    "\n",
    "        deep_context_transform_layer = nn.Linear(\n",
    "            2*config.hidden_size, config.hidden_size\n",
    "        )\n",
    "\n",
    "        self.context_layer = nn.ModuleList([\n",
    "            copy.deepcopy(deep_context_transform_layer) for _ in range(config.num_hidden_layers)\n",
    "        ])\n",
    "\n",
    "        layer = ContextBERTLayer(config)\n",
    "        self.layer = nn.ModuleList([copy.deepcopy(layer) for _ in range(config.num_hidden_layers)])\n",
    "\n",
    "    def forward(self, hidden_states, attention_mask, device=None, context_embeddings=None):\n",
    "\n",
    "        all_encoder_layers = []\n",
    "        layer_index = 0\n",
    "        for layer_module in self.layer:\n",
    "            deep_context_hidden = torch.cat([context_embeddings, hidden_states], dim=-1)\n",
    "            deep_context_hidden = self.context_layer[layer_index](deep_context_hidden)\n",
    "            deep_context_hidden += context_embeddings\n",
    "\n",
    "            # BERT encoding\n",
    "            hidden_states = layer_module(\n",
    "                hidden_states, attention_mask, device, deep_context_hidden\n",
    "            )\n",
    "            # (n_layer, m, seq_len, hidden_dim)\n",
    "            all_encoder_layers.append(hidden_states)\n",
    "            layer_index += 1\n",
    "\n",
    "        return all_encoder_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WyT5M1jCsl0d"
   },
   "outputs": [],
   "source": [
    "class ContextBertModel(nn.Module):\n",
    "    def __init__(self, config: BertConfig):\n",
    "        super(ContextBertModel, self).__init__()\n",
    "        self.embeddings = BERTEmbeddings(config)\n",
    "        self.encoder = ContextBERTEncoder(config)\n",
    "        self.pooler = ContextBERTPooler(config)\n",
    "\n",
    "        # context embedding\n",
    "        num_target = 4\n",
    "        num_aspect = 2\n",
    "        self.context_embeddings = nn.Embedding(num_target*num_aspect, config.hidden_size)\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids=None, attention_mask=None,\n",
    "                device=None, context_ids=None):\n",
    "\n",
    "        if attention_mask is None:\n",
    "            attention_mask = torch.ones_like(input_ids)\n",
    "        if token_type_ids is None:\n",
    "            token_type_ids = torch.zeros_like(input_ids)\n",
    "\n",
    "        # [batch_size, 1, 1, from_seq_length]\n",
    "        # broadcast to [batch_size, num_heads, seq_length, seq_length]\n",
    "        extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "        # multiply by negative big number to make it ignore during softmax\n",
    "        extended_attention_mask = extended_attention_mask.float()\n",
    "        extended_attention_mask = (1.0 - extended_attention_mask) * -9e9\n",
    "        embedding_output = self.embeddings(input_ids, token_type_ids)\n",
    "\n",
    "        # context embeddings\n",
    "        # [batch_size, 1, context_embedding_dim]\n",
    "        context_embedded = self.context_embeddings(context_ids).squeeze(dim=1)\n",
    "        # [batch_size, seq_len, context_embedding_dim]\n",
    "        seq_len = embedding_output.shape[1]\n",
    "        context_embedding_output = torch.stack(seq_len*[context_embedded], dim=1)\n",
    "\n",
    "        # (n_layer, m, seq_len, hidden_dim)\n",
    "        all_encoder_layers = self.encoder(\n",
    "            embedding_output,\n",
    "            extended_attention_mask,\n",
    "            device,\n",
    "            context_embedding_output\n",
    "        )\n",
    "\n",
    "        sequence_output = all_encoder_layers[-1]\n",
    "        pooled_output = self.pooler(sequence_output, attention_mask)\n",
    "        return pooled_output"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
