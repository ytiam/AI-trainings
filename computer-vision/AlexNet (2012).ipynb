{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16249b33",
   "metadata": {},
   "source": [
    "Motivation: Show deep CNNs can work on large-scale datasets (ImageNet).\n",
    "\n",
    "Used ReLU activations, dropout, GPU training â†’ big ImageNet breakthrough.\n",
    "\n",
    "Limitation: Very large model, heavy computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a06a30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc1e055b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "NUM_EPOCHS = 50\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_WORKERS = 4\n",
    "best_val_loss = 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6fe41f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset = datasets.CIFAR10(root='../data', \n",
    "                                 train=True, \n",
    "                                 transform=transforms.ToTensor(),\n",
    "                                 download=True)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, \n",
    "                          batch_size=BATCH_SIZE, \n",
    "                          num_workers=NUM_WORKERS,\n",
    "                          drop_last=True,\n",
    "                          shuffle=True)\n",
    "\n",
    "test_dataset = datasets.CIFAR10(root='../data', \n",
    "                                train=False,\n",
    "                                transform=transforms.ToTensor())\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset, \n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         num_workers=NUM_WORKERS,\n",
    "                         drop_last=False,\n",
    "                         shuffle=False)\n",
    "\n",
    "# Checking the dataset\n",
    "all_train_labels = []\n",
    "all_test_labels = []\n",
    "\n",
    "for images, labels in train_loader:  \n",
    "    all_train_labels.append(labels)\n",
    "all_train_labels = torch.cat(all_train_labels)\n",
    "    \n",
    "for images, labels in test_loader:  \n",
    "    all_test_labels.append(labels)\n",
    "all_test_labels = torch.cat(all_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "251b44b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x75fe45616c20>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = next(iter(train_loader))\n",
    "plt.imshow(img[0][1].reshape(32,32,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "004b4f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline ACC: 10.00%\n"
     ]
    }
   ],
   "source": [
    "majority_prediction = torch.argmax(torch.bincount(all_test_labels))\n",
    "baseline_acc = torch.mean((all_test_labels == majority_prediction).float())\n",
    "print(f'Baseline ACC: {baseline_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c723c47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(torch.nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.features = torch.nn.Sequential(\n",
    "            \n",
    "            # Conv -> Relu -> Maxpool\n",
    "            torch.nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            \n",
    "            # Conv -> Relu -> Maxpool\n",
    "            torch.nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            \n",
    "            # Conv -> Relu\n",
    "            torch.nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            \n",
    "            # Conv -> Relu\n",
    "            torch.nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            \n",
    "            # Conv -> Relu -> Maxpool (deactivated maxpool because of errors, need to debug)\n",
    "            torch.nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "#             torch.nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        \n",
    "        self.avgpool = torch.nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = torch.nn.Sequential(\n",
    "            torch.nn.Dropout(0.5),\n",
    "            torch.nn.Linear(256 * 6 * 6, 4096),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Dropout(0.5),\n",
    "            torch.nn.Linear(4096, 4096),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Linear(4096, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        logits = self.classifier(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "093cb216",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py:107: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343967769/work/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0a8c5d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec499c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57.023306 M parameters\n"
     ]
    }
   ],
   "source": [
    "model = AlexNet(num_classes=10)\n",
    "m = model.to(device)\n",
    "# print the number of parameters in the model\n",
    "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
    "\n",
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7b6330f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 17, 17]           1,792\n",
      "              ReLU-2           [-1, 64, 17, 17]               0\n",
      "         MaxPool2d-3             [-1, 64, 8, 8]               0\n",
      "            Conv2d-4            [-1, 192, 8, 8]         307,392\n",
      "              ReLU-5            [-1, 192, 8, 8]               0\n",
      "         MaxPool2d-6            [-1, 192, 3, 3]               0\n",
      "            Conv2d-7            [-1, 384, 3, 3]         663,936\n",
      "              ReLU-8            [-1, 384, 3, 3]               0\n",
      "            Conv2d-9            [-1, 256, 3, 3]         884,992\n",
      "             ReLU-10            [-1, 256, 3, 3]               0\n",
      "           Conv2d-11            [-1, 256, 3, 3]         590,080\n",
      "             ReLU-12            [-1, 256, 3, 3]               0\n",
      "AdaptiveAvgPool2d-13            [-1, 256, 6, 6]               0\n",
      "          Dropout-14                 [-1, 9216]               0\n",
      "           Linear-15                 [-1, 4096]      37,752,832\n",
      "             ReLU-16                 [-1, 4096]               0\n",
      "          Dropout-17                 [-1, 4096]               0\n",
      "           Linear-18                 [-1, 4096]      16,781,312\n",
      "             ReLU-19                 [-1, 4096]               0\n",
      "           Linear-20                   [-1, 10]          40,970\n",
      "================================================================\n",
      "Total params: 57,023,306\n",
      "Trainable params: 57,023,306\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.93\n",
      "Params size (MB): 217.53\n",
      "Estimated Total Size (MB): 218.47\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(m,(3,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7904af6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 3, 32, 32])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6e9b284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 | train_loss: 1.9979 valid_loss: 1.6400\n",
      "Accuracy:  0.3551\n",
      "epoch 1 | train_loss: 1.5218 valid_loss: 1.4159\n",
      "Accuracy:  0.4772\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x_v_b, y_v_b \u001b[38;5;129;01min\u001b[39;00m test_loader:\n\u001b[1;32m     19\u001b[0m     x_v_b, y_v_b \u001b[38;5;241m=\u001b[39m x_v_b\u001b[38;5;241m.\u001b[39mto(device), y_v_b\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 20\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_v_b\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(logits, y_v_b)\n\u001b[1;32m     22\u001b[0m     vdl \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[6], line 45\u001b[0m, in \u001b[0;36mAlexNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     43\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgpool(x)\n\u001b[1;32m     44\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(x, start_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 45\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m logits\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for ep in range(NUM_EPOCHS):\n",
    "    all_pred_labels = []\n",
    "    trl = 0\n",
    "    m.train()\n",
    "    for x_b, y_b in train_loader:\n",
    "        x_b = x_b.to(device)\n",
    "        y_b = y_b.to(device)\n",
    "        logits = m(x_b)\n",
    "        loss = F.cross_entropy(logits, y_b)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        trl += loss.item()\n",
    "    \n",
    "    m.eval()\n",
    "    with torch.no_grad():\n",
    "        vdl = 0\n",
    "        for x_v_b, y_v_b in test_loader:\n",
    "            x_v_b, y_v_b = x_v_b.to(device), y_v_b.to(device)\n",
    "            logits = m(x_v_b)\n",
    "            loss = F.cross_entropy(logits, y_v_b)\n",
    "            vdl += loss.item()\n",
    "        print(f'epoch {ep} | train_loss: {trl/len(train_loader):.4f} valid_loss: {vdl/len(test_loader):.4f}')\n",
    "    \n",
    "    if vdl < best_val_loss:\n",
    "        best_val_loss = vdl\n",
    "        for x_v_b, y_v_b in test_loader:\n",
    "            x_v_b, y_v_b = x_v_b.to(device), y_v_b.to(device)\n",
    "            logits = m(x_v_b)\n",
    "            pred_label = F.softmax(logits,dim=-1).argmax(dim=-1)\n",
    "            all_pred_labels.extend(list(pred_label.detach().cpu().flatten().numpy()))\n",
    "        print(\"Accuracy: \",accuracy_score(all_test_labels.detach().cpu().flatten().numpy(), all_pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b6292bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = next(iter(train_loader))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aa557eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_flow = torch.nn.Sequential(torch.nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=2),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.MaxPool2d(kernel_size=3, stride=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7b6d18c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 192, 3, 3])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.Sequential(torch.nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.MaxPool2d(kernel_size=3, stride=2))(test_flow(img)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b17d68db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 3, 32, 32])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99926e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
