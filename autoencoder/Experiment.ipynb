{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4ec54d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-25 17:31:05.525372: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-02-25 17:31:05.532510: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1740504665.544459      72 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1740504665.547982      72 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-25 17:31:05.560849: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.nn import functional as F\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb7a05f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, _), (x_test, _) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6b96ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype(\"float32\")/255.0\n",
    "x_test = x_test.astype(\"float32\")/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "43432229",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = torch.utils.data.DataLoader(x_train,batch_size=60,shuffle=True)\n",
    "val_dl = torch.utils.data.DataLoader(x_test,batch_size=60,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "96cb22b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Autoencoder model\n",
    "class VAE_EXP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE_EXP, self).__init__()\n",
    "        \n",
    "        #self.raw_beta = nn.Parameter(data=torch.Tensor(1), requires_grad=True)\n",
    "        \n",
    "        self.linear_encoder = nn.Sequential(\n",
    "               nn.Linear(input_size, 128),\n",
    "               nn.ReLU(),\n",
    "               nn.Linear(128, 32),\n",
    "               nn.ReLU(),\n",
    "               nn.Linear(32, encoding_dim),\n",
    "               nn.GELU()\n",
    "           )\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "               nn.Conv2d(1,32,3,padding=1),\n",
    "               nn.ReLU(),\n",
    "               nn.MaxPool2d(2,2),\n",
    "               nn.Conv2d(32,16,3,padding=1),\n",
    "               nn.ReLU(),\n",
    "               nn.MaxPool2d(2,2),\n",
    "               nn.Conv2d(16,8,3,padding=1),\n",
    "               nn.ReLU(),\n",
    "               nn.MaxPool2d(2,2),\n",
    "           )\n",
    "        self.decoder = nn.Sequential(\n",
    "           nn.ConvTranspose2d(8,8,3,stride=2),\n",
    "           nn.ReLU(),\n",
    "           nn.ConvTranspose2d(8,16,2,stride=2),\n",
    "           nn.ReLU(),\n",
    "           nn.ConvTranspose2d(16,32,2,stride=2),\n",
    "           nn.ReLU(),\n",
    "           nn.Conv2d(32,1,3,padding=1),\n",
    "           nn.Sigmoid(),\n",
    "       )\n",
    "        \n",
    "        self.fc_mu = nn.Linear(8*9, latent_dim)\n",
    "        self.fc_var = nn.Linear(8*9, latent_dim)\n",
    "        \n",
    "        self.decoder_input = nn.Linear(latent_dim, 8*9)\n",
    "        \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        \"\"\"\n",
    "        Reparameterization trick to sample from N(mu, var) from\n",
    "        N(0,1).\n",
    "        :param mu: (Tensor) Mean of the latent Gaussian [B x D]\n",
    "        :param logvar: (Tensor) Standard deviation of the latent Gaussian [B x D]\n",
    "        :return: (Tensor) [B x D]\n",
    "        \"\"\"\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return eps * std + mu\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_conv_in = torch.tensor(x).unsqueeze(1)\n",
    "        x_lin_in = x.reshape(len(x), np.prod(x.shape[1:]))\n",
    "        \n",
    "        conv_encoded = self.encoder(x_conv_in)\n",
    "        linear_encoded = self.linear_encoder(x_lin_in)\n",
    "        \n",
    "        conv_encoded_flatten = torch.flatten(conv_encoded, start_dim=1)\n",
    "        \n",
    "        #print(conv_encoded_flatten.shape, \"===========\", linear_encoded.shape)\n",
    "        \n",
    "        result = conv_encoded_flatten + linear_encoded\n",
    "        \n",
    "        #print(result[0],\"*****\",conv_encoded_flatten[0],\"++++\",linear_encoded[0])\n",
    "        # Split the result into mu and var components\n",
    "        # of the latent Gaussian distribution\n",
    "        mu = self.fc_mu(result)\n",
    "        log_var = self.fc_var(result)\n",
    "        \n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        \n",
    "        decoded = self.decoder_input(z)\n",
    "        decoded = decoded.view(-1,8,3,3)\n",
    "        x_ = self.decoder(decoded)\n",
    "        return  [x_, x, mu, log_var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "395c82eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(recons, input_, mu, log_var):\n",
    "        \"\"\"\n",
    "        Computes the VAE loss function.\n",
    "        KL(N(\\mu, \\sigma), N(0, 1)) = \\log \\frac{1}{\\sigma} + \\frac{\\sigma^2 + \\mu^2}{2} - \\frac{1}{2}\n",
    "        :param args:\n",
    "        :param kwargs:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        kld_weight = 0.00025 #kwargs['M_N'] # Account for the minibatch samples from the dataset\n",
    "        recons_loss =F.mse_loss(recons, input_)\n",
    "\n",
    "\n",
    "        kld_loss = torch.mean(-0.5 * torch.sum(1 + log_var - mu ** 2 - log_var.exp(), dim = 1), dim = 0)\n",
    "\n",
    "        loss = recons_loss + kld_weight * kld_loss\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "be6532ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "1ce7ecb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = np.prod(x_train.shape[1:])\n",
    "latent_dim = 128\n",
    "encoding_dim = 72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "81418b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting random seed for reproducibility\n",
    "torch.manual_seed(30)\n",
    "model = VAE_EXP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "b4d8366b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "8ac320c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "criterion = loss_function\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.002)\n",
    "sched = torch.optim.lr_scheduler.OneCycleLR(optimizer,max_lr=0.002, steps_per_epoch=len(train_dl),epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "8831bb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopper:\n",
    "    def __init__(self, patience=1, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = float('inf')\n",
    "\n",
    "    def early_stop(self, validation_loss):\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "        elif validation_loss < (self.min_validation_loss + self.min_delta):\n",
    "            print(\"*********************\")\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "9b415955",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72/30680453.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x_conv_in = torch.tensor(x).unsqueeze(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.1165, Val_Loss: 0.0714\n",
      "Epoch [2/100], Loss: 0.0656, Val_Loss: 0.0621\n",
      "Epoch [3/100], Loss: 0.0586, Val_Loss: 0.0555\n",
      "Epoch [4/100], Loss: 0.0513, Val_Loss: 0.0471\n",
      "Epoch [5/100], Loss: 0.0449, Val_Loss: 0.0425\n",
      "Epoch [6/100], Loss: 0.0411, Val_Loss: 0.0392\n",
      "Epoch [7/100], Loss: 0.0375, Val_Loss: 0.0352\n",
      "Epoch [8/100], Loss: 0.0339, Val_Loss: 0.0318\n",
      "Epoch [9/100], Loss: 0.0305, Val_Loss: 0.0285\n",
      "Epoch [10/100], Loss: 0.0279, Val_Loss: 0.0266\n",
      "Epoch [11/100], Loss: 0.0263, Val_Loss: 0.0252\n",
      "Epoch [12/100], Loss: 0.0252, Val_Loss: 0.0243\n",
      "Epoch [13/100], Loss: 0.0244, Val_Loss: 0.0237\n",
      "Epoch [14/100], Loss: 0.0238, Val_Loss: 0.0233\n",
      "Epoch [15/100], Loss: 0.0235, Val_Loss: 0.0232\n",
      "Epoch [16/100], Loss: 0.0231, Val_Loss: 0.0228\n",
      "Epoch [17/100], Loss: 0.0228, Val_Loss: 0.0224\n",
      "Epoch [18/100], Loss: 0.0226, Val_Loss: 0.0220\n",
      "Epoch [19/100], Loss: 0.0223, Val_Loss: 0.0218\n",
      "Epoch [20/100], Loss: 0.0221, Val_Loss: 0.0217\n",
      "Epoch [21/100], Loss: 0.0219, Val_Loss: 0.0213\n",
      "*********************\n",
      "Epoch [22/100], Loss: 0.0218, Val_Loss: 0.0213\n",
      "Epoch [23/100], Loss: 0.0217, Val_Loss: 0.0216\n",
      "Epoch [24/100], Loss: 0.0216, Val_Loss: 0.0212\n",
      "*********************\n",
      "Epoch [25/100], Loss: 0.0215, Val_Loss: 0.0212\n",
      "Epoch [26/100], Loss: 0.0214, Val_Loss: 0.0209\n",
      "Epoch [27/100], Loss: 0.0213, Val_Loss: 0.0211\n",
      "*********************\n",
      "Epoch [28/100], Loss: 0.0212, Val_Loss: 0.0209\n",
      "*********************\n",
      "Epoch [29/100], Loss: 0.0211, Val_Loss: 0.0209\n",
      "*********************\n",
      "Epoch [30/100], Loss: 0.0210, Val_Loss: 0.0209\n",
      "Epoch [31/100], Loss: 0.0209, Val_Loss: 0.0210\n",
      "Epoch [32/100], Loss: 0.0208, Val_Loss: 0.0207\n",
      "Epoch [33/100], Loss: 0.0208, Val_Loss: 0.0203\n",
      "Epoch [34/100], Loss: 0.0207, Val_Loss: 0.0202\n",
      "Epoch [35/100], Loss: 0.0206, Val_Loss: 0.0206\n",
      "Epoch [36/100], Loss: 0.0206, Val_Loss: 0.0203\n",
      "Epoch [37/100], Loss: 0.0205, Val_Loss: 0.0205\n",
      "*********************\n",
      "Epoch [38/100], Loss: 0.0204, Val_Loss: 0.0202\n",
      "Epoch [39/100], Loss: 0.0204, Val_Loss: 0.0201\n",
      "Epoch [40/100], Loss: 0.0203, Val_Loss: 0.0203\n",
      "Epoch [41/100], Loss: 0.0203, Val_Loss: 0.0204\n",
      "Epoch [42/100], Loss: 0.0202, Val_Loss: 0.0199\n",
      "*********************\n",
      "Epoch [43/100], Loss: 0.0201, Val_Loss: 0.0199\n",
      "*********************\n",
      "Epoch [44/100], Loss: 0.0201, Val_Loss: 0.0199\n",
      "Epoch [45/100], Loss: 0.0200, Val_Loss: 0.0198\n",
      "Epoch [46/100], Loss: 0.0200, Val_Loss: 0.0197\n",
      "*********************\n",
      "Epoch [47/100], Loss: 0.0199, Val_Loss: 0.0197\n",
      "Epoch [48/100], Loss: 0.0199, Val_Loss: 0.0196\n",
      "*********************\n",
      "Epoch [49/100], Loss: 0.0198, Val_Loss: 0.0196\n",
      "Epoch [50/100], Loss: 0.0198, Val_Loss: 0.0199\n",
      "*********************\n",
      "Epoch [51/100], Loss: 0.0197, Val_Loss: 0.0196\n",
      "Epoch [52/100], Loss: 0.0197, Val_Loss: 0.0195\n",
      "Epoch [53/100], Loss: 0.0196, Val_Loss: 0.0194\n",
      "*********************\n",
      "Epoch [54/100], Loss: 0.0196, Val_Loss: 0.0194\n",
      "Epoch [55/100], Loss: 0.0196, Val_Loss: 0.0193\n",
      "*********************\n",
      "Epoch [56/100], Loss: 0.0195, Val_Loss: 0.0193\n",
      "*********************\n",
      "Epoch [57/100], Loss: 0.0195, Val_Loss: 0.0193\n",
      "Epoch [58/100], Loss: 0.0194, Val_Loss: 0.0196\n",
      "Epoch [59/100], Loss: 0.0194, Val_Loss: 0.0191\n",
      "Epoch [60/100], Loss: 0.0193, Val_Loss: 0.0193\n",
      "*********************\n",
      "Epoch [61/100], Loss: 0.0193, Val_Loss: 0.0191\n",
      "*********************\n",
      "Epoch [62/100], Loss: 0.0192, Val_Loss: 0.0191\n",
      "*********************\n",
      "Epoch [63/100], Loss: 0.0192, Val_Loss: 0.0191\n",
      "Epoch [64/100], Loss: 0.0192, Val_Loss: 0.0190\n",
      "Epoch [65/100], Loss: 0.0191, Val_Loss: 0.0189\n",
      "*********************\n",
      "Epoch [66/100], Loss: 0.0191, Val_Loss: 0.0189\n",
      "Epoch [67/100], Loss: 0.0191, Val_Loss: 0.0190\n",
      "Epoch [68/100], Loss: 0.0190, Val_Loss: 0.0188\n",
      "*********************\n",
      "Epoch [69/100], Loss: 0.0190, Val_Loss: 0.0188\n",
      "*********************\n",
      "Epoch [70/100], Loss: 0.0189, Val_Loss: 0.0188\n",
      "*********************\n",
      "Epoch [71/100], Loss: 0.0189, Val_Loss: 0.0188\n",
      "Epoch [72/100], Loss: 0.0189, Val_Loss: 0.0189\n",
      "Epoch [73/100], Loss: 0.0188, Val_Loss: 0.0187\n",
      "*********************\n",
      "Epoch [74/100], Loss: 0.0188, Val_Loss: 0.0187\n",
      "*********************\n",
      "Epoch [75/100], Loss: 0.0188, Val_Loss: 0.0187\n",
      "Epoch [76/100], Loss: 0.0187, Val_Loss: 0.0186\n",
      "*********************\n",
      "Epoch [77/100], Loss: 0.0187, Val_Loss: 0.0186\n",
      "*********************\n",
      "Epoch [78/100], Loss: 0.0187, Val_Loss: 0.0186\n",
      "Epoch [79/100], Loss: 0.0186, Val_Loss: 0.0185\n",
      "*********************\n",
      "Epoch [80/100], Loss: 0.0186, Val_Loss: 0.0185\n",
      "*********************\n",
      "Epoch [81/100], Loss: 0.0186, Val_Loss: 0.0185\n",
      "*********************\n",
      "Epoch [82/100], Loss: 0.0185, Val_Loss: 0.0185\n",
      "*********************\n",
      "Epoch [83/100], Loss: 0.0185, Val_Loss: 0.0185\n",
      "Epoch [84/100], Loss: 0.0185, Val_Loss: 0.0184\n",
      "*********************\n",
      "Epoch [85/100], Loss: 0.0185, Val_Loss: 0.0184\n",
      "*********************\n",
      "Epoch [86/100], Loss: 0.0185, Val_Loss: 0.0184\n",
      "Epoch [87/100], Loss: 0.0184, Val_Loss: 0.0183\n",
      "*********************\n",
      "Epoch [88/100], Loss: 0.0184, Val_Loss: 0.0183\n",
      "*********************\n",
      "Epoch [89/100], Loss: 0.0184, Val_Loss: 0.0183\n",
      "*********************\n",
      "Epoch [90/100], Loss: 0.0184, Val_Loss: 0.0183\n",
      "*********************\n",
      "Epoch [91/100], Loss: 0.0184, Val_Loss: 0.0183\n",
      "*********************\n"
     ]
    }
   ],
   "source": [
    "# Training the autoencoder\n",
    "early_stopper = EarlyStopper(patience=5, min_delta=0.0001)\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    trl = 0\n",
    "    for bat in train_dl:\n",
    "        train_data = bat.to(\"cuda\")\n",
    "        # Forward pass\n",
    "        recons, input_, mu, log_var = model(train_data)\n",
    "        input_ = input_.unsqueeze(1)\n",
    "        loss = criterion(recons, input_, mu, log_var)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        sched.step()\n",
    "        trl += loss.item()\n",
    "        \n",
    "    model.eval()\n",
    "    vl = 0\n",
    "    with torch.no_grad():\n",
    "        for bat_val in val_dl:\n",
    "            val_data = bat_val.to(\"cuda\")\n",
    "            recons, input_, mu, log_var = model(val_data)\n",
    "            input_ = input_.unsqueeze(1)\n",
    "            val_loss = criterion(recons, input_, mu, log_var)\n",
    "            vl += val_loss.item()\n",
    "    if early_stopper.early_stop(round(vl/len(val_dl),4)):\n",
    "        break\n",
    "    # Loss for each epoch\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {trl/len(train_dl):.4f}, Val_Loss: {vl/len(val_dl):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6a8129d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.raw_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "1aab2cbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7d5c9c033370>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 26\n",
    "plt.imshow(bat_val[i].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "0e01442e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72/30680453.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x_conv_in = torch.tensor(x).unsqueeze(1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7d5c9051ff70>"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output = model(bat_val[i].unsqueeze(0).to(\"cuda\"))[0].detach().cpu()\n",
    "plt.imshow(output[0].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab870334",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec420a19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
