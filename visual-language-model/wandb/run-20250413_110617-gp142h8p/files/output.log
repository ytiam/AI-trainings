  0%|                                                     | 0/3 [00:00<?, ?it/s]
























































train step loss: 1.6325: 100%|██████████████████| 57/57 [03:05<00:00,  3.07s/it]



The hypothesis contains 0 counts of 2-gram overlaps.2/7 [00:08<00:15,  3.07s/it]
Therefore the BLEU score evaluates to 0, independently of
how many N-gram overlaps of lower order it contains.
Consider using lower n-gram order or use SmoothingFunction()
  warnings.warn(_msg)
/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning:
The hypothesis contains 0 counts of 3-gram overlaps.
Therefore the BLEU score evaluates to 0, independently of
how many N-gram overlaps of lower order it contains.
Consider using lower n-gram order or use SmoothingFunction()
  warnings.warn(_msg)
/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning:
The hypothesis contains 0 counts of 4-gram overlaps.
Therefore the BLEU score evaluates to 0, independently of
how many N-gram overlaps of lower order it contains.
Consider using lower n-gram order or use SmoothingFunction()
  warnings.warn(_msg)




  0%|                                                     | 0/3 [03:22<?, ?it/s]
  0%|                                                     | 0/3 [00:00<?, ?it/s]
























































train step loss: 1.6505: 100%|██████████████████| 57/57 [02:56<00:00,  2.83s/it]








  0%|                                                     | 0/3 [03:12<?, ?it/s]
torch.Size([20, 3, 224, 224])
torch.Size([20, 3, 224, 224])
torch.Size([20, 3, 224, 224])
torch.Size([20, 3, 224, 224])
torch.Size([20, 3, 224, 224])
torch.Size([20, 3, 224, 224])
torch.Size([7, 3, 224, 224])
  0%|                                                     | 0/3 [00:00<?, ?it/s]





































train step loss: 1.0873: 100%|██████████████████| 57/57 [02:35<00:00,  1.09it/s]



The hypothesis contains 0 counts of 2-gram overlaps.5/7 [00:06<00:02,  1.06s/it]
Therefore the BLEU score evaluates to 0, independently of
how many N-gram overlaps of lower order it contains.
Consider using lower n-gram order or use SmoothingFunction()
  warnings.warn(_msg)
/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning:
The hypothesis contains 0 counts of 3-gram overlaps.
Therefore the BLEU score evaluates to 0, independently of
how many N-gram overlaps of lower order it contains.
Consider using lower n-gram order or use SmoothingFunction()
  warnings.warn(_msg)
/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning:
The hypothesis contains 0 counts of 4-gram overlaps.
Therefore the BLEU score evaluates to 0, independently of
how many N-gram overlaps of lower order it contains.
Consider using lower n-gram order or use SmoothingFunction()
  warnings.warn(_msg)
valid step loss: 1.4939:  86%|█████████████████▏  | 6/7 [00:07<00:01,  1.23s/it]
  0%|                                                     | 0/3 [02:42<?, ?it/s]
  0%|                                                     | 0/3 [00:00<?, ?it/s]





























train step loss: 1.0684: 100%|██████████████████| 57/57 [01:00<00:00,  1.02it/s]



valid step loss: 0.8910:  71%|██████████████▎     | 5/7 [00:06<00:02,  1.23s/it]
The hypothesis contains 0 counts of 2-gram overlaps.5/7 [00:07<00:02,  1.23s/it]
Therefore the BLEU score evaluates to 0, independently of
how many N-gram overlaps of lower order it contains.
Consider using lower n-gram order or use SmoothingFunction()
  warnings.warn(_msg)
/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning:
The hypothesis contains 0 counts of 3-gram overlaps.
Therefore the BLEU score evaluates to 0, independently of
how many N-gram overlaps of lower order it contains.
Consider using lower n-gram order or use SmoothingFunction()
  warnings.warn(_msg)
/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning:
The hypothesis contains 0 counts of 4-gram overlaps.
Therefore the BLEU score evaluates to 0, independently of
how many N-gram overlaps of lower order it contains.
Consider using lower n-gram order or use SmoothingFunction()
  warnings.warn(_msg)
valid step loss: 1.2511: 100%|████████████████████| 7/7 [00:08<00:00,  1.17s/it]
 33%|███████████████                              | 1/3 [01:08<02:17, 68.67s/it]





































train step loss: 0.4667: 100%|██████████████████| 57/57 [01:15<00:00,  1.24s/it]




valid step loss: 0.5702:  86%|█████████████████▏  | 6/7 [00:09<00:01,  1.58s/it]
 67%|██████████████████████████████               | 2/3 [02:34<01:18, 78.60s/it]




















































train step loss: 0.2828: 100%|██████████████████| 57/57 [02:00<00:00,  2.34s/it]







valid step loss: 0.3553:  86%|█████████████████▏  | 6/7 [00:14<00:02,  2.34s/it]

100%|█████████████████████████████████████████████| 3/3 [04:49<00:00, 96.60s/it]