{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8ae3f798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stage6_end_to_end.py\n",
    "from langgraph.graph import StateGraph, MessagesState, END\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.tools import tool\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, ToolMessage\n",
    "import wikipedia\n",
    "import json\n",
    "import os\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from typing import List, Dict, Annotated\n",
    "from langgraph.graph.message import add_messages # Import add_messages\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "load_dotenv(\"../../../config/local.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672a1d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator # Import the operator module\n",
    "\n",
    "class CustomMessagesState(MessagesState):\n",
    "    draft: str\n",
    "    feedback: str\n",
    "    score: int\n",
    "    task: str\n",
    "    revise_iter: int\n",
    "    subtasks: str\n",
    "    subtask_index: int\n",
    "    research: Annotated[List[Dict], operator.add]\n",
    "    next_node: str\n",
    "    tool_args: str\n",
    "    last_research_msg: str\n",
    "    error: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c85feb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------- Config ----------\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "EVAL_THRESHOLD = 8\n",
    "MAX_REVISE_ITER = 2\n",
    "CHECKPOINT_FILE = \"agent_checkpoints.json\"\n",
    "\n",
    "# ---------- Helpers: simple file memory ----------\n",
    "def load_checkpoints():\n",
    "    if os.path.exists(CHECKPOINT_FILE):\n",
    "        with open(CHECKPOINT_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "            return json.load(f)\n",
    "    return {}\n",
    "\n",
    "def save_checkpoint(key, value):\n",
    "    data = load_checkpoints()\n",
    "    data[key] = value\n",
    "    with open(CHECKPOINT_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9454c7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Tools ----------\n",
    "\n",
    "@tool\n",
    "def wiki_search(query: str) -> str:\n",
    "    \"\"\"Search Wikipedia for a summary on the given query.\"\"\"\n",
    "    try:\n",
    "        return wikipedia.summary(query, sentences=2)\n",
    "    except Exception:\n",
    "        return \"No summary found.\"\n",
    "\n",
    "@tool\n",
    "def calculator(expression: str) -> str:\n",
    "    \"\"\"Evaluate a mathematical expression.\"\"\"\n",
    "    try:\n",
    "        return str(eval(expression))\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "@tool\n",
    "def read_csv_tool(input_str: str) -> str:\n",
    "    \"\"\"\n",
    "    Read a CSV file from a string or base64-encoded bytes and return its contents.\n",
    "    Input format:\n",
    "    - For text CSV: pass CSV text directly\n",
    "    - For file bytes: pass base64 string starting with 'base64:'\n",
    "    Returns:\n",
    "        CSV content preview + column names.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(\"REACHED read_csv_tool\")\n",
    "        if input_str.startswith(\"base64:\"):\n",
    "            import base64\n",
    "            bdata = base64.b64decode(input_str.replace(\"base64:\", \"\"))\n",
    "            df = pd.read_csv(io.BytesIO(bdata))\n",
    "        else:\n",
    "            df = pd.read_csv(io.StringIO(input_str))\n",
    "\n",
    "        preview = df.head().to_string()\n",
    "        cols = \", \".join(df.columns)\n",
    "\n",
    "        return f\"Columns: {cols}\\n\\nPreview:\\n{preview}\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error reading CSV: {str(e)}\"\n",
    "\n",
    "\n",
    "TOOLS = [wiki_search, calculator, read_csv_tool]\n",
    "\n",
    "# ---------- LLM ----------\n",
    "llm = ChatOpenAI(model=MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "15ff5a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_numerator(feedback: str, default: int = 7) -> int:\n",
    "    \"\"\"\n",
    "    Extracts the first integer before a slash (/) in the given feedback string.\n",
    "    Returns `default` if no such pattern is found.\n",
    "    \"\"\"\n",
    "    match = re.search(r'\\b(\\d+)(?=\\s*/)', feedback)\n",
    "    return int(match.group(1)) if match else default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7169124",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------- System prompts ----------\n",
    "SYSTEM_PLANNER = SystemMessage(content=(\"You are a planner that breaks a high-level task into subtasks.\"\n",
    "    \"Understand the user's main task and create clear, manageable subtasks to achieve it.\"\n",
    "    \"If the task involves CSV data, ensure at least one subtask addresses it. and if required include the data context from the user provided context\"\n",
    "))\n",
    "SYSTEM_RESEARCH = SystemMessage(content=(\n",
    "    \"You are a researcher that decides which tool to call. \"\n",
    "    \"Return an LLM response that may include a tool_call if you need external data.\"\n",
    "    \"If the user provides a CSV or requests analysis of CSV data, you MUST call the 'read_csv_tool' tool.\"\n",
    "))\n",
    "SYSTEM_WRITER = SystemMessage(content=\"You are a writer. Synthesize the provided research into a concise, clear answer.\")\n",
    "SYSTEM_EVALUATOR = SystemMessage(content=\"You are an evaluator. Score from 1-10 and provide short critique and improvement points.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9b7f74c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Node implementations ----------\n",
    "def planner_node(state: CustomMessagesState):\n",
    "    try:\n",
    "        user_task = state[\"task\"]\n",
    "        # simple decomposition prompt\n",
    "        prompt = f\"Task: {user_task}\\nBreak this into 2 short subtasks (one sentence each). Make the subtasks pointed, coincise and task oriented to cover the task requirements. \\\n",
    "                you only have access to tools like wiki_search, calculator and read_csv_tool. if the task involves csv data, ensure one subtask is about reading and understanding the csv data provided.\"\n",
    "        resp = llm.invoke([SYSTEM_PLANNER, HumanMessage(content=prompt)])\n",
    "        subtasks = [s.strip() for s in resp.content.split(\"\\n\") if s.strip()]\n",
    "        # fallback if LLM didn't give 3 lines\n",
    "        if len(subtasks) < 1:\n",
    "            subtasks = [user_task]\n",
    "        print(\"Planner generated subtasks:\", subtasks)\n",
    "        return {\"subtasks\": subtasks, \"subtask_index\": 0, \"research\": []}\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "\n",
    "def researcher_node(state: CustomMessagesState):\n",
    "    try:\n",
    "        idx = state[\"subtask_index\"]\n",
    "        subtasks: List[str] = state[\"subtasks\"]\n",
    "        if idx >= len(subtasks):\n",
    "            # nothing left\n",
    "            return {} #{\"done\": True}\n",
    "        current = subtasks[idx]\n",
    "        # create messages including system and brief history\n",
    "        # messages = [SYSTEM_RESEARCH, HumanMessage(content=f\"Research this: {current}\")]\n",
    "\n",
    "        messages = [\n",
    "            SYSTEM_RESEARCH,\n",
    "            HumanMessage(\n",
    "                content=(\n",
    "                    f\"Research this subtask:\\n{current}\\n\\n\"\n",
    "                    f\"Original user data (for reference):\\n{state.get('task','')}\"\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        # allow model to call tools\n",
    "        response = llm.bind_tools(TOOLS).invoke(messages)\n",
    "        # If tool call -> handle via tool node (route will be to 'tool')\n",
    "        if response.tool_calls:\n",
    "            # carry needed context for tool node\n",
    "            return {\n",
    "                \"research\": state.get(\"research\", []),\n",
    "                \"subtasks\": subtasks,\n",
    "                \"subtask_index\": idx,\n",
    "                \"next_node\": response.tool_calls[0][\"name\"],\n",
    "                \"tool_args\": response.tool_calls[0][\"args\"],\n",
    "                \"last_research_msg\": response  # store the model message that requested the tool\n",
    "            }\n",
    "\n",
    "        # If no tool call, treat response as observation/result\n",
    "        observations = state.get(\"research\", []) + [{\"subtask\": current, \"result\": response.content}]\n",
    "        return {\n",
    "            \"research\": observations,\n",
    "            \"subtasks\": subtasks,\n",
    "            \"subtask_index\": idx + 1\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "\n",
    "def tool_node(state: CustomMessagesState):\n",
    "    try:\n",
    "        subtasks = state.get(\"subtasks\", [])\n",
    "        idx = state.get(\"subtask_index\", 0)\n",
    "\n",
    "        # Safety check\n",
    "        if not subtasks or idx >= len(subtasks):\n",
    "            print(\"[tool_node] No valid subtask found, skipping tool execution.\")\n",
    "            #return {\"done\": True}\n",
    "            return {\n",
    "                \"research\": state.get(\"research\", []),\n",
    "                \"subtasks\": subtasks,\n",
    "                \"subtask_index\": idx,\n",
    "                \"next_node\": None,\n",
    "            }\n",
    "        tool_name = state[\"next_node\"]\n",
    "        tool_args = state[\"tool_args\"]\n",
    "        last_model_msg = state[\"last_research_msg\"]\n",
    "        # execute appropriate tool\n",
    "        result = None\n",
    "        for t in TOOLS:\n",
    "            if t.name == tool_name:\n",
    "                result = t.invoke(tool_args)\n",
    "                break\n",
    "        if result is None: \n",
    "            result = f\"Tool {tool_name} not found.\"\n",
    "\n",
    "        # Build a ToolMessage linked to the tool_call_id from the stored model message\n",
    "        tool_call_id = None\n",
    "        if hasattr(last_model_msg, \"tool_calls\") and last_model_msg.tool_calls:\n",
    "            tool_call_id = last_model_msg.tool_calls[0][\"id\"]\n",
    "        # if no id, generate a safe fallback\n",
    "        if not tool_call_id:\n",
    "            tool_call_id = \"auto_tool_call\"\n",
    "\n",
    "        tool_msg = ToolMessage(content=result, tool_call_id=tool_call_id)\n",
    "        # append tool observation into research history\n",
    "        observations = state.get(\"research\", []) + [{\"subtask\": state[\"subtasks\"][state[\"subtask_index\"]], \"result\": result}]\n",
    "        return {\n",
    "            \"research\": observations,\n",
    "            \"subtasks\": state[\"subtasks\"],\n",
    "            \"subtask_index\": state[\"subtask_index\"] + 1,  # move to next subtask after tool result\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "\n",
    "def writer_node(state: CustomMessagesState):\n",
    "    try:\n",
    "        print(\"Reached writer node\")\n",
    "        # gather all research into a single prompt\n",
    "        research = state.get(\"research\", [])\n",
    "        topic = state.get(\"task\")\n",
    "        research_text = \"\\n\".join([f\"- {r['subtask']}: {r['result']}\" for r in research])\n",
    "        prompt = f\"Topic: {topic}\\nResearch gathered:\\n{research_text}\\n\\nWrite final answer (concise).\"\n",
    "        resp = llm.invoke([SYSTEM_WRITER, HumanMessage(content=prompt)])\n",
    "        return {\"draft\": resp.content, \"research\": research, \"task\": topic, \"revise_iter\": 0}\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "def evaluator_node(state: CustomMessagesState):\n",
    "    try:\n",
    "        print(\"Reached Eval Node\")\n",
    "        draft = state[\"draft\"]\n",
    "        prompt = f\"Text:\\n{draft}\\n\\nGive a score from 1–10 in the format `score: x/10`, then give a 1-line critique and 1 improvement suggestion.\"\n",
    "        resp = llm.invoke([SYSTEM_EVALUATOR, HumanMessage(content=prompt)])\n",
    "        # crude score parsing\n",
    "        score = extract_numerator(resp.content, default=7)\n",
    "        print(f\"Evaluation score: {score}, feedback: {resp.content}\")\n",
    "        return {\"draft\": draft, \"feedback\": resp.content, \"score\": score, \"revise_iter\": state.get(\"revise_iter\", 0)}\n",
    "    except Exception as e:\n",
    "        print(f\"Error in evaluator_node: {str(e)}\")\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "\n",
    "def reviser_node(state: CustomMessagesState):\n",
    "    try:\n",
    "        draft = state[\"draft\"]\n",
    "        feedback = state[\"feedback\"]\n",
    "        iter_count = state.get(\"revise_iter\", 0) + 1\n",
    "        prompt = f\"Improve the draft based on this feedback:\\nFeedback: {feedback}\\n\\nDraft:\\n{draft}\"\n",
    "        resp = llm.invoke([HumanMessage(content=prompt)])\n",
    "        return {\"draft\": resp.content, \"revise_iter\": iter_count, \"feedback\": state[\"feedback\"], \"score\": state[\"score\"], \"task\": state.get(\"task\")}\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "def error_node(state: CustomMessagesState):\n",
    "    return {\"draft\": f\"Agent failed safely. Error: {state.get('error')}\"}\n",
    "\n",
    "def route_researcher(state: CustomMessagesState):\n",
    "    if (\"next_node\" in state) and (state[\"next_node\"] is not None):\n",
    "        return \"tool\"\n",
    "    \n",
    "    idx = state.get(\"subtask_index\", 0)\n",
    "    subtasks = state.get(\"subtasks\", [])\n",
    "    \n",
    "    # Check if there are still subtasks left to process\n",
    "    if idx < len(subtasks):\n",
    "        return \"researcher\"\n",
    "    else:\n",
    "        # All subtasks complete\n",
    "        return \"writer\"\n",
    "    \n",
    "\n",
    "def route_eval(state:CustomMessagesState):\n",
    "    score = state.get(\"score\", 0)\n",
    "    revise_iter = state.get(\"revise_iter\", 0)\n",
    "    if score < EVAL_THRESHOLD and revise_iter < MAX_REVISE_ITER:\n",
    "        return \"reviser\"\n",
    "    else:\n",
    "        return END\n",
    "\n",
    "def route_errors(state):\n",
    "    if \"error\" in state:\n",
    "        return \"error\"\n",
    "\n",
    "#-----------------------------------------------\n",
    "\n",
    "builder1 = StateGraph(CustomMessagesState)\n",
    "\n",
    "builder1.add_node(\"planner\", planner_node)\n",
    "builder1.add_node(\"researcher\", researcher_node)\n",
    "builder1.add_node(\"tool\", tool_node)\n",
    "builder1.add_node(\"writer\", writer_node)\n",
    "builder1.add_node(\"evaluator\", evaluator_node)\n",
    "builder1.add_node(\"reviser\", reviser_node)\n",
    "# builder1.add_node(\"error\", error_node)\n",
    "\n",
    "builder1.set_entry_point(\"planner\")\n",
    "builder1.add_edge(\"planner\", \"researcher\")\n",
    "\n",
    "builder1.add_conditional_edges(\"researcher\", route_researcher, {\"tool\": \"tool\", \"writer\": \"writer\"})\n",
    "# builder1.add_conditional_edges(\"tool\", route_tool, {\"researcher\": \"researcher\", END: END})\n",
    "builder1.add_edge(\"tool\", \"researcher\")\n",
    "\n",
    "builder1.add_edge(\"writer\", \"evaluator\")\n",
    "builder1.add_conditional_edges(\"evaluator\", route_eval, {\"reviser\": \"reviser\", END: END})\n",
    "builder1.add_edge(\"reviser\", \"evaluator\")\n",
    "\n",
    "# builder1.add_edge(\"planner\", \"error\")\n",
    "# builder1.add_edge(\"researcher\", \"error\")\n",
    "# builder1.add_edge(\"tool\", \"error\")\n",
    "# builder1.add_edge(\"writer\", \"error\")\n",
    "\n",
    "graph1 = builder1.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ecce8494",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_recursion_limit = 25\n",
    "\n",
    "# Create a RunnableConfig object with the specified recursion limit\n",
    "config = RunnableConfig(recursion_limit=custom_recursion_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa41ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph1\n",
    "# prompt1 -> \"Write a detailed analysis of the following CSV data:\\n\\nName,Age,Occupation,Salary\\nAlice,30,Engineer,70000\\nBob,25,Designer,50000\\n;Diana,28,Doctor,80000\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "74a5ba0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planner generated subtasks: ['1. Use the read_csv_tool to extract and analyze the data from the provided CSV file to identify relevant examples and contextual information for explaining the theory of relativity.', '2. Research the theory of relativity and formulate a clear explanation while incorporating insights drawn from the CSV data regarding the occupations and salaries of the individuals mentioned.']\n",
      "REACHED read_csv_tool\n",
      "REACHED read_csv_tool\n",
      "[tool_node] No valid subtask found, skipping tool execution.\n",
      "Reached writer node\n",
      "Reached Eval Node\n",
      "Evaluation score: 7, feedback: score: 7/10  \n",
      "The text contains informative content but lacks clarity in connecting the theory of relativity with the CSV data contextually.  \n",
      "Improvement suggestion: Strengthen the connections between relativity concepts and the examples by elaborating on how each individual’s experiences metaphorically relate to time and space as influenced by relativity.\n",
      "Reached Eval Node\n",
      "Evaluation score: 8, feedback: score: 8/10  \n",
      "The text effectively connects the theory of relativity with personal experiences but could benefit from clearer connections between the scientific concepts and the individuals' situations.  \n",
      "\n",
      "Improvement suggestion: Strengthen the links between the individuals' experiences and the principles of relativity with more explicit comparisons for clarity.\n"
     ]
    }
   ],
   "source": [
    "init_state = {\"task\": \"Explain the theory of relativity using data from the provided CSV file:\\n\\nName,Age,Occupation,Salary\\nAlice,30,Engineer,70000\\nBob,25,Designer,50000\\nDiana,28,Doctor,80000\"}\n",
    "result = graph1.invoke(init_state, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "696ad4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The theory of relativity, formulated by Albert Einstein, encompasses two theories: special relativity and general relativity. Special relativity introduces the idea that the laws of physics are the same for all non-accelerating observers, emphasizing the intrinsic relationship between space and time. It asserts that the speed of light is constant, leading to phenomena such as time dilation and length contraction at high velocities. General relativity extends these concepts to the influence of gravity, describing it as the curvature of spacetime caused by mass.\n",
      "\n",
      "To contextualize these profound concepts with examples from our CSV data, consider the individual experiences of Alice (age 30, occupation Engineer, salary $70,000), Bob (age 25, occupation Designer, salary $50,000), and Diana (age 28, occupation Doctor, salary $80,000). Each of these individuals navigates their own \"spacetime\" marked by their career choices and financial situations, and we can draw interesting parallels to the principles of relativity.\n",
      "\n",
      "For example, Alice, an engineer, approaches life's challenges with a systematic and logical framework, akin to how an inertial observer in special relativity perceives time and space as linear and consistent. Her salary and profession may provide her with greater financial stability, allowing her to explore opportunities (much like a spaceship traveling at light speed, moving freely through the cosmos). \n",
      "\n",
      "Conversely, Bob, a designer, may experience a more dynamic lifestyle influenced by the immediacy of trends and creative demands—a reflection of how time can be perceived differently depending on one's relative velocity through the currents of cultural change. This can be likened to the concept of time dilation; his experiences may seem to stretch and warp under the pressure of deadlines and the fast-paced world of design.\n",
      "\n",
      "Diana, as a doctor, occupies a position of significant responsibility, which can be comparable to the gravitational effects explained in general relativity. Her high-stakes role may compress her personal time, making each moment feel heavier, much like how mass influences the curvature of spacetime, affecting the flow of time for those nearby—or in this case, the patients relying on her expertise.\n",
      "\n",
      "In conclusion, while the CSV data reflects the diverse experiences shaped by occupation and income, the theory of relativity fundamentally alters our perception of reality. It emphasizes that time, space, and our perceived \"velocity\" through life are interconnected in profound and metaphorical ways, echoing the experiences of Alice, Bob, and Diana as they navigate a universe where their individual journeys are shaped by the relativity of their choices and circumstances.\n"
     ]
    }
   ],
   "source": [
    "print(result[\"draft\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3094a29e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ddae26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
